2018-09-06 11:24:07,581-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-06 11:24:09,229-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-06 11:24:09,341-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-06 11:24:09,342-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-06 11:24:09,804-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-06 11:24:09,818-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-06 11:24:09,914-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-06 11:24:09,985-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-06 11:24:10,169-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1918383273_0001
2018-09-06 11:24:10,170-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-06 11:24:10,325-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-06 11:24:10,326-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1918383273_0001
2018-09-06 11:24:10,327-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-06 11:24:10,337-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-06 11:24:10,337-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-06 11:24:10,337-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-06 11:24:10,462-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-06 11:24:10,463-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1918383273_0001_m_000000_0
2018-09-06 11:24:10,497-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-06 11:24:10,498-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-06 11:24:10,521-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-06 11:24:10,521-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-06 11:24:10,525-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t2.txt:0+58
2018-09-06 11:24:10,679-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-06 11:24:10,680-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-06 11:24:10,680-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-06 11:24:10,680-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-06 11:24:10,680-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-06 11:24:10,684-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-06 11:24:10,886-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-06 11:24:10,889-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-06 11:24:10,889-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-06 11:24:10,889-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-09-06 11:24:10,889-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-06 11:24:10,922-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-06 11:24:10,938-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1918383273_0001_m_000000_0 is done. And is in the process of committing
2018-09-06 11:24:10,944-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-06 11:24:10,944-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1918383273_0001_m_000000_0' done.
2018-09-06 11:24:10,956-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1918383273_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=299
		FILE: Number of bytes written=499874
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=76
		Input split bytes=112
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=300417024
	File Input Format Counters 
		Bytes Read=58
2018-09-06 11:24:10,956-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1918383273_0001_m_000000_0
2018-09-06 11:24:10,957-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1918383273_0001_m_000001_0
2018-09-06 11:24:10,958-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-06 11:24:10,958-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-06 11:24:10,959-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-06 11:24:10,959-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-06 11:24:10,961-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t1.txt:0+50
2018-09-06 11:24:11,138-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-06 11:24:11,139-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-06 11:24:11,139-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-06 11:24:11,139-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-06 11:24:11,139-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-06 11:24:11,140-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-06 11:24:11,151-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-06 11:24:11,151-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-06 11:24:11,151-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-06 11:24:11,151-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-09-06 11:24:11,151-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-06 11:24:11,166-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-06 11:24:11,178-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1918383273_0001_m_000001_0 is done. And is in the process of committing
2018-09-06 11:24:11,185-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-06 11:24:11,186-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1918383273_0001_m_000001_0' done.
2018-09-06 11:24:11,187-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1918383273_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=542
		FILE: Number of bytes written=499972
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=66
		Input split bytes=112
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=405798912
	File Input Format Counters 
		Bytes Read=50
2018-09-06 11:24:11,187-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1918383273_0001_m_000001_0
2018-09-06 11:24:11,188-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-06 11:24:11,192-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-06 11:24:11,193-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1918383273_0001_r_000000_0
2018-09-06 11:24:11,203-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-06 11:24:11,204-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-06 11:24:11,204-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-06 11:24:11,205-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-06 11:24:11,212-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@58644cb
2018-09-06 11:24:11,222-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-06 11:24:11,257-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-06 11:24:11,260-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1918383273_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-06 11:24:11,281-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1918383273_0001_m_000000_0 decomp: 72 len: 76 to MEMORY
2018-09-06 11:24:11,285-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 72 bytes from map-output for attempt_local1918383273_0001_m_000000_0
2018-09-06 11:24:11,286-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 72, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->72
2018-09-06 11:24:11,289-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1918383273_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2018-09-06 11:24:11,290-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local1918383273_0001_m_000001_0
2018-09-06 11:24:11,290-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 72, usedMemory ->134
2018-09-06 11:24:11,291-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-06 11:24:11,292-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-06 11:24:11,292-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-06 11:24:11,309-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-06 11:24:11,309-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 122 bytes
2018-09-06 11:24:11,320-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 134 bytes to disk to satisfy reduce memory limit
2018-09-06 11:24:11,320-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 136 bytes from disk
2018-09-06 11:24:11,321-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-06 11:24:11,321-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-06 11:24:11,321-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 126 bytes
2018-09-06 11:24:11,322-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-06 11:24:11,338-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1918383273_0001 running in uber mode : false
2018-09-06 11:24:11,343-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-09-06 11:24:11,459-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-06 11:24:12,108-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1918383273_0001_r_000000_0 is done. And is in the process of committing
2018-09-06 11:24:12,109-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-06 11:24:12,110-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1918383273_0001_r_000000_0 is allowed to commit now
2018-09-06 11:24:12,122-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1918383273_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/data_output_1
2018-09-06 11:24:12,123-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-06 11:24:12,123-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1918383273_0001_r_000000_0' done.
2018-09-06 11:24:12,124-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1918383273_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=884
		FILE: Number of bytes written=500108
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=27
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=142
		Reduce input records=13
		Reduce output records=3
		Spilled Records=13
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=405798912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=27
2018-09-06 11:24:12,124-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1918383273_0001_r_000000_0
2018-09-06 11:24:12,124-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-06 11:24:12,349-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-06 11:24:12,350-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1918383273_0001 completed successfully
2018-09-06 11:24:12,359-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=1725
		FILE: Number of bytes written=1499954
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=274
		HDFS: Number of bytes written=27
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=142
		Input split bytes=224
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=142
		Reduce input records=13
		Reduce output records=3
		Spilled Records=26
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=1112014848
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=27
2018-09-06 11:52:56,032-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-06 11:52:57,417-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-06 11:52:57,493-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-06 11:52:57,493-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-06 11:52:57,824-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-06 11:52:57,834-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-06 11:52:57,896-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
2018-09-06 11:52:57,974-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-06 11:52:58,042-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3
2018-09-06 11:52:58,175-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local2119177971_0001
2018-09-06 11:52:58,177-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-06 11:52:58,313-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-06 11:52:58,313-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local2119177971_0001
2018-09-06 11:52:58,314-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-06 11:52:58,323-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-06 11:52:58,323-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-06 11:52:58,324-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-06 11:52:58,360-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-06 11:52:58,361-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2119177971_0001_m_000000_0
2018-09-06 11:52:58,386-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-06 11:52:58,386-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-06 11:52:58,396-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-06 11:52:58,396-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-06 11:52:58,400-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t4.txt:0+72
2018-09-06 11:52:58,495-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-06 11:52:58,495-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-06 11:52:58,495-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-06 11:52:58,495-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-06 11:52:58,495-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-06 11:52:58,499-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-06 11:52:58,620-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-06 11:52:58,623-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-06 11:52:58,623-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-06 11:52:58,623-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 128; bufvoid = 104857600
2018-09-06 11:52:58,623-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-06 11:52:58,647-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-06 11:52:58,660-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local2119177971_0001_m_000000_0 is done. And is in the process of committing
2018-09-06 11:52:58,663-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-06 11:52:58,663-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local2119177971_0001_m_000000_0' done.
2018-09-06 11:52:58,675-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local2119177971_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=856
		FILE: Number of bytes written=504335
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=72
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=128
		Map output materialized bytes=154
		Input split bytes=251
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=277348352
	File Input Format Counters 
		Bytes Read=0
2018-09-06 11:52:58,676-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2119177971_0001_m_000000_0
2018-09-06 11:52:58,676-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2119177971_0001_m_000001_0
2018-09-06 11:52:58,677-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-06 11:52:58,677-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-06 11:52:58,678-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-06 11:52:58,678-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-06 11:52:58,680-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t3.txt:0+62
2018-09-06 11:52:58,770-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-06 11:52:58,770-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-06 11:52:58,771-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-06 11:52:58,771-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-06 11:52:58,771-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-06 11:52:58,772-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-06 11:52:58,792-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-06 11:52:58,792-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-06 11:52:58,792-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-06 11:52:58,792-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 110; bufvoid = 104857600
2018-09-06 11:52:58,793-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-06 11:52:58,803-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-06 11:52:58,809-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local2119177971_0001_m_000001_0 is done. And is in the process of committing
2018-09-06 11:52:58,811-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-06 11:52:58,811-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local2119177971_0001_m_000001_0' done.
2018-09-06 11:52:58,812-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local2119177971_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=1635
		FILE: Number of bytes written=504525
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=134
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=110
		Map output materialized bytes=134
		Input split bytes=251
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=382730240
	File Input Format Counters 
		Bytes Read=0
2018-09-06 11:52:58,812-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2119177971_0001_m_000001_0
2018-09-06 11:52:58,812-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2119177971_0001_m_000002_0
2018-09-06 11:52:58,813-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-06 11:52:58,813-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-06 11:52:58,814-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-06 11:52:58,814-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-06 11:52:58,816-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/s1.txt:0+21
2018-09-06 11:52:58,946-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-06 11:52:58,946-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-06 11:52:58,946-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-06 11:52:58,946-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-06 11:52:58,947-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-06 11:52:58,953-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-06 11:52:58,965-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-06 11:52:58,965-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-06 11:52:58,965-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-06 11:52:58,966-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 37; bufvoid = 104857600
2018-09-06 11:52:58,966-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2018-09-06 11:52:58,989-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-06 11:52:58,997-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local2119177971_0001_m_000002_0 is done. And is in the process of committing
2018-09-06 11:52:59,002-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-06 11:52:59,002-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local2119177971_0001_m_000002_0' done.
2018-09-06 11:52:59,003-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local2119177971_0001_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=2414
		FILE: Number of bytes written=504634
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=37
		Map output materialized bytes=53
		Input split bytes=254
		Combine input records=0
		Spilled Records=2
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=488112128
	File Input Format Counters 
		Bytes Read=0
2018-09-06 11:52:59,003-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2119177971_0001_m_000002_0
2018-09-06 11:52:59,004-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-06 11:52:59,010-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-06 11:52:59,010-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2119177971_0001_r_000000_0
2018-09-06 11:52:59,021-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-06 11:52:59,021-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-06 11:52:59,021-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-06 11:52:59,021-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-06 11:52:59,026-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2025e28a
2018-09-06 11:52:59,031-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-06 11:52:59,057-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-06 11:52:59,059-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local2119177971_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-06 11:52:59,083-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local2119177971_0001_m_000000_0 decomp: 84 len: 88 to MEMORY
2018-09-06 11:52:59,086-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 84 bytes from map-output for attempt_local2119177971_0001_m_000000_0
2018-09-06 11:52:59,088-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 84, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->84
2018-09-06 11:52:59,091-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local2119177971_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2018-09-06 11:52:59,091-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 23 bytes from map-output for attempt_local2119177971_0001_m_000002_0
2018-09-06 11:52:59,092-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 2, commitMemory -> 84, usedMemory ->107
2018-09-06 11:52:59,093-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local2119177971_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-06 11:52:59,093-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local2119177971_0001_m_000001_0
2018-09-06 11:52:59,094-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 3, commitMemory -> 107, usedMemory ->170
2018-09-06 11:52:59,094-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-06 11:52:59,095-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-06 11:52:59,095-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-06 11:52:59,107-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-06 11:52:59,108-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 140 bytes
2018-09-06 11:52:59,114-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 170 bytes to disk to satisfy reduce memory limit
2018-09-06 11:52:59,115-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 170 bytes from disk
2018-09-06 11:52:59,115-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-06 11:52:59,115-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-06 11:52:59,115-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 156 bytes
2018-09-06 11:52:59,116-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-06 11:52:59,147-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-06 11:52:59,266-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local2119177971_0001_r_000000_0 is done. And is in the process of committing
2018-09-06 11:52:59,268-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-06 11:52:59,268-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local2119177971_0001_r_000000_0 is allowed to commit now
2018-09-06 11:52:59,290-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local2119177971_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/data_2/out_11
2018-09-06 11:52:59,291-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-06 11:52:59,291-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local2119177971_0001_r_000000_0' done.
2018-09-06 11:52:59,291-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local2119177971_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=3093
		FILE: Number of bytes written=504804
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=150
		HDFS: Number of read operations=18
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=182
		Reduce input records=8
		Reduce output records=7
		Spilled Records=8
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=488112128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=150
2018-09-06 11:52:59,292-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2119177971_0001_r_000000_0
2018-09-06 11:52:59,292-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2119177971_0001_r_000001_0
2018-09-06 11:52:59,293-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-06 11:52:59,293-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-06 11:52:59,294-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-06 11:52:59,294-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-06 11:52:59,294-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7e886c78
2018-09-06 11:52:59,294-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-06 11:52:59,295-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-06 11:52:59,296-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local2119177971_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-06 11:52:59,297-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local2119177971_0001_m_000000_0 decomp: 62 len: 66 to MEMORY
2018-09-06 11:52:59,298-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local2119177971_0001_m_000000_0
2018-09-06 11:52:59,298-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->62
2018-09-06 11:52:59,300-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local2119177971_0001_m_000002_0 decomp: 22 len: 26 to MEMORY
2018-09-06 11:52:59,300-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local2119177971_0001_m_000002_0
2018-09-06 11:52:59,300-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 62, usedMemory ->84
2018-09-06 11:52:59,304-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local2119177971_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-06 11:52:59,305-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local2119177971_0001_m_000001_0
2018-09-06 11:52:59,305-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 3, commitMemory -> 84, usedMemory ->147
2018-09-06 11:52:59,306-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-06 11:52:59,306-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-06 11:52:59,307-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-06 11:52:59,312-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-06 11:52:59,313-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 117 bytes
2018-09-06 11:52:59,318-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 147 bytes to disk to satisfy reduce memory limit
2018-09-06 11:52:59,319-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 147 bytes from disk
2018-09-06 11:52:59,319-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-06 11:52:59,319-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-06 11:52:59,319-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 133 bytes
2018-09-06 11:52:59,320-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-06 11:52:59,320-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local2119177971_0001 running in uber mode : false
2018-09-06 11:52:59,321-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 50%
2018-09-06 11:52:59,348-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local2119177971_0001_r_000001_0 is done. And is in the process of committing
2018-09-06 11:52:59,351-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-06 11:52:59,351-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local2119177971_0001_r_000001_0 is allowed to commit now
2018-09-06 11:52:59,356-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local2119177971_0001_r_000001_0' to hdfs://localhost:9000/user/lizhijun/data_2/out_11
2018-09-06 11:52:59,357-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-06 11:52:59,357-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local2119177971_0001_r_000001_0' done.
2018-09-06 11:52:59,358-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local2119177971_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=3567
		FILE: Number of bytes written=504951
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=271
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=159
		Reduce input records=7
		Reduce output records=6
		Spilled Records=7
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=488112128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=121
2018-09-06 11:52:59,358-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2119177971_0001_r_000001_0
2018-09-06 11:52:59,358-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-06 11:53:00,322-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-06 11:53:00,324-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local2119177971_0001 completed successfully
2018-09-06 11:53:00,333-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=11565
		FILE: Number of bytes written=2523249
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=671
		HDFS: Number of bytes written=421
		HDFS: Number of read operations=74
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=11
	Map-Reduce Framework
		Map input records=15
		Map output records=15
		Map output bytes=275
		Map output materialized bytes=341
		Input split bytes=756
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=341
		Reduce input records=15
		Reduce output records=13
		Spilled Records=30
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2124414976
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=271
