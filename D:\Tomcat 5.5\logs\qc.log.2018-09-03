2018-09-03 14:53:55,842-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 14:53:57,665-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-09-03 14:53:58,481-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 14:53:58,494-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 14:53:58,804-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 14:53:58,872-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 14:53:58,930-[TS] INFO main org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-09-03 14:53:59,065-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1535957157618_0001
2018-09-03 14:53:59,067-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 14:53:59,229-[TS] INFO main org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.
2018-09-03 14:53:59,282-[TS] INFO main org.apache.hadoop.conf.Configuration - resource-types.xml not found
2018-09-03 14:53:59,283-[TS] INFO main org.apache.hadoop.yarn.util.resource.ResourceUtils - Unable to find 'resource-types.xml'.
2018-09-03 14:53:59,630-[TS] INFO main org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1535957157618_0001
2018-09-03 14:53:59,680-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://10.215.107.197:8088/proxy/application_1535957157618_0001/
2018-09-03 14:53:59,681-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_1535957157618_0001
2018-09-03 14:54:03,725-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535957157618_0001 running in uber mode : false
2018-09-03 14:54:03,728-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
2018-09-03 14:54:03,745-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535957157618_0001 failed with state FAILED due to: Application application_1535957157618_0001 failed 2 times due to AM Container for appattempt_1535957157618_0001_000002 exited with  exitCode: 1
Failing this attempt.Diagnostics: [2018-09-03 14:54:03.477]Exception from container-launch.
Container id: container_1535957157618_0001_02_000001
Exit code: 1

[2018-09-03 14:54:03.479]Container exited with a non-zero exit code 1. Error file: prelaunch.err.
Last 4096 bytes of prelaunch.err :
Last 4096 bytes of stderr :
错误: 找不到或无法加载主类 org.apache.hadoop.mapreduce.v2.app.MRAppMaster


[2018-09-03 14:54:03.480]Container exited with a non-zero exit code 1. Error file: prelaunch.err.
Last 4096 bytes of prelaunch.err :
Last 4096 bytes of stderr :
错误: 找不到或无法加载主类 org.apache.hadoop.mapreduce.v2.app.MRAppMaster


For more detailed output, check the application tracking page: http://10.215.107.197:8088/cluster/app/application_1535957157618_0001 Then click on links to logs of each attempt.
. Failing the application.
2018-09-03 14:54:03,772-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
2018-09-03 15:07:16,931-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 15:07:18,558-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-09-03 15:07:19,326-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 15:07:19,358-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 15:07:19,538-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 15:07:19,663-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 15:07:19,765-[TS] INFO main org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-09-03 15:07:19,970-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1535958417064_0001
2018-09-03 15:07:19,972-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 15:07:20,198-[TS] INFO main org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.
2018-09-03 15:07:20,247-[TS] INFO main org.apache.hadoop.conf.Configuration - resource-types.xml not found
2018-09-03 15:07:20,247-[TS] INFO main org.apache.hadoop.yarn.util.resource.ResourceUtils - Unable to find 'resource-types.xml'.
2018-09-03 15:07:20,774-[TS] INFO main org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1535958417064_0001
2018-09-03 15:07:20,819-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://10.215.107.197:8088/proxy/application_1535958417064_0001/
2018-09-03 15:07:20,820-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_1535958417064_0001
2018-09-03 15:07:25,879-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535958417064_0001 running in uber mode : false
2018-09-03 15:07:25,881-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
2018-09-03 15:07:25,897-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535958417064_0001 failed with state FAILED due to: Application application_1535958417064_0001 failed 2 times due to AM Container for appattempt_1535958417064_0001_000002 exited with  exitCode: 1
Failing this attempt.Diagnostics: [2018-09-03 15:07:24.843]Exception from container-launch.
Container id: container_1535958417064_0001_02_000001
Exit code: 1

[2018-09-03 15:07:24.849]Container exited with a non-zero exit code 1. Error file: prelaunch.err.
Last 4096 bytes of prelaunch.err :
Last 4096 bytes of stderr :
错误: 找不到或无法加载主类 org.apache.hadoop.mapreduce.v2.app.MRAppMaster


[2018-09-03 15:07:24.849]Container exited with a non-zero exit code 1. Error file: prelaunch.err.
Last 4096 bytes of prelaunch.err :
Last 4096 bytes of stderr :
错误: 找不到或无法加载主类 org.apache.hadoop.mapreduce.v2.app.MRAppMaster


For more detailed output, check the application tracking page: http://10.215.107.197:8088/cluster/app/application_1535958417064_0001 Then click on links to logs of each attempt.
. Failing the application.
2018-09-03 15:07:25,920-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
2018-09-03 15:22:17,846-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 15:22:19,112-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-09-03 15:22:20,553-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-03 15:22:21,558-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-03 15:22:22,564-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-03 15:22:23,566-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-03 15:22:24,571-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-03 15:22:25,574-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-03 15:22:26,580-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-03 15:22:27,585-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-03 15:22:28,588-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-03 15:22:29,590-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-03 15:22:30,609-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-09-03 15:30:05,855-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 15:30:07,286-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-09-03 15:30:07,916-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 15:30:07,929-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 15:30:08,039-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 15:30:08,106-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 15:30:08,181-[TS] INFO main org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-09-03 15:30:08,302-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1535959783708_0001
2018-09-03 15:30:08,303-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 15:30:08,454-[TS] INFO main org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.
2018-09-03 15:30:08,497-[TS] INFO main org.apache.hadoop.conf.Configuration - resource-types.xml not found
2018-09-03 15:30:08,497-[TS] INFO main org.apache.hadoop.yarn.util.resource.ResourceUtils - Unable to find 'resource-types.xml'.
2018-09-03 15:30:08,749-[TS] INFO main org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1535959783708_0001
2018-09-03 15:30:08,786-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://10.215.107.197:8088/proxy/application_1535959783708_0001/
2018-09-03 15:30:08,787-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_1535959783708_0001
2018-09-03 15:30:17,952-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535959783708_0001 running in uber mode : false
2018-09-03 15:30:17,956-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
2018-09-03 15:30:20,010-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535959783708_0001_m_000000_0, Status : FAILED
2018-09-03 15:30:21,039-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535959783708_0001_m_000001_0, Status : FAILED
2018-09-03 15:30:22,051-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535959783708_0001_m_000000_1, Status : FAILED
2018-09-03 15:30:23,061-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535959783708_0001_m_000001_1, Status : FAILED
2018-09-03 15:30:25,088-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535959783708_0001_m_000000_2, Status : FAILED
2018-09-03 15:30:26,107-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535959783708_0001_m_000001_2, Status : FAILED
2018-09-03 15:30:28,123-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 15:30:29,138-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535959783708_0001 failed with state FAILED due to: Task failed task_1535959783708_0001_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2018-09-03 15:30:29,234-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 11
	Job Counters 
		Failed map tasks=7
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=7
		Other local map tasks=5
		Rack-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=12
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=12
		Total vcore-milliseconds taken by all map tasks=12
		Total megabyte-milliseconds taken by all map tasks=12288
2018-09-03 15:32:22,198-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 15:32:23,564-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-09-03 15:32:48,837-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 15:32:49,891-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-09-03 15:32:50,535-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 15:32:50,548-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 15:32:50,633-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 15:32:50,698-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 15:32:50,744-[TS] INFO main org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-09-03 15:32:50,902-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1535959783708_0002
2018-09-03 15:32:50,903-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 15:32:51,050-[TS] INFO main org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.
2018-09-03 15:32:51,090-[TS] INFO main org.apache.hadoop.conf.Configuration - resource-types.xml not found
2018-09-03 15:32:51,091-[TS] INFO main org.apache.hadoop.yarn.util.resource.ResourceUtils - Unable to find 'resource-types.xml'.
2018-09-03 15:32:51,165-[TS] INFO main org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1535959783708_0002
2018-09-03 15:32:51,198-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://10.215.107.197:8088/proxy/application_1535959783708_0002/
2018-09-03 15:32:51,199-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_1535959783708_0002
2018-09-03 15:32:59,345-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535959783708_0002 running in uber mode : false
2018-09-03 15:32:59,354-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
2018-09-03 15:33:01,416-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535959783708_0002_m_000000_0, Status : FAILED
2018-09-03 15:33:02,443-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535959783708_0002_m_000001_0, Status : FAILED
2018-09-03 15:33:03,451-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535959783708_0002_m_000000_1, Status : FAILED
2018-09-03 15:33:04,461-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535959783708_0002_m_000001_1, Status : FAILED
2018-09-03 15:33:06,483-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535959783708_0002_m_000000_2, Status : FAILED
2018-09-03 15:33:07,494-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535959783708_0002_m_000001_2, Status : FAILED
2018-09-03 15:33:09,517-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 15:33:10,532-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535959783708_0002 failed with state FAILED due to: Task failed task_1535959783708_0002_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2018-09-03 15:33:10,601-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 11
	Job Counters 
		Failed map tasks=7
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=7
		Other local map tasks=5
		Rack-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=13
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=13
		Total vcore-milliseconds taken by all map tasks=13
		Total megabyte-milliseconds taken by all map tasks=13312
2018-09-03 15:36:48,393-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 15:36:49,736-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-09-03 15:37:03,392-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 15:37:04,686-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-09-03 15:37:05,278-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 15:37:05,298-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 15:37:05,397-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 15:37:05,464-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 15:37:05,515-[TS] INFO main org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-09-03 15:37:05,618-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1535960158413_0001
2018-09-03 15:37:05,619-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 15:37:05,797-[TS] INFO main org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.
2018-09-03 15:37:05,845-[TS] INFO main org.apache.hadoop.conf.Configuration - resource-types.xml not found
2018-09-03 15:37:05,845-[TS] INFO main org.apache.hadoop.yarn.util.resource.ResourceUtils - Unable to find 'resource-types.xml'.
2018-09-03 15:37:06,234-[TS] INFO main org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1535960158413_0001
2018-09-03 15:37:06,292-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://10.215.107.197:8088/proxy/application_1535960158413_0001/
2018-09-03 15:37:06,293-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_1535960158413_0001
2018-09-03 15:37:15,430-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535960158413_0001 running in uber mode : false
2018-09-03 15:37:15,437-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
2018-09-03 15:37:22,558-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0001_m_000000_0, Status : FAILED
2018-09-03 15:37:22,592-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0001_m_000001_0, Status : FAILED
2018-09-03 15:37:26,639-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0001_m_000000_1, Status : FAILED
2018-09-03 15:37:27,650-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0001_m_000001_1, Status : FAILED
2018-09-03 15:37:33,702-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0001_m_000000_2, Status : FAILED
2018-09-03 15:37:34,713-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0001_m_000001_2, Status : FAILED
2018-09-03 15:37:40,762-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 15:37:41,781-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535960158413_0001 failed with state FAILED due to: Task failed task_1535960158413_0001_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2018-09-03 15:37:41,859-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 14
	Job Counters 
		Failed map tasks=7
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=8
		Other local map tasks=6
		Rack-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=32176
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=32176
		Total vcore-milliseconds taken by all map tasks=32176
		Total megabyte-milliseconds taken by all map tasks=32948224
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
2018-09-03 15:43:18,360-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 15:43:19,768-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-09-03 15:50:36,061-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 15:50:43,507-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-09-03 15:50:44,383-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 15:50:44,690-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 15:50:44,800-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 15:50:44,878-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 15:50:44,948-[TS] INFO main org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-09-03 15:50:45,081-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1535960158413_0002
2018-09-03 15:50:45,088-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 15:50:45,313-[TS] INFO main org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.
2018-09-03 15:50:45,370-[TS] INFO main org.apache.hadoop.conf.Configuration - resource-types.xml not found
2018-09-03 15:50:45,370-[TS] INFO main org.apache.hadoop.yarn.util.resource.ResourceUtils - Unable to find 'resource-types.xml'.
2018-09-03 15:50:45,602-[TS] INFO main org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1535960158413_0002
2018-09-03 15:50:45,673-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://10.215.107.197:8088/proxy/application_1535960158413_0002/
2018-09-03 15:50:45,673-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_1535960158413_0002
2018-09-03 15:50:53,944-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535960158413_0002 running in uber mode : false
2018-09-03 15:50:53,947-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
2018-09-03 15:51:00,074-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0002_m_000000_0, Status : FAILED
2018-09-03 15:51:01,108-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0002_m_000001_0, Status : FAILED
2018-09-03 15:51:07,168-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0002_m_000000_1, Status : FAILED
2018-09-03 15:51:07,171-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0002_m_000001_1, Status : FAILED
2018-09-03 15:51:13,224-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0002_m_000000_2, Status : FAILED
2018-09-03 15:51:14,232-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0002_m_000001_2, Status : FAILED
2018-09-03 15:51:19,275-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 15:51:19,283-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535960158413_0002 failed with state FAILED due to: Task failed task_1535960158413_0002_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2018-09-03 15:51:19,355-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 14
	Job Counters 
		Failed map tasks=7
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=8
		Other local map tasks=6
		Rack-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=30733
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=30733
		Total vcore-milliseconds taken by all map tasks=30733
		Total megabyte-milliseconds taken by all map tasks=31470592
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
2018-09-03 15:52:58,255-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 15:52:59,570-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-09-03 15:53:00,172-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 15:53:00,185-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 15:53:00,271-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 15:53:00,326-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 15:53:00,368-[TS] INFO main org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-09-03 15:53:00,486-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1535960158413_0003
2018-09-03 15:53:00,488-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 15:53:00,626-[TS] INFO main org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.
2018-09-03 15:53:00,665-[TS] INFO main org.apache.hadoop.conf.Configuration - resource-types.xml not found
2018-09-03 15:53:00,665-[TS] INFO main org.apache.hadoop.yarn.util.resource.ResourceUtils - Unable to find 'resource-types.xml'.
2018-09-03 15:53:00,745-[TS] INFO main org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1535960158413_0003
2018-09-03 15:53:00,785-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://10.215.107.197:8088/proxy/application_1535960158413_0003/
2018-09-03 15:53:00,786-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_1535960158413_0003
2018-09-03 15:53:06,894-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535960158413_0003 running in uber mode : false
2018-09-03 15:53:06,899-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
2018-09-03 15:53:14,009-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0003_m_000000_0, Status : FAILED
2018-09-03 15:53:15,045-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0003_m_000001_0, Status : FAILED
2018-09-03 15:53:20,091-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0003_m_000000_1, Status : FAILED
2018-09-03 15:53:21,099-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0003_m_000001_1, Status : FAILED
2018-09-03 15:53:25,128-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0003_m_000000_2, Status : FAILED
2018-09-03 15:53:26,143-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0003_m_000001_2, Status : FAILED
2018-09-03 15:53:32,188-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 15:53:32,197-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535960158413_0003 failed with state FAILED due to: Task failed task_1535960158413_0003_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2018-09-03 15:53:32,276-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 14
	Job Counters 
		Failed map tasks=7
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=8
		Other local map tasks=6
		Rack-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=28816
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=28816
		Total vcore-milliseconds taken by all map tasks=28816
		Total megabyte-milliseconds taken by all map tasks=29507584
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
2018-09-03 15:55:22,815-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 15:55:24,407-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-09-03 15:55:36,406-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 15:55:37,637-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-09-03 15:55:38,127-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 15:55:38,143-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 15:55:38,233-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 15:55:38,297-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 15:55:38,343-[TS] INFO main org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-09-03 15:55:38,447-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1535960158413_0004
2018-09-03 15:55:38,448-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 15:55:38,579-[TS] INFO main org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.
2018-09-03 15:55:38,617-[TS] INFO main org.apache.hadoop.conf.Configuration - resource-types.xml not found
2018-09-03 15:55:38,617-[TS] INFO main org.apache.hadoop.yarn.util.resource.ResourceUtils - Unable to find 'resource-types.xml'.
2018-09-03 15:55:38,691-[TS] INFO main org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1535960158413_0004
2018-09-03 15:55:38,732-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://10.215.107.197:8088/proxy/application_1535960158413_0004/
2018-09-03 15:55:38,733-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_1535960158413_0004
2018-09-03 15:55:45,877-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535960158413_0004 running in uber mode : false
2018-09-03 15:55:45,882-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
2018-09-03 15:55:51,966-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0004_m_000000_0, Status : FAILED
2018-09-03 15:55:51,989-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0004_m_000001_0, Status : FAILED
2018-09-03 15:55:56,028-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0004_m_000000_1, Status : FAILED
2018-09-03 15:55:57,041-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0004_m_000001_1, Status : FAILED
2018-09-03 15:56:02,085-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0004_m_000000_2, Status : FAILED
2018-09-03 15:56:03,094-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0004_m_000001_2, Status : FAILED
2018-09-03 15:58:39,225-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 15:58:40,957-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 15:58:41,056-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 15:58:41,056-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 15:58:41,352-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 15:58:41,363-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 15:58:41,454-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 15:58:41,509-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 15:58:41,637-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1430671377_0001
2018-09-03 15:58:41,638-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 15:58:41,757-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 15:58:41,758-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1430671377_0001
2018-09-03 15:58:41,759-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 15:58:41,766-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 15:58:41,766-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 15:58:41,767-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 15:58:41,809-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 15:58:41,809-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1430671377_0001_m_000000_0
2018-09-03 15:58:41,835-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 15:58:41,835-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 15:58:41,847-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 15:58:41,848-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 15:58:41,851-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t2.txt:0+58
2018-09-03 15:58:41,977-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 15:58:41,978-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 15:58:41,978-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 15:58:41,978-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 15:58:41,978-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 15:58:41,983-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 15:58:42,103-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 15:58:42,106-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 15:58:42,106-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 15:58:42,106-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-09-03 15:58:42,106-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 15:58:42,127-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 15:58:42,143-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1430671377_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 15:58:42,146-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 15:58:42,147-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1430671377_0001_m_000000_0' done.
2018-09-03 15:58:42,155-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1430671377_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=299
		FILE: Number of bytes written=500786
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=76
		Input split bytes=112
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=232783872
	File Input Format Counters 
		Bytes Read=58
2018-09-03 15:58:42,155-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1430671377_0001_m_000000_0
2018-09-03 15:58:42,155-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1430671377_0001_m_000001_0
2018-09-03 15:58:42,157-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 15:58:42,157-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 15:58:42,158-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 15:58:42,158-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 15:58:42,160-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t1.txt:0+50
2018-09-03 15:58:42,302-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 15:58:42,302-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 15:58:42,302-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 15:58:42,302-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 15:58:42,302-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 15:58:42,303-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 15:58:42,334-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 15:58:42,335-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 15:58:42,335-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 15:58:42,335-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-09-03 15:58:42,335-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 15:58:42,347-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 15:58:42,354-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1430671377_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 15:58:42,357-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 15:58:42,357-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1430671377_0001_m_000001_0' done.
2018-09-03 15:58:42,359-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1430671377_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=542
		FILE: Number of bytes written=500884
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=66
		Input split bytes=112
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=338165760
	File Input Format Counters 
		Bytes Read=50
2018-09-03 15:58:42,359-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1430671377_0001_m_000001_0
2018-09-03 15:58:42,359-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 15:58:42,361-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 15:58:42,361-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1430671377_0001_r_000000_0
2018-09-03 15:58:42,367-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 15:58:42,368-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 15:58:42,369-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 15:58:42,369-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 15:58:42,373-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4cef49eb
2018-09-03 15:58:42,375-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 15:58:42,390-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 15:58:42,393-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1430671377_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 15:58:42,431-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1430671377_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2018-09-03 15:58:42,433-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local1430671377_0001_m_000001_0
2018-09-03 15:58:42,434-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->62
2018-09-03 15:58:42,437-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1430671377_0001_m_000000_0 decomp: 72 len: 76 to MEMORY
2018-09-03 15:58:42,438-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 72 bytes from map-output for attempt_local1430671377_0001_m_000000_0
2018-09-03 15:58:42,438-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 72, inMemoryMapOutputs.size() -> 2, commitMemory -> 62, usedMemory ->134
2018-09-03 15:58:42,438-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 15:58:42,439-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 15:58:42,439-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 15:58:42,450-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 15:58:42,451-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 114 bytes
2018-09-03 15:58:42,457-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 134 bytes to disk to satisfy reduce memory limit
2018-09-03 15:58:42,458-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 136 bytes from disk
2018-09-03 15:58:42,458-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 15:58:42,458-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 15:58:42,459-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 122 bytes
2018-09-03 15:58:42,459-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 15:58:42,506-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 15:58:42,585-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1430671377_0001_r_000000_0 is done. And is in the process of committing
2018-09-03 15:58:42,587-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 15:58:42,587-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1430671377_0001_r_000000_0 is allowed to commit now
2018-09-03 15:58:42,605-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1430671377_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/output_6
2018-09-03 15:58:42,606-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 15:58:42,606-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1430671377_0001_r_000000_0' done.
2018-09-03 15:58:42,607-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1430671377_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=884
		FILE: Number of bytes written=501020
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=142
		Reduce input records=13
		Reduce output records=10
		Spilled Records=13
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=338165760
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=84
2018-09-03 15:58:42,607-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1430671377_0001_r_000000_0
2018-09-03 15:58:42,607-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 15:58:42,766-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1430671377_0001 running in uber mode : false
2018-09-03 15:58:42,767-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 15:58:42,768-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1430671377_0001 completed successfully
2018-09-03 15:58:42,775-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=1725
		FILE: Number of bytes written=1502690
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=274
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=142
		Input split bytes=224
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=142
		Reduce input records=13
		Reduce output records=10
		Spilled Records=26
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=909115392
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=84
2018-09-03 16:00:05,569-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 16:00:06,961-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 16:00:07,032-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 16:00:07,032-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 16:00:07,343-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 16:00:07,358-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 16:00:07,432-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 16:00:07,486-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 16:00:07,625-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1077922284_0001
2018-09-03 16:00:07,627-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 16:00:07,767-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 16:00:07,768-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1077922284_0001
2018-09-03 16:00:07,768-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 16:00:07,773-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:00:07,773-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:00:07,773-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 16:00:07,805-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 16:00:07,805-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1077922284_0001_m_000000_0
2018-09-03 16:00:07,822-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:00:07,822-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:00:07,832-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 16:00:07,833-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 16:00:07,836-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t2.txt:0+58
2018-09-03 16:00:07,980-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 16:00:07,982-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 16:00:07,983-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 16:00:07,983-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 16:00:07,984-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 16:00:07,988-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 16:00:08,090-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 16:00:08,093-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 16:00:08,093-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 16:00:08,093-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-09-03 16:00:08,094-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 16:00:08,118-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 16:00:08,135-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1077922284_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 16:00:08,138-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 16:00:08,138-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1077922284_0001_m_000000_0' done.
2018-09-03 16:00:08,148-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1077922284_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=299
		FILE: Number of bytes written=500786
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=76
		Input split bytes=112
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=279445504
	File Input Format Counters 
		Bytes Read=58
2018-09-03 16:00:08,148-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1077922284_0001_m_000000_0
2018-09-03 16:00:08,149-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1077922284_0001_m_000001_0
2018-09-03 16:00:08,151-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:00:08,151-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:00:08,151-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 16:00:08,151-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 16:00:08,153-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t1.txt:0+50
2018-09-03 16:00:08,265-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 16:00:08,265-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 16:00:08,265-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 16:00:08,265-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 16:00:08,266-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 16:00:08,266-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 16:00:08,290-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 16:00:08,290-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 16:00:08,290-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 16:00:08,290-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-09-03 16:00:08,290-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 16:00:08,303-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 16:00:08,310-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1077922284_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 16:00:08,312-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 16:00:08,312-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1077922284_0001_m_000001_0' done.
2018-09-03 16:00:08,313-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1077922284_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=542
		FILE: Number of bytes written=500884
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=66
		Input split bytes=112
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=384827392
	File Input Format Counters 
		Bytes Read=50
2018-09-03 16:00:08,313-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1077922284_0001_m_000001_0
2018-09-03 16:00:08,313-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 16:00:08,316-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 16:00:08,317-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1077922284_0001_r_000000_0
2018-09-03 16:00:08,322-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:00:08,322-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:00:08,322-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 16:00:08,323-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 16:00:08,325-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@87ba8d3
2018-09-03 16:00:08,326-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 16:00:08,340-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 16:00:08,343-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1077922284_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 16:00:08,364-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1077922284_0001_m_000000_0 decomp: 72 len: 76 to MEMORY
2018-09-03 16:00:08,368-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 72 bytes from map-output for attempt_local1077922284_0001_m_000000_0
2018-09-03 16:00:08,369-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 72, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->72
2018-09-03 16:00:08,371-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1077922284_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2018-09-03 16:00:08,371-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local1077922284_0001_m_000001_0
2018-09-03 16:00:08,371-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 72, usedMemory ->134
2018-09-03 16:00:08,372-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 16:00:08,372-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:00:08,373-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 16:00:08,385-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 16:00:08,386-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 114 bytes
2018-09-03 16:00:08,392-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 134 bytes to disk to satisfy reduce memory limit
2018-09-03 16:00:08,392-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 136 bytes from disk
2018-09-03 16:00:08,393-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 16:00:08,393-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 16:00:08,393-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 122 bytes
2018-09-03 16:00:08,394-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:00:08,431-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 16:00:08,491-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1077922284_0001_r_000000_0 is done. And is in the process of committing
2018-09-03 16:00:08,492-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:00:08,493-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1077922284_0001_r_000000_0 is allowed to commit now
2018-09-03 16:00:08,499-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1077922284_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/output_7
2018-09-03 16:00:08,500-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 16:00:08,500-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1077922284_0001_r_000000_0' done.
2018-09-03 16:00:08,501-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1077922284_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=884
		FILE: Number of bytes written=501020
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=142
		Reduce input records=13
		Reduce output records=10
		Spilled Records=13
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=384827392
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=84
2018-09-03 16:00:08,501-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1077922284_0001_r_000000_0
2018-09-03 16:00:08,501-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 16:00:08,772-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1077922284_0001 running in uber mode : false
2018-09-03 16:00:08,773-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 16:00:08,774-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1077922284_0001 completed successfully
2018-09-03 16:00:08,780-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=1725
		FILE: Number of bytes written=1502690
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=274
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=142
		Input split bytes=224
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=142
		Reduce input records=13
		Reduce output records=10
		Spilled Records=26
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1049100288
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=84
2018-09-03 16:07:39,013-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 16:07:40,719-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-09-03 16:07:52,934-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 16:07:54,099-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-09-03 16:07:54,719-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 16:07:54,733-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 16:07:54,826-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 16:07:54,884-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 16:07:54,938-[TS] INFO main org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-09-03 16:07:55,098-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1535960158413_0005
2018-09-03 16:07:55,100-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 16:07:55,312-[TS] INFO main org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.
2018-09-03 16:07:55,354-[TS] INFO main org.apache.hadoop.conf.Configuration - resource-types.xml not found
2018-09-03 16:07:55,354-[TS] INFO main org.apache.hadoop.yarn.util.resource.ResourceUtils - Unable to find 'resource-types.xml'.
2018-09-03 16:07:55,683-[TS] INFO main org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1535960158413_0005
2018-09-03 16:07:55,734-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://10.215.107.197:8088/proxy/application_1535960158413_0005/
2018-09-03 16:07:55,735-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_1535960158413_0005
2018-09-03 16:08:04,924-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535960158413_0005 running in uber mode : false
2018-09-03 16:08:04,926-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
2018-09-03 16:08:11,003-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0005_m_000000_0, Status : FAILED
2018-09-03 16:08:12,029-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0005_m_000001_0, Status : FAILED
2018-09-03 16:08:16,066-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0005_m_000000_1, Status : FAILED
2018-09-03 16:08:17,078-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0005_m_000001_1, Status : FAILED
2018-09-03 16:08:22,123-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0005_m_000000_2, Status : FAILED
2018-09-03 16:08:23,132-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0005_m_000001_2, Status : FAILED
2018-09-03 16:08:28,170-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 16:08:28,181-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535960158413_0005 failed with state FAILED due to: Task failed task_1535960158413_0005_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2018-09-03 16:08:28,288-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 14
	Job Counters 
		Failed map tasks=7
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=8
		Other local map tasks=6
		Rack-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=26799
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=26799
		Total vcore-milliseconds taken by all map tasks=26799
		Total megabyte-milliseconds taken by all map tasks=27442176
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
2018-09-03 16:13:28,084-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 16:13:29,676-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-09-03 16:13:30,304-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 16:13:30,318-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 16:13:30,415-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 16:13:30,473-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 16:13:30,523-[TS] INFO main org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-09-03 16:13:30,675-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1535960158413_0006
2018-09-03 16:13:30,677-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 16:13:30,849-[TS] INFO main org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.
2018-09-03 16:13:30,885-[TS] INFO main org.apache.hadoop.conf.Configuration - resource-types.xml not found
2018-09-03 16:13:30,885-[TS] INFO main org.apache.hadoop.yarn.util.resource.ResourceUtils - Unable to find 'resource-types.xml'.
2018-09-03 16:13:30,960-[TS] INFO main org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1535960158413_0006
2018-09-03 16:13:31,011-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://10.215.107.197:8088/proxy/application_1535960158413_0006/
2018-09-03 16:13:31,013-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_1535960158413_0006
2018-09-03 16:13:38,219-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535960158413_0006 running in uber mode : false
2018-09-03 16:13:38,222-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
2018-09-03 16:13:45,334-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0006_m_000000_0, Status : FAILED
2018-09-03 16:13:46,363-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0006_m_000001_0, Status : FAILED
2018-09-03 16:13:51,401-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0006_m_000000_1, Status : FAILED
2018-09-03 16:13:52,412-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0006_m_000001_1, Status : FAILED
2018-09-03 16:13:57,468-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0006_m_000000_2, Status : FAILED
2018-09-03 16:13:58,477-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0006_m_000001_2, Status : FAILED
2018-09-03 16:14:03,509-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 16:14:04,528-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535960158413_0006 failed with state FAILED due to: Task failed task_1535960158413_0006_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2018-09-03 16:14:04,639-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 14
	Job Counters 
		Failed map tasks=7
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=8
		Other local map tasks=6
		Rack-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=30499
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=30499
		Total vcore-milliseconds taken by all map tasks=30499
		Total megabyte-milliseconds taken by all map tasks=31230976
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
2018-09-03 16:19:57,118-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 16:19:58,548-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-09-03 16:19:59,280-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 16:19:59,302-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 16:19:59,425-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 16:19:59,520-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 16:19:59,583-[TS] INFO main org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-09-03 16:19:59,721-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1535960158413_0007
2018-09-03 16:19:59,724-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 16:19:59,972-[TS] INFO main org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.
2018-09-03 16:20:00,019-[TS] INFO main org.apache.hadoop.conf.Configuration - resource-types.xml not found
2018-09-03 16:20:00,020-[TS] INFO main org.apache.hadoop.yarn.util.resource.ResourceUtils - Unable to find 'resource-types.xml'.
2018-09-03 16:20:00,146-[TS] INFO main org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1535960158413_0007
2018-09-03 16:20:00,211-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://10.215.107.197:8088/proxy/application_1535960158413_0007/
2018-09-03 16:20:00,212-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_1535960158413_0007
2018-09-03 16:20:09,441-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535960158413_0007 running in uber mode : false
2018-09-03 16:20:09,445-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
2018-09-03 16:20:16,554-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0007_m_000000_0, Status : FAILED
2018-09-03 16:20:17,577-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0007_m_000001_0, Status : FAILED
2018-09-03 16:20:22,643-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0007_m_000000_1, Status : FAILED
2018-09-03 16:20:23,652-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0007_m_000001_1, Status : FAILED
2018-09-03 16:20:28,703-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0007_m_000000_2, Status : FAILED
2018-09-03 16:20:29,715-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0007_m_000001_2, Status : FAILED
2018-09-03 16:20:34,751-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 16:20:35,769-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535960158413_0007 failed with state FAILED due to: Task failed task_1535960158413_0007_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2018-09-03 16:20:35,844-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 14
	Job Counters 
		Failed map tasks=7
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=8
		Other local map tasks=6
		Rack-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=32799
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=32799
		Total vcore-milliseconds taken by all map tasks=32799
		Total megabyte-milliseconds taken by all map tasks=33586176
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
2018-09-03 16:21:28,823-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 16:21:31,054-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-09-03 16:21:31,910-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 16:21:31,923-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 16:21:32,010-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 16:21:32,065-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 16:21:32,109-[TS] INFO main org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-09-03 16:21:32,222-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1535960158413_0008
2018-09-03 16:21:32,224-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 16:21:32,418-[TS] INFO main org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.
2018-09-03 16:21:32,481-[TS] INFO main org.apache.hadoop.conf.Configuration - resource-types.xml not found
2018-09-03 16:21:32,481-[TS] INFO main org.apache.hadoop.yarn.util.resource.ResourceUtils - Unable to find 'resource-types.xml'.
2018-09-03 16:21:32,610-[TS] INFO main org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1535960158413_0008
2018-09-03 16:21:32,653-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://10.215.107.197:8088/proxy/application_1535960158413_0008/
2018-09-03 16:21:32,653-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_1535960158413_0008
2018-09-03 16:21:41,876-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535960158413_0008 running in uber mode : false
2018-09-03 16:21:41,878-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
2018-09-03 16:21:50,003-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0008_m_000000_0, Status : FAILED
2018-09-03 16:21:51,032-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0008_m_000001_0, Status : FAILED
2018-09-03 16:21:55,064-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0008_m_000000_1, Status : FAILED
2018-09-03 16:21:56,076-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0008_m_000001_1, Status : FAILED
2018-09-03 16:22:06,152-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0008_m_000000_2, Status : FAILED
2018-09-03 16:22:06,157-[TS] INFO main org.apache.hadoop.mapreduce.Job - Task Id : attempt_1535960158413_0008_m_000001_2, Status : FAILED
2018-09-03 16:22:12,212-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 16:22:13,234-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1535960158413_0008 failed with state FAILED due to: Task failed task_1535960158413_0008_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2018-09-03 16:22:13,355-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 14
	Job Counters 
		Failed map tasks=7
		Killed map tasks=1
		Killed reduce tasks=1
		Launched map tasks=8
		Other local map tasks=6
		Rack-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=41804
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=41804
		Total vcore-milliseconds taken by all map tasks=41804
		Total megabyte-milliseconds taken by all map tasks=42807296
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
2018-09-03 16:28:58,720-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 16:29:00,245-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 16:29:00,307-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 16:29:00,307-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 16:29:00,630-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 16:29:00,642-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 16:29:00,727-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 16:29:00,789-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 16:29:00,944-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local764463337_0001
2018-09-03 16:29:00,946-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 16:29:01,111-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 16:29:01,111-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local764463337_0001
2018-09-03 16:29:01,112-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 16:29:01,117-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:29:01,117-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:29:01,118-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 16:29:01,155-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 16:29:01,156-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local764463337_0001_m_000000_0
2018-09-03 16:29:01,180-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:29:01,180-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:29:01,191-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 16:29:01,191-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 16:29:01,194-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t2.txt:0+58
2018-09-03 16:29:01,310-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 16:29:01,311-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 16:29:01,311-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 16:29:01,311-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 16:29:01,311-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 16:29:01,321-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 16:29:01,426-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 16:29:01,432-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 16:29:01,432-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 16:29:01,433-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-09-03 16:29:01,433-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 16:29:01,457-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 16:29:01,474-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local764463337_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 16:29:01,477-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 16:29:01,477-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local764463337_0001_m_000000_0' done.
2018-09-03 16:29:01,484-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local764463337_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=299
		FILE: Number of bytes written=498382
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=76
		Input split bytes=112
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=278921216
	File Input Format Counters 
		Bytes Read=58
2018-09-03 16:29:01,484-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local764463337_0001_m_000000_0
2018-09-03 16:29:01,484-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local764463337_0001_m_000001_0
2018-09-03 16:29:01,486-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:29:01,486-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:29:01,486-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 16:29:01,486-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 16:29:01,488-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t1.txt:0+50
2018-09-03 16:29:01,662-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 16:29:01,662-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 16:29:01,662-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 16:29:01,662-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 16:29:01,662-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 16:29:01,663-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 16:29:01,679-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 16:29:01,679-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 16:29:01,679-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 16:29:01,679-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-09-03 16:29:01,679-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 16:29:01,691-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 16:29:01,721-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local764463337_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 16:29:01,724-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 16:29:01,725-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local764463337_0001_m_000001_0' done.
2018-09-03 16:29:01,725-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local764463337_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=542
		FILE: Number of bytes written=498480
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=66
		Input split bytes=112
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=384303104
	File Input Format Counters 
		Bytes Read=50
2018-09-03 16:29:01,725-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local764463337_0001_m_000001_0
2018-09-03 16:29:01,726-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 16:29:01,728-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 16:29:01,728-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local764463337_0001_r_000000_0
2018-09-03 16:29:01,736-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:29:01,736-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:29:01,737-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 16:29:01,737-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 16:29:01,739-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@26a881b5
2018-09-03 16:29:01,741-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 16:29:01,756-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 16:29:01,758-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local764463337_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 16:29:01,783-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local764463337_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2018-09-03 16:29:01,786-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local764463337_0001_m_000001_0
2018-09-03 16:29:01,787-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->62
2018-09-03 16:29:01,789-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local764463337_0001_m_000000_0 decomp: 72 len: 76 to MEMORY
2018-09-03 16:29:01,790-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 72 bytes from map-output for attempt_local764463337_0001_m_000000_0
2018-09-03 16:29:01,790-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 72, inMemoryMapOutputs.size() -> 2, commitMemory -> 62, usedMemory ->134
2018-09-03 16:29:01,791-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 16:29:01,791-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:29:01,792-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 16:29:01,804-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 16:29:01,804-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 114 bytes
2018-09-03 16:29:01,818-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 134 bytes to disk to satisfy reduce memory limit
2018-09-03 16:29:01,818-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 136 bytes from disk
2018-09-03 16:29:01,819-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 16:29:01,819-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 16:29:01,820-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 122 bytes
2018-09-03 16:29:01,821-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:29:01,852-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 16:29:01,942-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local764463337_0001_r_000000_0 is done. And is in the process of committing
2018-09-03 16:29:01,945-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:29:01,945-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local764463337_0001_r_000000_0 is allowed to commit now
2018-09-03 16:29:01,963-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local764463337_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/output_13
2018-09-03 16:29:01,965-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 16:29:01,965-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local764463337_0001_r_000000_0' done.
2018-09-03 16:29:01,966-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local764463337_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=884
		FILE: Number of bytes written=498616
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=142
		Reduce input records=13
		Reduce output records=10
		Spilled Records=13
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=384303104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=84
2018-09-03 16:29:01,966-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local764463337_0001_r_000000_0
2018-09-03 16:29:01,967-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 16:29:02,119-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local764463337_0001 running in uber mode : false
2018-09-03 16:29:02,120-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 16:29:02,121-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local764463337_0001 completed successfully
2018-09-03 16:29:02,128-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=1725
		FILE: Number of bytes written=1495478
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=274
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=142
		Input split bytes=224
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=142
		Reduce input records=13
		Reduce output records=10
		Spilled Records=26
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1047527424
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=84
2018-09-03 16:31:03,656-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 16:31:04,961-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 16:31:05,018-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 16:31:05,018-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 16:31:12,603-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 16:31:13,939-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 16:31:14,008-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 16:31:14,008-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 16:31:14,374-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 16:31:14,386-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 16:31:14,513-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 16:31:14,568-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 16:31:14,718-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1729296756_0001
2018-09-03 16:31:14,720-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 16:31:14,872-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 16:31:14,876-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 16:31:14,876-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1729296756_0001
2018-09-03 16:31:14,878-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:31:14,878-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:31:14,879-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 16:31:14,915-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 16:31:14,916-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1729296756_0001_m_000000_0
2018-09-03 16:31:14,933-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:31:14,933-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:31:14,943-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 16:31:14,944-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 16:31:14,946-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t2.txt:0+58
2018-09-03 16:31:15,040-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 16:31:15,040-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 16:31:15,040-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 16:31:15,041-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 16:31:15,041-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 16:31:15,044-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 16:31:15,145-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 16:31:15,148-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 16:31:15,148-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 16:31:15,148-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-09-03 16:31:15,148-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 16:31:15,167-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 16:31:15,180-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1729296756_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 16:31:15,182-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 16:31:15,183-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1729296756_0001_m_000000_0' done.
2018-09-03 16:31:15,192-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1729296756_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=299
		FILE: Number of bytes written=501217
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=76
		Input split bytes=112
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=278396928
	File Input Format Counters 
		Bytes Read=58
2018-09-03 16:31:15,192-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1729296756_0001_m_000000_0
2018-09-03 16:31:15,193-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1729296756_0001_m_000001_0
2018-09-03 16:31:15,194-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:31:15,194-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:31:15,194-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 16:31:15,195-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 16:31:15,196-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t1.txt:0+50
2018-09-03 16:31:15,332-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 16:31:15,332-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 16:31:15,332-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 16:31:15,332-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 16:31:15,332-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 16:31:15,333-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 16:31:15,353-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 16:31:15,353-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 16:31:15,353-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 16:31:15,353-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-09-03 16:31:15,353-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 16:31:15,366-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 16:31:15,374-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1729296756_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 16:31:15,379-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 16:31:15,379-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1729296756_0001_m_000001_0' done.
2018-09-03 16:31:15,380-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1729296756_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=542
		FILE: Number of bytes written=501315
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=66
		Input split bytes=112
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=383778816
	File Input Format Counters 
		Bytes Read=50
2018-09-03 16:31:15,380-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1729296756_0001_m_000001_0
2018-09-03 16:31:15,380-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 16:31:15,383-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 16:31:15,383-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1729296756_0001_r_000000_0
2018-09-03 16:31:15,389-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:31:15,389-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:31:15,389-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 16:31:15,389-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 16:31:15,391-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@560076aa
2018-09-03 16:31:15,393-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 16:31:15,406-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 16:31:15,408-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1729296756_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 16:31:15,427-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1729296756_0001_m_000000_0 decomp: 72 len: 76 to MEMORY
2018-09-03 16:31:15,430-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 72 bytes from map-output for attempt_local1729296756_0001_m_000000_0
2018-09-03 16:31:15,431-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 72, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->72
2018-09-03 16:31:15,433-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1729296756_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2018-09-03 16:31:15,434-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local1729296756_0001_m_000001_0
2018-09-03 16:31:15,434-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 72, usedMemory ->134
2018-09-03 16:31:15,435-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 16:31:15,436-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:31:15,436-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 16:31:15,447-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 16:31:15,447-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 114 bytes
2018-09-03 16:31:15,458-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 134 bytes to disk to satisfy reduce memory limit
2018-09-03 16:31:15,459-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 136 bytes from disk
2018-09-03 16:31:15,460-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 16:31:15,460-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 16:31:15,461-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 122 bytes
2018-09-03 16:31:15,461-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:31:15,502-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 16:31:15,883-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1729296756_0001 running in uber mode : false
2018-09-03 16:31:15,885-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-09-03 16:31:15,962-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1729296756_0001_r_000000_0 is done. And is in the process of committing
2018-09-03 16:31:15,963-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:31:15,963-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1729296756_0001_r_000000_0 is allowed to commit now
2018-09-03 16:31:15,977-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1729296756_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/output_14
2018-09-03 16:31:15,977-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 16:31:15,977-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1729296756_0001_r_000000_0' done.
2018-09-03 16:31:15,978-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1729296756_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=884
		FILE: Number of bytes written=501451
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=142
		Reduce input records=13
		Reduce output records=10
		Spilled Records=13
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=383778816
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=84
2018-09-03 16:31:15,978-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1729296756_0001_r_000000_0
2018-09-03 16:31:15,978-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 16:31:16,888-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 16:31:16,889-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1729296756_0001 completed successfully
2018-09-03 16:31:16,895-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=1725
		FILE: Number of bytes written=1503983
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=274
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=142
		Input split bytes=224
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=142
		Reduce input records=13
		Reduce output records=10
		Spilled Records=26
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1045954560
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=84
2018-09-03 16:36:39,785-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 16:36:41,241-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 16:36:41,297-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 16:36:41,297-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 16:36:41,607-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 16:36:41,625-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 16:36:41,711-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 16:36:41,770-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 16:36:41,927-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1455693571_0001
2018-09-03 16:36:41,930-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 16:36:42,064-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 16:36:42,065-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 16:36:42,066-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1455693571_0001
2018-09-03 16:36:42,070-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:36:42,071-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:36:42,071-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 16:36:42,106-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 16:36:42,106-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1455693571_0001_m_000000_0
2018-09-03 16:36:42,126-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:36:42,126-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:36:42,141-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 16:36:42,142-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 16:36:42,147-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t2.txt:0+58
2018-09-03 16:36:42,227-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 16:36:42,227-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 16:36:42,227-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 16:36:42,227-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 16:36:42,227-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 16:36:42,230-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 16:36:42,328-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 16:36:42,330-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 16:36:42,330-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 16:36:42,330-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-09-03 16:36:42,330-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 16:36:42,347-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 16:36:42,365-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1455693571_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 16:36:42,368-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 16:36:42,368-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1455693571_0001_m_000000_0' done.
2018-09-03 16:36:42,378-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1455693571_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=299
		FILE: Number of bytes written=501215
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=76
		Input split bytes=112
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=277348352
	File Input Format Counters 
		Bytes Read=58
2018-09-03 16:36:42,379-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1455693571_0001_m_000000_0
2018-09-03 16:36:42,379-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1455693571_0001_m_000001_0
2018-09-03 16:36:42,380-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:36:42,380-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:36:42,381-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 16:36:42,381-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 16:36:42,382-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t1.txt:0+50
2018-09-03 16:36:42,493-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 16:36:42,494-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 16:36:42,494-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 16:36:42,494-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 16:36:42,494-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 16:36:42,495-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 16:36:42,502-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 16:36:42,502-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 16:36:42,503-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 16:36:42,503-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-09-03 16:36:42,503-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 16:36:42,516-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 16:36:42,522-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1455693571_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 16:36:42,524-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 16:36:42,525-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1455693571_0001_m_000001_0' done.
2018-09-03 16:36:42,526-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1455693571_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=542
		FILE: Number of bytes written=501313
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=66
		Input split bytes=112
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=382730240
	File Input Format Counters 
		Bytes Read=50
2018-09-03 16:36:42,526-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1455693571_0001_m_000001_0
2018-09-03 16:36:42,526-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 16:36:42,529-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 16:36:42,530-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1455693571_0001_r_000000_0
2018-09-03 16:36:42,535-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:36:42,535-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:36:42,536-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 16:36:42,536-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 16:36:42,539-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@693182d
2018-09-03 16:36:42,540-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 16:36:42,551-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 16:36:42,553-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1455693571_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 16:36:42,570-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1455693571_0001_m_000000_0 decomp: 72 len: 76 to MEMORY
2018-09-03 16:36:42,573-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 72 bytes from map-output for attempt_local1455693571_0001_m_000000_0
2018-09-03 16:36:42,574-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 72, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->72
2018-09-03 16:36:42,579-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1455693571_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2018-09-03 16:36:42,580-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local1455693571_0001_m_000001_0
2018-09-03 16:36:42,580-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 72, usedMemory ->134
2018-09-03 16:36:42,581-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 16:36:42,581-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:36:42,582-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 16:36:42,595-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 16:36:42,595-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 114 bytes
2018-09-03 16:36:42,601-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 134 bytes to disk to satisfy reduce memory limit
2018-09-03 16:36:42,602-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 136 bytes from disk
2018-09-03 16:36:42,602-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 16:36:42,603-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 16:36:42,603-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 122 bytes
2018-09-03 16:36:42,604-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:36:42,672-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 16:36:43,076-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1455693571_0001 running in uber mode : false
2018-09-03 16:36:43,078-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-09-03 16:36:43,291-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1455693571_0001_r_000000_0 is done. And is in the process of committing
2018-09-03 16:36:43,295-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:36:43,295-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1455693571_0001_r_000000_0 is allowed to commit now
2018-09-03 16:36:43,305-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1455693571_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/output_1
2018-09-03 16:36:43,305-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 16:36:43,305-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1455693571_0001_r_000000_0' done.
2018-09-03 16:36:43,307-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1455693571_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=884
		FILE: Number of bytes written=501449
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=142
		Reduce input records=13
		Reduce output records=10
		Spilled Records=13
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=382730240
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=84
2018-09-03 16:36:43,307-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1455693571_0001_r_000000_0
2018-09-03 16:36:43,307-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 16:36:44,083-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 16:36:44,083-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1455693571_0001 completed successfully
2018-09-03 16:36:44,090-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=1725
		FILE: Number of bytes written=1503977
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=274
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=142
		Input split bytes=224
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=142
		Reduce input records=13
		Reduce output records=10
		Spilled Records=26
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1042808832
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=84
2018-09-03 16:38:23,330-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 16:38:24,717-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 16:38:24,788-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 16:38:24,788-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 16:38:25,115-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 16:38:25,128-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 16:38:25,201-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 16:38:25,254-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 16:38:25,395-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1897135939_0001
2018-09-03 16:38:25,397-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 16:38:25,531-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 16:38:25,531-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1897135939_0001
2018-09-03 16:38:25,532-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 16:38:25,537-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:38:25,538-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:38:25,538-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 16:38:25,571-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 16:38:25,572-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1897135939_0001_m_000000_0
2018-09-03 16:38:25,585-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:38:25,585-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:38:25,596-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 16:38:25,596-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 16:38:25,598-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t2.txt:0+58
2018-09-03 16:38:25,770-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 16:38:25,771-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 16:38:25,771-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 16:38:25,771-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 16:38:25,771-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 16:38:25,775-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 16:38:25,881-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 16:38:25,883-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 16:38:25,883-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 16:38:25,883-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-09-03 16:38:25,883-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 16:38:25,900-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 16:38:25,912-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1897135939_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 16:38:25,914-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 16:38:25,915-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1897135939_0001_m_000000_0' done.
2018-09-03 16:38:25,921-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1897135939_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=299
		FILE: Number of bytes written=501215
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=76
		Input split bytes=112
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=277348352
	File Input Format Counters 
		Bytes Read=58
2018-09-03 16:38:25,921-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1897135939_0001_m_000000_0
2018-09-03 16:38:25,922-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1897135939_0001_m_000001_0
2018-09-03 16:38:25,922-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:38:25,923-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:38:25,923-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 16:38:25,923-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 16:38:25,924-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t1.txt:0+50
2018-09-03 16:38:26,078-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 16:38:26,079-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 16:38:26,080-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 16:38:26,080-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 16:38:26,080-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 16:38:26,083-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 16:38:26,105-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 16:38:26,106-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 16:38:26,106-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 16:38:26,106-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-09-03 16:38:26,106-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 16:38:26,120-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 16:38:26,126-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1897135939_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 16:38:26,128-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 16:38:26,128-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1897135939_0001_m_000001_0' done.
2018-09-03 16:38:26,129-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1897135939_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=542
		FILE: Number of bytes written=501313
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=66
		Input split bytes=112
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=382730240
	File Input Format Counters 
		Bytes Read=50
2018-09-03 16:38:26,129-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1897135939_0001_m_000001_0
2018-09-03 16:38:26,129-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 16:38:26,134-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 16:38:26,135-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1897135939_0001_r_000000_0
2018-09-03 16:38:26,143-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:38:26,144-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:38:26,144-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 16:38:26,144-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 16:38:26,146-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1511428e
2018-09-03 16:38:26,148-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 16:38:26,161-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 16:38:26,163-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1897135939_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 16:38:26,182-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1897135939_0001_m_000000_0 decomp: 72 len: 76 to MEMORY
2018-09-03 16:38:26,185-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 72 bytes from map-output for attempt_local1897135939_0001_m_000000_0
2018-09-03 16:38:26,186-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 72, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->72
2018-09-03 16:38:26,188-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1897135939_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2018-09-03 16:38:26,188-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local1897135939_0001_m_000001_0
2018-09-03 16:38:26,189-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 72, usedMemory ->134
2018-09-03 16:38:26,189-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 16:38:26,189-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:38:26,190-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 16:38:26,200-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 16:38:26,200-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 114 bytes
2018-09-03 16:38:26,205-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 134 bytes to disk to satisfy reduce memory limit
2018-09-03 16:38:26,206-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 136 bytes from disk
2018-09-03 16:38:26,207-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 16:38:26,207-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 16:38:26,207-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 122 bytes
2018-09-03 16:38:26,207-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:38:26,231-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 16:38:26,286-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1897135939_0001_r_000000_0 is done. And is in the process of committing
2018-09-03 16:38:26,293-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:38:26,293-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1897135939_0001_r_000000_0 is allowed to commit now
2018-09-03 16:38:26,304-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1897135939_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/output_2
2018-09-03 16:38:26,305-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 16:38:26,305-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1897135939_0001_r_000000_0' done.
2018-09-03 16:38:26,306-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1897135939_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=884
		FILE: Number of bytes written=501449
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=142
		Reduce input records=13
		Reduce output records=10
		Spilled Records=13
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=382730240
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=84
2018-09-03 16:38:26,306-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1897135939_0001_r_000000_0
2018-09-03 16:38:26,308-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 16:38:26,539-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1897135939_0001 running in uber mode : false
2018-09-03 16:38:26,540-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 16:38:26,541-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1897135939_0001 completed successfully
2018-09-03 16:38:26,549-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=1725
		FILE: Number of bytes written=1503977
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=274
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=142
		Input split bytes=224
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=142
		Reduce input records=13
		Reduce output records=10
		Spilled Records=26
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1042808832
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=84
2018-09-03 16:46:44,221-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 16:46:45,613-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 16:46:45,669-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 16:46:45,669-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 16:46:45,982-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 16:46:45,992-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 16:46:46,069-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 16:46:46,123-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 16:46:46,260-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local32195433_0001
2018-09-03 16:46:46,265-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 16:46:46,414-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 16:46:46,416-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 16:46:46,417-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local32195433_0001
2018-09-03 16:46:46,420-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:46:46,420-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:46:46,420-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 16:46:46,450-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 16:46:46,451-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local32195433_0001_m_000000_0
2018-09-03 16:46:46,465-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:46:46,466-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:46:46,477-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 16:46:46,478-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 16:46:46,481-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t2.txt:0+58
2018-09-03 16:46:46,613-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 16:46:46,613-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 16:46:46,613-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 16:46:46,613-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 16:46:46,613-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 16:46:46,618-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 16:46:46,761-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=110}
2018-09-03 16:46:46,762-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=99}
2018-09-03 16:46:46,762-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1993, temp=89}
2018-09-03 16:46:46,762-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=10}
2018-09-03 16:46:46,762-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=67}
2018-09-03 16:46:46,762-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=10}
2018-09-03 16:46:46,762-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1993, temp=200}
2018-09-03 16:46:46,766-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 16:46:46,771-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 16:46:46,771-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 16:46:46,771-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-09-03 16:46:46,771-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 16:46:46,795-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 16:46:46,812-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local32195433_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 16:46:46,815-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 16:46:46,815-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local32195433_0001_m_000000_0' done.
2018-09-03 16:46:46,822-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local32195433_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=299
		FILE: Number of bytes written=496421
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=82
		Input split bytes=112
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=278921216
	File Input Format Counters 
		Bytes Read=58
2018-09-03 16:46:46,822-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local32195433_0001_m_000000_0
2018-09-03 16:46:46,823-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local32195433_0001_m_000001_0
2018-09-03 16:46:46,823-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:46:46,824-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:46:46,825-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 16:46:46,825-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 16:46:46,826-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t1.txt:0+50
2018-09-03 16:46:46,898-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 16:46:46,898-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 16:46:46,898-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 16:46:46,898-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 16:46:46,899-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 16:46:46,899-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 16:46:46,909-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=100}
2018-09-03 16:46:46,909-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=99}
2018-09-03 16:46:46,909-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=89}
2018-09-03 16:46:46,910-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=10}
2018-09-03 16:46:46,910-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=67}
2018-09-03 16:46:46,910-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=101}
2018-09-03 16:46:46,910-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 16:46:46,910-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 16:46:46,910-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 16:46:46,911-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-09-03 16:46:46,911-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 16:46:46,921-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 16:46:46,927-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local32195433_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 16:46:46,929-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 16:46:46,929-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local32195433_0001_m_000001_0' done.
2018-09-03 16:46:46,930-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local32195433_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=542
		FILE: Number of bytes written=496549
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=72
		Input split bytes=112
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=384303104
	File Input Format Counters 
		Bytes Read=50
2018-09-03 16:46:46,930-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local32195433_0001_m_000001_0
2018-09-03 16:46:46,930-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 16:46:46,933-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 16:46:46,933-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local32195433_0001_r_000000_0
2018-09-03 16:46:46,938-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:46:46,938-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:46:46,939-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 16:46:46,939-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 16:46:46,941-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@560076aa
2018-09-03 16:46:46,942-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 16:46:46,954-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 16:46:46,955-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local32195433_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 16:46:46,972-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local32195433_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2018-09-03 16:46:46,975-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 52 bytes from map-output for attempt_local32195433_0001_m_000000_0
2018-09-03 16:46:46,976-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 52, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->52
2018-09-03 16:46:46,978-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local32195433_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2018-09-03 16:46:46,979-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local32195433_0001_m_000001_0
2018-09-03 16:46:46,979-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 52, usedMemory ->114
2018-09-03 16:46:46,979-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 16:46:46,980-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:46:46,980-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 16:46:46,990-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 16:46:46,990-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 94 bytes
2018-09-03 16:46:46,996-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 114 bytes to disk to satisfy reduce memory limit
2018-09-03 16:46:46,996-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 116 bytes from disk
2018-09-03 16:46:46,997-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 16:46:46,997-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 16:46:46,997-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 102 bytes
2018-09-03 16:46:46,998-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:46:47,031-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 16:46:47,109-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local32195433_0001_r_000000_0 is done. And is in the process of committing
2018-09-03 16:46:47,111-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:46:47,112-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local32195433_0001_r_000000_0 is allowed to commit now
2018-09-03 16:46:47,128-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local32195433_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/output_4
2018-09-03 16:46:47,129-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 16:46:47,129-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local32195433_0001_r_000000_0' done.
2018-09-03 16:46:47,130-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local32195433_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=924
		FILE: Number of bytes written=496665
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=67
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=8
		Reduce shuffle bytes=122
		Reduce input records=11
		Reduce output records=8
		Spilled Records=11
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=384303104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=67
2018-09-03 16:46:47,130-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local32195433_0001_r_000000_0
2018-09-03 16:46:47,130-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local32195433_0001_r_000001_0
2018-09-03 16:46:47,132-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 16:46:47,132-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 16:46:47,133-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 16:46:47,133-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 16:46:47,133-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@44341d76
2018-09-03 16:46:47,133-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 16:46:47,134-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 16:46:47,135-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local32195433_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 16:46:47,137-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local32195433_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2018-09-03 16:46:47,138-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local32195433_0001_m_000000_0
2018-09-03 16:46:47,138-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2018-09-03 16:46:47,139-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local32195433_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2018-09-03 16:46:47,140-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local32195433_0001_m_000001_0
2018-09-03 16:46:47,140-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->24
2018-09-03 16:46:47,140-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 16:46:47,141-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:46:47,141-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 16:46:47,150-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 16:46:47,151-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-09-03 16:46:47,155-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 24 bytes to disk to satisfy reduce memory limit
2018-09-03 16:46:47,156-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 26 bytes from disk
2018-09-03 16:46:47,156-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 16:46:47,156-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 16:46:47,156-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-09-03 16:46:47,156-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:46:47,178-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local32195433_0001_r_000001_0 is done. And is in the process of committing
2018-09-03 16:46:47,180-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 16:46:47,180-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local32195433_0001_r_000001_0 is allowed to commit now
2018-09-03 16:46:47,186-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local32195433_0001_r_000001_0' to hdfs://localhost:9000/user/lizhijun/output_4
2018-09-03 16:46:47,186-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 16:46:47,187-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local32195433_0001_r_000001_0' done.
2018-09-03 16:46:47,187-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local32195433_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1094
		FILE: Number of bytes written=496691
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=32
		Reduce input records=2
		Reduce output records=2
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=384303104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=17
2018-09-03 16:46:47,187-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local32195433_0001_r_000001_0
2018-09-03 16:46:47,187-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 16:46:47,425-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local32195433_0001 running in uber mode : false
2018-09-03 16:46:47,427-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 16:46:47,428-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local32195433_0001 completed successfully
2018-09-03 16:46:47,436-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2859
		FILE: Number of bytes written=1986326
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=382
		HDFS: Number of bytes written=151
		HDFS: Number of read operations=41
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=154
		Input split bytes=224
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=154
		Reduce input records=13
		Reduce output records=10
		Spilled Records=26
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1431830528
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=84
2018-09-03 17:20:52,686-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 17:20:54,028-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 17:20:54,081-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 17:20:54,082-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 17:20:54,386-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 17:20:54,397-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 17:20:54,497-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 17:20:54,561-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 17:20:54,725-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local485711835_0001
2018-09-03 17:20:54,727-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 17:20:54,886-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 17:20:54,887-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 17:20:54,887-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local485711835_0001
2018-09-03 17:20:54,892-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:20:54,892-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:20:54,893-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 17:20:54,933-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local485711835_0001_m_000000_0
2018-09-03 17:20:54,933-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 17:20:54,951-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:20:54,951-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:20:54,963-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 17:20:54,964-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 17:20:54,966-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t2.txt:0+58
2018-09-03 17:20:55,105-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 17:20:55,105-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 17:20:55,106-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 17:20:55,106-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 17:20:55,106-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 17:20:55,114-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 17:20:55,289-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=110}
2018-09-03 17:20:55,290-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=99}
2018-09-03 17:20:55,290-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1993, temp=89}
2018-09-03 17:20:55,290-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=10}
2018-09-03 17:20:55,290-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=67}
2018-09-03 17:20:55,291-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=10}
2018-09-03 17:20:55,291-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1993, temp=200}
2018-09-03 17:20:55,295-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 17:20:55,297-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 17:20:55,297-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 17:20:55,297-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-09-03 17:20:55,298-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 17:20:55,320-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 17:20:55,334-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local485711835_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 17:20:55,338-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 17:20:55,338-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local485711835_0001_m_000000_0' done.
2018-09-03 17:20:55,345-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local485711835_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=299
		FILE: Number of bytes written=498829
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=82
		Input split bytes=112
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=278921216
	File Input Format Counters 
		Bytes Read=58
2018-09-03 17:20:55,345-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local485711835_0001_m_000000_0
2018-09-03 17:20:55,345-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local485711835_0001_m_000001_0
2018-09-03 17:20:55,346-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:20:55,346-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:20:55,347-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 17:20:55,347-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 17:20:55,348-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t1.txt:0+50
2018-09-03 17:20:55,457-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 17:20:55,457-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 17:20:55,457-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 17:20:55,457-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 17:20:55,458-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 17:20:55,458-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 17:20:55,478-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=100}
2018-09-03 17:20:55,478-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=99}
2018-09-03 17:20:55,479-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=89}
2018-09-03 17:20:55,479-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=10}
2018-09-03 17:20:55,479-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=67}
2018-09-03 17:20:55,479-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=101}
2018-09-03 17:20:55,480-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 17:20:55,480-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 17:20:55,480-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 17:20:55,480-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-09-03 17:20:55,480-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 17:20:55,496-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 17:20:55,503-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local485711835_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 17:20:55,505-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 17:20:55,505-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local485711835_0001_m_000001_0' done.
2018-09-03 17:20:55,506-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local485711835_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=542
		FILE: Number of bytes written=498957
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=72
		Input split bytes=112
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=384303104
	File Input Format Counters 
		Bytes Read=50
2018-09-03 17:20:55,506-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local485711835_0001_m_000001_0
2018-09-03 17:20:55,506-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 17:20:55,508-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 17:20:55,509-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local485711835_0001_r_000000_0
2018-09-03 17:20:55,515-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:20:55,515-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:20:55,516-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 17:20:55,516-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 17:20:55,518-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@209fd814
2018-09-03 17:20:55,519-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 17:20:55,533-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 17:20:55,536-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local485711835_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 17:20:55,553-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local485711835_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2018-09-03 17:20:55,556-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 52 bytes from map-output for attempt_local485711835_0001_m_000000_0
2018-09-03 17:20:55,557-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 52, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->52
2018-09-03 17:20:55,559-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local485711835_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2018-09-03 17:20:55,559-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local485711835_0001_m_000001_0
2018-09-03 17:20:55,560-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 52, usedMemory ->114
2018-09-03 17:20:55,560-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 17:20:55,561-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:20:55,561-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 17:20:55,571-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 17:20:55,572-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 94 bytes
2018-09-03 17:20:55,580-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 114 bytes to disk to satisfy reduce memory limit
2018-09-03 17:20:55,580-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 116 bytes from disk
2018-09-03 17:20:55,581-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 17:20:55,581-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 17:20:55,581-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 102 bytes
2018-09-03 17:20:55,582-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:20:55,620-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 17:20:55,893-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local485711835_0001 running in uber mode : false
2018-09-03 17:20:55,894-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-09-03 17:20:56,098-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local485711835_0001_r_000000_0 is done. And is in the process of committing
2018-09-03 17:20:56,102-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:20:56,102-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local485711835_0001_r_000000_0 is allowed to commit now
2018-09-03 17:20:56,117-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local485711835_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/output_5
2018-09-03 17:20:56,117-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 17:20:56,117-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local485711835_0001_r_000000_0' done.
2018-09-03 17:20:56,118-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local485711835_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=924
		FILE: Number of bytes written=499073
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=67
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=8
		Reduce shuffle bytes=122
		Reduce input records=11
		Reduce output records=8
		Spilled Records=11
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=384303104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=67
2018-09-03 17:20:56,118-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local485711835_0001_r_000000_0
2018-09-03 17:20:56,118-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local485711835_0001_r_000001_0
2018-09-03 17:20:56,119-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:20:56,119-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:20:56,120-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 17:20:56,120-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 17:20:56,120-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7910e216
2018-09-03 17:20:56,120-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 17:20:56,121-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 17:20:56,123-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local485711835_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 17:20:56,125-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local485711835_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2018-09-03 17:20:56,126-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local485711835_0001_m_000000_0
2018-09-03 17:20:56,126-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2018-09-03 17:20:56,127-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local485711835_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2018-09-03 17:20:56,128-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local485711835_0001_m_000001_0
2018-09-03 17:20:56,128-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->24
2018-09-03 17:20:56,128-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 17:20:56,129-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:20:56,129-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 17:20:56,135-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 17:20:56,135-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-09-03 17:20:56,140-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 24 bytes to disk to satisfy reduce memory limit
2018-09-03 17:20:56,140-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 26 bytes from disk
2018-09-03 17:20:56,141-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 17:20:56,141-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 17:20:56,141-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-09-03 17:20:56,141-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:20:56,162-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local485711835_0001_r_000001_0 is done. And is in the process of committing
2018-09-03 17:20:56,163-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:20:56,164-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local485711835_0001_r_000001_0 is allowed to commit now
2018-09-03 17:20:56,170-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local485711835_0001_r_000001_0' to hdfs://localhost:9000/user/lizhijun/output_5
2018-09-03 17:20:56,171-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 17:20:56,171-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local485711835_0001_r_000001_0' done.
2018-09-03 17:20:56,171-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local485711835_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1094
		FILE: Number of bytes written=499099
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=32
		Reduce input records=2
		Reduce output records=2
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=384303104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=17
2018-09-03 17:20:56,171-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local485711835_0001_r_000001_0
2018-09-03 17:20:56,172-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 17:20:56,898-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 17:20:56,899-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local485711835_0001 completed successfully
2018-09-03 17:20:56,909-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2859
		FILE: Number of bytes written=1995958
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=382
		HDFS: Number of bytes written=151
		HDFS: Number of read operations=41
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=154
		Input split bytes=224
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=154
		Reduce input records=13
		Reduce output records=10
		Spilled Records=26
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1431830528
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=84
2018-09-03 17:33:29,369-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 17:33:30,730-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 17:33:30,787-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 17:33:30,788-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 17:33:31,094-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 17:33:31,106-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 17:33:31,216-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 17:33:31,271-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 17:33:31,408-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1773348073_0001
2018-09-03 17:33:31,410-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 17:33:31,559-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 17:33:31,560-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1773348073_0001
2018-09-03 17:33:31,560-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 17:33:31,565-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:33:31,565-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:33:31,566-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 17:33:31,611-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 17:33:31,612-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1773348073_0001_m_000000_0
2018-09-03 17:33:31,633-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:33:31,633-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:33:31,644-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 17:33:31,645-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 17:33:31,648-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t2.txt:0+58
2018-09-03 17:33:31,755-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 17:33:31,755-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 17:33:31,755-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 17:33:31,755-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 17:33:31,756-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 17:33:31,759-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 17:33:31,971-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=110}
2018-09-03 17:33:31,971-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=99}
2018-09-03 17:33:31,971-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1993, temp=89}
2018-09-03 17:33:31,972-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=10}
2018-09-03 17:33:31,972-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=67}
2018-09-03 17:33:31,972-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=10}
2018-09-03 17:33:31,973-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1993, temp=200}
2018-09-03 17:33:31,975-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 17:33:31,981-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 17:33:31,982-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 17:33:31,982-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-09-03 17:33:31,982-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 17:33:32,002-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 17:33:32,013-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1773348073_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 17:33:32,017-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 17:33:32,017-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1773348073_0001_m_000000_0' done.
2018-09-03 17:33:32,023-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1773348073_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=299
		FILE: Number of bytes written=501702
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=82
		Input split bytes=112
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=277872640
	File Input Format Counters 
		Bytes Read=58
2018-09-03 17:33:32,024-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1773348073_0001_m_000000_0
2018-09-03 17:33:32,024-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1773348073_0001_m_000001_0
2018-09-03 17:33:32,025-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:33:32,025-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:33:32,026-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 17:33:32,026-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 17:33:32,027-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t1.txt:0+50
2018-09-03 17:33:32,087-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 17:33:32,087-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 17:33:32,088-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 17:33:32,088-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 17:33:32,088-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 17:33:32,088-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 17:33:32,104-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=100}
2018-09-03 17:33:32,104-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=99}
2018-09-03 17:33:32,104-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=89}
2018-09-03 17:33:32,104-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=10}
2018-09-03 17:33:32,105-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=67}
2018-09-03 17:33:32,105-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=101}
2018-09-03 17:33:32,105-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 17:33:32,106-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 17:33:32,106-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 17:33:32,106-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-09-03 17:33:32,106-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 17:33:32,122-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 17:33:32,128-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1773348073_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 17:33:32,131-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 17:33:32,132-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1773348073_0001_m_000001_0' done.
2018-09-03 17:33:32,132-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1773348073_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=542
		FILE: Number of bytes written=501830
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=72
		Input split bytes=112
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=383254528
	File Input Format Counters 
		Bytes Read=50
2018-09-03 17:33:32,133-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1773348073_0001_m_000001_0
2018-09-03 17:33:32,133-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 17:33:32,135-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 17:33:32,135-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1773348073_0001_r_000000_0
2018-09-03 17:33:32,141-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:33:32,141-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:33:32,142-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 17:33:32,142-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 17:33:32,144-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@575d32ef
2018-09-03 17:33:32,145-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 17:33:32,157-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 17:33:32,159-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1773348073_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 17:33:32,174-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1773348073_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2018-09-03 17:33:32,177-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 52 bytes from map-output for attempt_local1773348073_0001_m_000000_0
2018-09-03 17:33:32,178-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 52, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->52
2018-09-03 17:33:32,180-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1773348073_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2018-09-03 17:33:32,181-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local1773348073_0001_m_000001_0
2018-09-03 17:33:32,181-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 52, usedMemory ->114
2018-09-03 17:33:32,181-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 17:33:32,182-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:33:32,182-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 17:33:32,193-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 17:33:32,193-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 94 bytes
2018-09-03 17:33:32,199-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 114 bytes to disk to satisfy reduce memory limit
2018-09-03 17:33:32,200-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 116 bytes from disk
2018-09-03 17:33:32,201-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 17:33:32,201-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 17:33:32,201-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 102 bytes
2018-09-03 17:33:32,202-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:33:32,232-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 17:33:32,241-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1773348073_0001_r_000001_0
2018-09-03 17:33:32,242-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:33:32,243-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:33:32,243-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 17:33:32,243-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 17:33:32,243-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@603b983f
2018-09-03 17:33:32,243-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 17:33:32,244-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 17:33:32,245-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1773348073_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 17:33:32,247-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1773348073_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2018-09-03 17:33:32,248-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local1773348073_0001_m_000000_0
2018-09-03 17:33:32,248-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2018-09-03 17:33:32,249-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1773348073_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2018-09-03 17:33:32,250-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local1773348073_0001_m_000001_0
2018-09-03 17:33:32,250-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->24
2018-09-03 17:33:32,251-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 17:33:32,252-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:33:32,252-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 17:33:32,263-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 17:33:32,263-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-09-03 17:33:32,270-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 24 bytes to disk to satisfy reduce memory limit
2018-09-03 17:33:32,270-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 26 bytes from disk
2018-09-03 17:33:32,271-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 17:33:32,271-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 17:33:32,271-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-09-03 17:33:32,272-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:33:32,278-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 17:33:32,290-[TS] WARN Thread-22 org.apache.hadoop.mapred.LocalJobRunner - job_local1773348073_0001
java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:559)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:157)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:158)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:302)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:628)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:390)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:347)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-09-03 17:33:32,567-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1773348073_0001 running in uber mode : false
2018-09-03 17:33:32,569-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-09-03 17:33:32,570-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1773348073_0001 failed with state FAILED due to: NA
2018-09-03 17:33:32,578-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=841
		FILE: Number of bytes written=1003532
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=166
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=154
		Input split bytes=224
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=154
		Reduce input records=0
		Reduce output records=0
		Spilled Records=13
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=661127168
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=0
2018-09-03 17:35:00,163-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 17:35:01,663-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 17:35:01,729-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 17:35:01,729-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 17:35:13,250-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 17:35:14,581-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 17:35:14,639-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 17:35:14,639-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 17:35:14,935-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 17:35:14,948-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 17:35:15,025-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 17:35:15,084-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 17:35:15,258-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local940024940_0001
2018-09-03 17:35:15,259-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 17:35:15,434-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 17:35:15,434-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local940024940_0001
2018-09-03 17:35:15,435-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 17:35:15,440-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:35:15,440-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:35:15,440-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 17:35:15,477-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 17:35:15,477-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local940024940_0001_m_000000_0
2018-09-03 17:35:15,502-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:35:15,502-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:35:15,513-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 17:35:15,513-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 17:35:15,516-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t2.txt:0+58
2018-09-03 17:35:15,652-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 17:35:15,652-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 17:35:15,652-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 17:35:15,652-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 17:35:15,652-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 17:35:15,656-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 17:35:15,796-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 17:35:15,800-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 17:35:15,800-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 17:35:15,800-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-09-03 17:35:15,800-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 17:35:15,821-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 17:35:15,838-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local940024940_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 17:35:15,841-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 17:35:15,841-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local940024940_0001_m_000000_0' done.
2018-09-03 17:35:15,847-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local940024940_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=299
		FILE: Number of bytes written=498406
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=82
		Input split bytes=112
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=275775488
	File Input Format Counters 
		Bytes Read=58
2018-09-03 17:35:15,847-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local940024940_0001_m_000000_0
2018-09-03 17:35:15,848-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local940024940_0001_m_000001_0
2018-09-03 17:35:15,848-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:35:15,849-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:35:15,849-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 17:35:15,849-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 17:35:15,850-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t1.txt:0+50
2018-09-03 17:35:15,931-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 17:35:15,943-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 17:35:15,943-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 17:35:15,943-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 17:35:15,943-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 17:35:15,944-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 17:35:15,951-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 17:35:15,951-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 17:35:15,951-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 17:35:15,952-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-09-03 17:35:15,952-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 17:35:15,970-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 17:35:15,978-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local940024940_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 17:35:15,981-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 17:35:15,981-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local940024940_0001_m_000001_0' done.
2018-09-03 17:35:15,982-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local940024940_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=542
		FILE: Number of bytes written=498534
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=72
		Input split bytes=112
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=381157376
	File Input Format Counters 
		Bytes Read=50
2018-09-03 17:35:15,982-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local940024940_0001_m_000001_0
2018-09-03 17:35:15,982-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 17:35:15,985-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 17:35:15,985-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local940024940_0001_r_000000_0
2018-09-03 17:35:15,990-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:35:15,990-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:35:15,991-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 17:35:15,991-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 17:35:15,993-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3ad9c7f
2018-09-03 17:35:15,994-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 17:35:16,010-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 17:35:16,012-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local940024940_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 17:35:16,031-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local940024940_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2018-09-03 17:35:16,049-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local940024940_0001_m_000001_0
2018-09-03 17:35:16,050-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2018-09-03 17:35:16,052-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local940024940_0001_m_000000_0 decomp: 32 len: 36 to MEMORY
2018-09-03 17:35:16,052-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 32 bytes from map-output for attempt_local940024940_0001_m_000000_0
2018-09-03 17:35:16,052-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 32, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->54
2018-09-03 17:35:16,053-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 17:35:16,053-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:35:16,054-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 17:35:16,066-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 17:35:16,066-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 34 bytes
2018-09-03 17:35:16,072-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 54 bytes to disk to satisfy reduce memory limit
2018-09-03 17:35:16,073-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 56 bytes from disk
2018-09-03 17:35:16,074-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 17:35:16,074-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 17:35:16,074-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 42 bytes
2018-09-03 17:35:16,074-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:35:16,103-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 17:35:16,442-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local940024940_0001 running in uber mode : false
2018-09-03 17:35:16,450-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-09-03 17:35:16,591-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local940024940_0001_r_000000_0 is done. And is in the process of committing
2018-09-03 17:35:16,593-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:35:16,594-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local940024940_0001_r_000000_0 is allowed to commit now
2018-09-03 17:35:16,609-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local940024940_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/output_7
2018-09-03 17:35:16,609-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 17:35:16,609-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local940024940_0001_r_000000_0' done.
2018-09-03 17:35:16,610-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local940024940_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=864
		FILE: Number of bytes written=498590
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=33
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=62
		Reduce input records=5
		Reduce output records=4
		Spilled Records=5
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=381157376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=33
2018-09-03 17:35:16,610-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local940024940_0001_r_000000_0
2018-09-03 17:35:16,610-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local940024940_0001_r_000001_0
2018-09-03 17:35:16,612-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:35:16,612-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:35:16,612-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 17:35:16,613-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 17:35:16,613-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@78bda86
2018-09-03 17:35:16,613-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 17:35:16,614-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 17:35:16,614-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local940024940_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 17:35:16,616-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local940024940_0001_m_000001_0 decomp: 42 len: 46 to MEMORY
2018-09-03 17:35:16,617-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 42 bytes from map-output for attempt_local940024940_0001_m_000001_0
2018-09-03 17:35:16,617-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 42, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->42
2018-09-03 17:35:16,620-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local940024940_0001_m_000000_0 decomp: 42 len: 46 to MEMORY
2018-09-03 17:35:16,620-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 42 bytes from map-output for attempt_local940024940_0001_m_000000_0
2018-09-03 17:35:16,620-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 42, inMemoryMapOutputs.size() -> 2, commitMemory -> 42, usedMemory ->84
2018-09-03 17:35:16,620-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 17:35:16,622-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:35:16,622-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 17:35:16,629-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 17:35:16,629-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 64 bytes
2018-09-03 17:35:16,634-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 84 bytes to disk to satisfy reduce memory limit
2018-09-03 17:35:16,635-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 86 bytes from disk
2018-09-03 17:35:16,635-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 17:35:16,635-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 17:35:16,635-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 72 bytes
2018-09-03 17:35:16,635-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:35:17,087-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local940024940_0001_r_000001_0 is done. And is in the process of committing
2018-09-03 17:35:17,090-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:35:17,090-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local940024940_0001_r_000001_0 is allowed to commit now
2018-09-03 17:35:17,097-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local940024940_0001_r_000001_0' to hdfs://localhost:9000/user/lizhijun/output_7
2018-09-03 17:35:17,098-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 17:35:17,099-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local940024940_0001_r_000001_0' done.
2018-09-03 17:35:17,099-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local940024940_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1154
		FILE: Number of bytes written=498676
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=92
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=92
		Reduce input records=8
		Reduce output records=7
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=381157376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=59
2018-09-03 17:35:17,099-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local940024940_0001_r_000001_0
2018-09-03 17:35:17,099-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 17:35:17,451-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 17:35:17,452-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local940024940_0001 completed successfully
2018-09-03 17:35:17,462-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2859
		FILE: Number of bytes written=1994206
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=382
		HDFS: Number of bytes written=125
		HDFS: Number of read operations=41
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=154
		Input split bytes=224
		Combine input records=0
		Combine output records=0
		Reduce input groups=11
		Reduce shuffle bytes=154
		Reduce input records=13
		Reduce output records=11
		Spilled Records=26
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1419247616
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=92
2018-09-03 17:36:33,390-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 17:36:34,805-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 17:36:34,861-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 17:36:34,861-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 17:36:35,170-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 17:36:35,215-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 17:36:35,291-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 17:36:35,364-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 17:36:35,509-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1807115874_0001
2018-09-03 17:36:35,511-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 17:36:35,655-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 17:36:35,655-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 17:36:35,656-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1807115874_0001
2018-09-03 17:36:35,662-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:36:35,662-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:36:35,663-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 17:36:35,697-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 17:36:35,697-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1807115874_0001_m_000000_0
2018-09-03 17:36:35,712-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:36:35,712-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:36:35,723-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 17:36:35,724-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 17:36:35,726-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t2.txt:0+58
2018-09-03 17:36:35,876-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 17:36:35,878-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 17:36:35,878-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 17:36:35,881-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 17:36:35,881-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 17:36:35,886-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 17:36:35,976-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=110}
2018-09-03 17:36:35,976-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=99}
2018-09-03 17:36:35,977-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1993, temp=89}
2018-09-03 17:36:35,977-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=10}
2018-09-03 17:36:35,977-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=67}
2018-09-03 17:36:35,977-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=10}
2018-09-03 17:36:35,977-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1993, temp=200}
2018-09-03 17:36:35,980-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 17:36:35,982-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 17:36:35,982-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 17:36:35,982-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-09-03 17:36:35,982-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 17:36:36,006-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 17:36:36,025-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1807115874_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 17:36:36,028-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 17:36:36,029-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1807115874_0001_m_000000_0' done.
2018-09-03 17:36:36,035-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1807115874_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=299
		FILE: Number of bytes written=501241
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=82
		Input split bytes=112
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=279445504
	File Input Format Counters 
		Bytes Read=58
2018-09-03 17:36:36,036-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1807115874_0001_m_000000_0
2018-09-03 17:36:36,036-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1807115874_0001_m_000001_0
2018-09-03 17:36:36,037-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:36:36,037-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:36:36,038-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 17:36:36,038-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 17:36:36,039-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t1.txt:0+50
2018-09-03 17:36:36,162-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 17:36:36,163-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 17:36:36,163-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 17:36:36,163-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 17:36:36,163-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 17:36:36,165-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 17:36:36,192-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=100}
2018-09-03 17:36:36,192-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=99}
2018-09-03 17:36:36,193-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=89}
2018-09-03 17:36:36,193-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=10}
2018-09-03 17:36:36,193-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=67}
2018-09-03 17:36:36,193-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=101}
2018-09-03 17:36:36,194-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 17:36:36,194-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 17:36:36,194-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 17:36:36,194-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-09-03 17:36:36,194-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 17:36:36,221-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 17:36:36,230-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1807115874_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 17:36:36,233-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 17:36:36,233-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1807115874_0001_m_000001_0' done.
2018-09-03 17:36:36,234-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1807115874_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=542
		FILE: Number of bytes written=501369
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=72
		Input split bytes=112
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=384827392
	File Input Format Counters 
		Bytes Read=50
2018-09-03 17:36:36,234-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1807115874_0001_m_000001_0
2018-09-03 17:36:36,234-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 17:36:36,237-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 17:36:36,237-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1807115874_0001_r_000000_0
2018-09-03 17:36:36,247-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:36:36,247-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:36:36,248-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 17:36:36,248-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 17:36:36,250-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@60626afc
2018-09-03 17:36:36,252-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 17:36:36,271-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 17:36:36,273-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1807115874_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 17:36:36,295-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1807115874_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2018-09-03 17:36:36,298-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local1807115874_0001_m_000001_0
2018-09-03 17:36:36,299-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->62
2018-09-03 17:36:36,302-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1807115874_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2018-09-03 17:36:36,302-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 52 bytes from map-output for attempt_local1807115874_0001_m_000000_0
2018-09-03 17:36:36,302-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 52, inMemoryMapOutputs.size() -> 2, commitMemory -> 62, usedMemory ->114
2018-09-03 17:36:36,303-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 17:36:36,303-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:36:36,304-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 17:36:36,318-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 17:36:36,318-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 94 bytes
2018-09-03 17:36:36,325-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 114 bytes to disk to satisfy reduce memory limit
2018-09-03 17:36:36,326-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 116 bytes from disk
2018-09-03 17:36:36,326-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 17:36:36,326-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 17:36:36,327-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 102 bytes
2018-09-03 17:36:36,327-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:36:36,349-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 17:36:36,427-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1807115874_0001_r_000000_0 is done. And is in the process of committing
2018-09-03 17:36:36,440-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:36:36,441-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1807115874_0001_r_000000_0 is allowed to commit now
2018-09-03 17:36:36,459-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1807115874_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/output_8
2018-09-03 17:36:36,459-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 17:36:36,460-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1807115874_0001_r_000000_0' done.
2018-09-03 17:36:36,460-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1807115874_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=924
		FILE: Number of bytes written=501485
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=67
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=8
		Reduce shuffle bytes=122
		Reduce input records=11
		Reduce output records=8
		Spilled Records=11
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=384827392
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=67
2018-09-03 17:36:36,462-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1807115874_0001_r_000000_0
2018-09-03 17:36:36,462-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1807115874_0001_r_000001_0
2018-09-03 17:36:36,463-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 17:36:36,463-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 17:36:36,466-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 17:36:36,467-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 17:36:36,472-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4413e1a8
2018-09-03 17:36:36,473-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 17:36:36,474-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 17:36:36,489-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1807115874_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 17:36:36,492-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1807115874_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2018-09-03 17:36:36,493-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local1807115874_0001_m_000001_0
2018-09-03 17:36:36,494-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2018-09-03 17:36:36,495-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1807115874_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2018-09-03 17:36:36,496-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local1807115874_0001_m_000000_0
2018-09-03 17:36:36,496-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->24
2018-09-03 17:36:36,497-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 17:36:36,499-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:36:36,500-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 17:36:36,511-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 17:36:36,511-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-09-03 17:36:36,521-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 24 bytes to disk to satisfy reduce memory limit
2018-09-03 17:36:36,521-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 26 bytes from disk
2018-09-03 17:36:36,522-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 17:36:36,522-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 17:36:36,522-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-09-03 17:36:36,523-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:36:36,565-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1807115874_0001_r_000001_0 is done. And is in the process of committing
2018-09-03 17:36:36,569-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 17:36:36,570-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1807115874_0001_r_000001_0 is allowed to commit now
2018-09-03 17:36:36,577-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1807115874_0001_r_000001_0' to hdfs://localhost:9000/user/lizhijun/output_8
2018-09-03 17:36:36,580-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 17:36:36,580-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1807115874_0001_r_000001_0' done.
2018-09-03 17:36:36,580-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1807115874_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1094
		FILE: Number of bytes written=501511
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=32
		Reduce input records=2
		Reduce output records=2
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=384827392
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=17
2018-09-03 17:36:36,581-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1807115874_0001_r_000001_0
2018-09-03 17:36:36,584-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 17:36:36,661-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1807115874_0001 running in uber mode : false
2018-09-03 17:36:36,663-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 17:36:36,664-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1807115874_0001 completed successfully
2018-09-03 17:36:36,676-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2859
		FILE: Number of bytes written=2005606
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=382
		HDFS: Number of bytes written=151
		HDFS: Number of read operations=41
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=154
		Input split bytes=224
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=154
		Reduce input records=13
		Reduce output records=10
		Spilled Records=26
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1433927680
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=84
2018-09-03 19:22:13,136-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 19:22:14,690-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 19:22:14,818-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 19:22:14,818-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 19:22:15,230-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 19:22:15,244-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 19:22:15,388-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 19:22:15,463-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 19:22:15,643-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local924262639_0001
2018-09-03 19:22:15,645-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 19:22:15,800-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 19:22:15,801-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local924262639_0001
2018-09-03 19:22:15,802-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 19:22:15,811-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 19:22:15,811-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 19:22:15,812-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 19:22:15,866-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 19:22:15,866-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local924262639_0001_m_000000_0
2018-09-03 19:22:15,890-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 19:22:15,891-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 19:22:15,903-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 19:22:15,903-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 19:22:15,906-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t2.txt:0+58
2018-09-03 19:22:16,041-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 19:22:16,042-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 19:22:16,042-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 19:22:16,042-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 19:22:16,046-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 19:22:16,051-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 19:22:16,278-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=110}
2018-09-03 19:22:16,279-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=99}
2018-09-03 19:22:16,279-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1993, temp=89}
2018-09-03 19:22:16,279-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=10}
2018-09-03 19:22:16,279-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=67}
2018-09-03 19:22:16,279-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=10}
2018-09-03 19:22:16,280-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1993, temp=200}
2018-09-03 19:22:16,282-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 19:22:16,285-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 19:22:16,285-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 19:22:16,285-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-09-03 19:22:16,285-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 19:22:16,320-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 19:22:16,344-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local924262639_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 19:22:16,347-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 19:22:16,347-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local924262639_0001_m_000000_0' done.
2018-09-03 19:22:16,361-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local924262639_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=299
		FILE: Number of bytes written=499292
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=82
		Input split bytes=112
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=299892736
	File Input Format Counters 
		Bytes Read=58
2018-09-03 19:22:16,361-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local924262639_0001_m_000000_0
2018-09-03 19:22:16,362-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local924262639_0001_m_000001_0
2018-09-03 19:22:16,363-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 19:22:16,363-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 19:22:16,364-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 19:22:16,364-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 19:22:16,365-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t1.txt:0+50
2018-09-03 19:22:16,484-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 19:22:16,484-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 19:22:16,484-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 19:22:16,484-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 19:22:16,485-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 19:22:16,485-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 19:22:16,503-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=100}
2018-09-03 19:22:16,504-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=99}
2018-09-03 19:22:16,504-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=89}
2018-09-03 19:22:16,505-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=10}
2018-09-03 19:22:16,506-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=67}
2018-09-03 19:22:16,506-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=101}
2018-09-03 19:22:16,506-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 19:22:16,506-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 19:22:16,506-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 19:22:16,506-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-09-03 19:22:16,507-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 19:22:16,524-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 19:22:16,532-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local924262639_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 19:22:16,537-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 19:22:16,538-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local924262639_0001_m_000001_0' done.
2018-09-03 19:22:16,538-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local924262639_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=542
		FILE: Number of bytes written=499420
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=72
		Input split bytes=112
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=405274624
	File Input Format Counters 
		Bytes Read=50
2018-09-03 19:22:16,539-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local924262639_0001_m_000001_0
2018-09-03 19:22:16,539-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 19:22:16,543-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 19:22:16,543-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local924262639_0001_r_000000_0
2018-09-03 19:22:16,554-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 19:22:16,554-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 19:22:16,555-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 19:22:16,555-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 19:22:16,560-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6575ca3d
2018-09-03 19:22:16,563-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 19:22:16,580-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 19:22:16,598-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local924262639_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 19:22:16,619-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local924262639_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2018-09-03 19:22:16,622-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 52 bytes from map-output for attempt_local924262639_0001_m_000000_0
2018-09-03 19:22:16,623-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 52, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->52
2018-09-03 19:22:16,625-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local924262639_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2018-09-03 19:22:16,625-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local924262639_0001_m_000001_0
2018-09-03 19:22:16,626-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 52, usedMemory ->114
2018-09-03 19:22:16,626-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 19:22:16,627-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 19:22:16,627-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 19:22:16,637-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 19:22:16,637-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 94 bytes
2018-09-03 19:22:16,643-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 114 bytes to disk to satisfy reduce memory limit
2018-09-03 19:22:16,643-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 116 bytes from disk
2018-09-03 19:22:16,643-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 19:22:16,644-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 19:22:16,644-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 102 bytes
2018-09-03 19:22:16,644-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 19:22:16,681-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 19:22:16,690-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local924262639_0001_r_000001_0
2018-09-03 19:22:16,692-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 19:22:16,693-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 19:22:16,693-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 19:22:16,693-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 19:22:16,693-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7f1401b2
2018-09-03 19:22:16,694-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 19:22:16,697-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 19:22:16,698-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local924262639_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 19:22:16,700-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local924262639_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2018-09-03 19:22:16,700-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local924262639_0001_m_000000_0
2018-09-03 19:22:16,701-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2018-09-03 19:22:16,702-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local924262639_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2018-09-03 19:22:16,703-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local924262639_0001_m_000001_0
2018-09-03 19:22:16,703-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->24
2018-09-03 19:22:16,703-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 19:22:16,706-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 19:22:16,707-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 19:22:16,716-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 19:22:16,717-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-09-03 19:22:16,725-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 24 bytes to disk to satisfy reduce memory limit
2018-09-03 19:22:16,726-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 26 bytes from disk
2018-09-03 19:22:16,726-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 19:22:16,726-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 19:22:16,727-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-09-03 19:22:16,727-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 19:22:16,732-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 19:22:16,740-[TS] WARN Thread-22 org.apache.hadoop.mapred.LocalJobRunner - job_local924262639_0001
java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:559)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:157)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:158)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:302)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:628)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:390)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:347)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-09-03 19:22:16,809-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local924262639_0001 running in uber mode : false
2018-09-03 19:22:16,811-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-09-03 19:22:16,811-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local924262639_0001 failed with state FAILED due to: NA
2018-09-03 19:22:16,820-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=841
		FILE: Number of bytes written=998712
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=166
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=154
		Input split bytes=224
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=154
		Reduce input records=0
		Reduce output records=0
		Spilled Records=13
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=705167360
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=0
2018-09-03 20:51:04,284-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 20:51:05,740-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 20:51:05,842-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 20:51:05,842-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 20:51:20,904-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 20:51:22,059-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 20:51:22,122-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 20:51:22,122-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 20:51:33,239-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 20:51:34,493-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 20:51:34,558-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 20:51:34,558-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 20:51:34,977-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 20:51:34,991-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 20:51:35,063-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
2018-09-03 20:51:35,184-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 20:51:35,316-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3
2018-09-03 20:51:35,530-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local639984826_0001
2018-09-03 20:51:35,533-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 20:51:35,698-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 20:51:35,698-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local639984826_0001
2018-09-03 20:51:35,699-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 20:51:35,707-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 20:51:35,707-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 20:51:35,708-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 20:51:35,766-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 20:51:35,767-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local639984826_0001_m_000000_0
2018-09-03 20:51:35,792-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 20:51:35,793-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 20:51:35,807-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 20:51:35,808-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 20:51:35,812-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t4.txt:0+72
2018-09-03 20:51:36,040-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 20:51:36,041-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 20:51:36,041-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 20:51:36,041-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 20:51:36,042-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 20:51:36,053-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 20:51:36,289-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 20:51:36,302-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 20:51:36,303-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 20:51:36,303-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 128; bufvoid = 104857600
2018-09-03 20:51:36,303-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 20:51:36,326-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 20:51:36,343-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local639984826_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 20:51:36,346-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 20:51:36,346-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local639984826_0001_m_000000_0' done.
2018-09-03 20:51:36,357-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local639984826_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=856
		FILE: Number of bytes written=501496
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=72
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=128
		Map output materialized bytes=154
		Input split bytes=251
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=275775488
	File Input Format Counters 
		Bytes Read=0
2018-09-03 20:51:36,357-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local639984826_0001_m_000000_0
2018-09-03 20:51:36,357-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local639984826_0001_m_000001_0
2018-09-03 20:51:36,358-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 20:51:36,358-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 20:51:36,359-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 20:51:36,359-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 20:51:36,360-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t3.txt:0+62
2018-09-03 20:51:36,490-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 20:51:36,490-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 20:51:36,490-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 20:51:36,490-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 20:51:36,490-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 20:51:36,492-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 20:51:36,513-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 20:51:36,513-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 20:51:36,513-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 20:51:36,514-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 110; bufvoid = 104857600
2018-09-03 20:51:36,514-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 20:51:36,536-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 20:51:36,544-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local639984826_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 20:51:36,561-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 20:51:36,561-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local639984826_0001_m_000001_0' done.
2018-09-03 20:51:36,563-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local639984826_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=1635
		FILE: Number of bytes written=501686
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=134
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=110
		Map output materialized bytes=134
		Input split bytes=251
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=381157376
	File Input Format Counters 
		Bytes Read=0
2018-09-03 20:51:36,563-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local639984826_0001_m_000001_0
2018-09-03 20:51:36,563-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local639984826_0001_m_000002_0
2018-09-03 20:51:36,565-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 20:51:36,565-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 20:51:36,566-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 20:51:36,566-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 20:51:36,577-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/s1.txt:0+21
2018-09-03 20:51:36,710-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local639984826_0001 running in uber mode : false
2018-09-03 20:51:36,720-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-09-03 20:51:36,733-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 20:51:36,733-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 20:51:36,733-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 20:51:36,734-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 20:51:36,734-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 20:51:36,736-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 20:51:36,768-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 20:51:36,769-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 20:51:36,769-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 20:51:36,769-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 37; bufvoid = 104857600
2018-09-03 20:51:36,769-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2018-09-03 20:51:36,793-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 20:51:36,806-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local639984826_0001_m_000002_0 is done. And is in the process of committing
2018-09-03 20:51:36,811-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 20:51:36,812-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local639984826_0001_m_000002_0' done.
2018-09-03 20:51:36,816-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local639984826_0001_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=2414
		FILE: Number of bytes written=501795
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=37
		Map output materialized bytes=53
		Input split bytes=254
		Combine input records=0
		Spilled Records=2
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=486539264
	File Input Format Counters 
		Bytes Read=0
2018-09-03 20:51:36,816-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local639984826_0001_m_000002_0
2018-09-03 20:51:36,816-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 20:51:36,824-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 20:51:36,825-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local639984826_0001_r_000000_0
2018-09-03 20:51:36,837-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 20:51:36,838-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 20:51:36,838-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 20:51:36,839-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 20:51:36,844-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@57be4c5c
2018-09-03 20:51:36,848-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 20:51:36,867-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 20:51:36,868-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local639984826_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 20:51:36,892-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local639984826_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 20:51:36,895-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local639984826_0001_m_000001_0
2018-09-03 20:51:36,897-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
2018-09-03 20:51:36,900-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local639984826_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2018-09-03 20:51:36,900-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 23 bytes from map-output for attempt_local639984826_0001_m_000002_0
2018-09-03 20:51:36,900-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 2, commitMemory -> 63, usedMemory ->86
2018-09-03 20:51:36,902-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local639984826_0001_m_000000_0 decomp: 84 len: 88 to MEMORY
2018-09-03 20:51:36,902-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 84 bytes from map-output for attempt_local639984826_0001_m_000000_0
2018-09-03 20:51:36,903-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 84, inMemoryMapOutputs.size() -> 3, commitMemory -> 86, usedMemory ->170
2018-09-03 20:51:36,903-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 20:51:36,904-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 20:51:36,904-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 20:51:36,919-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 20:51:36,919-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 140 bytes
2018-09-03 20:51:36,927-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 170 bytes to disk to satisfy reduce memory limit
2018-09-03 20:51:36,928-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 170 bytes from disk
2018-09-03 20:51:36,929-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 20:51:36,929-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 20:51:36,929-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 156 bytes
2018-09-03 20:51:36,930-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 20:51:36,974-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 20:51:36,990-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local639984826_0001_r_000001_0
2018-09-03 20:51:36,991-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 20:51:36,991-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 20:51:36,992-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 20:51:36,992-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 20:51:36,992-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@63633765
2018-09-03 20:51:36,992-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 20:51:36,994-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 20:51:36,995-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local639984826_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 20:51:36,998-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local639984826_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 20:51:36,998-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local639984826_0001_m_000001_0
2018-09-03 20:51:36,998-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
2018-09-03 20:51:37,001-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local639984826_0001_m_000002_0 decomp: 22 len: 26 to MEMORY
2018-09-03 20:51:37,001-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local639984826_0001_m_000002_0
2018-09-03 20:51:37,002-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 63, usedMemory ->85
2018-09-03 20:51:37,004-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local639984826_0001_m_000000_0 decomp: 62 len: 66 to MEMORY
2018-09-03 20:51:37,005-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local639984826_0001_m_000000_0
2018-09-03 20:51:37,005-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 3, commitMemory -> 85, usedMemory ->147
2018-09-03 20:51:37,006-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 20:51:37,006-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 20:51:37,006-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 20:51:37,018-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 20:51:37,018-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 117 bytes
2018-09-03 20:51:37,028-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 147 bytes to disk to satisfy reduce memory limit
2018-09-03 20:51:37,029-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 147 bytes from disk
2018-09-03 20:51:37,029-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 20:51:37,029-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 20:51:37,029-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 133 bytes
2018-09-03 20:51:37,030-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 20:51:37,035-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 20:51:37,049-[TS] WARN Thread-22 org.apache.hadoop.mapred.LocalJobRunner - job_local639984826_0001
java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:559)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:157)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:158)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:302)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:628)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:390)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:347)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-09-03 20:51:37,728-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local639984826_0001 failed with state FAILED due to: NA
2018-09-03 20:51:37,743-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=4905
		FILE: Number of bytes written=1504977
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=361
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=33
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Map input records=15
		Map output records=15
		Map output bytes=275
		Map output materialized bytes=341
		Input split bytes=756
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=341
		Reduce input records=0
		Reduce output records=0
		Spilled Records=15
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1143472128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2018-09-03 21:06:01,690-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 21:06:02,979-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 21:06:03,035-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 21:06:03,035-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 21:06:03,333-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 21:06:03,344-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 21:06:03,393-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
2018-09-03 21:06:03,452-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 21:06:03,511-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3
2018-09-03 21:06:03,650-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local743141690_0001
2018-09-03 21:06:03,652-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 21:06:03,818-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 21:06:03,819-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local743141690_0001
2018-09-03 21:06:03,819-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 21:06:03,827-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:06:03,828-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:06:03,829-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 21:06:03,914-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 21:06:03,915-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local743141690_0001_m_000000_0
2018-09-03 21:06:03,935-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:06:03,935-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:06:03,955-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:06:03,956-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:06:03,961-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t4.txt:0+72
2018-09-03 21:06:04,113-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:06:04,113-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:06:04,113-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:06:04,114-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:06:04,114-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:06:04,119-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:06:04,307-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:06:04,312-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:06:04,312-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:06:04,312-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 128; bufvoid = 104857600
2018-09-03 21:06:04,312-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 21:06:04,343-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:06:04,359-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local743141690_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 21:06:04,365-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:06:04,366-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local743141690_0001_m_000000_0' done.
2018-09-03 21:06:04,377-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local743141690_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=856
		FILE: Number of bytes written=501961
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=72
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=128
		Map output materialized bytes=154
		Input split bytes=251
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=277872640
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:06:04,377-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local743141690_0001_m_000000_0
2018-09-03 21:06:04,377-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local743141690_0001_m_000001_0
2018-09-03 21:06:04,378-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:06:04,379-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:06:04,379-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:06:04,379-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:06:04,381-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t3.txt:0+62
2018-09-03 21:06:04,532-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:06:04,532-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:06:04,532-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:06:04,532-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:06:04,532-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:06:04,533-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:06:04,543-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:06:04,543-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:06:04,543-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:06:04,544-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 110; bufvoid = 104857600
2018-09-03 21:06:04,544-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 21:06:04,562-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:06:04,568-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local743141690_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 21:06:04,581-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:06:04,581-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local743141690_0001_m_000001_0' done.
2018-09-03 21:06:04,582-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local743141690_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=1635
		FILE: Number of bytes written=502151
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=134
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=110
		Map output materialized bytes=134
		Input split bytes=251
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=383254528
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:06:04,583-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local743141690_0001_m_000001_0
2018-09-03 21:06:04,583-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local743141690_0001_m_000002_0
2018-09-03 21:06:04,584-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:06:04,584-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:06:04,585-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:06:04,585-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:06:04,587-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/s1.txt:0+21
2018-09-03 21:06:04,730-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:06:04,730-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:06:04,730-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:06:04,730-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:06:04,730-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:06:04,731-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:06:04,739-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:06:04,739-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:06:04,739-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:06:04,739-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 37; bufvoid = 104857600
2018-09-03 21:06:04,739-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2018-09-03 21:06:04,750-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:06:04,773-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local743141690_0001_m_000002_0 is done. And is in the process of committing
2018-09-03 21:06:04,776-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:06:04,776-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local743141690_0001_m_000002_0' done.
2018-09-03 21:06:04,778-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local743141690_0001_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=2414
		FILE: Number of bytes written=502260
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=37
		Map output materialized bytes=53
		Input split bytes=254
		Combine input records=0
		Spilled Records=2
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=488636416
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:06:04,779-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local743141690_0001_m_000002_0
2018-09-03 21:06:04,780-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 21:06:04,789-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 21:06:04,790-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local743141690_0001_r_000000_0
2018-09-03 21:06:04,804-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:06:04,805-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:06:04,806-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:06:04,806-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:06:04,808-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@633e0802
2018-09-03 21:06:04,809-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:06:04,823-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local743141690_0001 running in uber mode : false
2018-09-03 21:06:04,824-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-09-03 21:06:04,831-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:06:04,834-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local743141690_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:06:04,858-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local743141690_0001_m_000000_0 decomp: 84 len: 88 to MEMORY
2018-09-03 21:06:04,861-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 84 bytes from map-output for attempt_local743141690_0001_m_000000_0
2018-09-03 21:06:04,864-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 84, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->84
2018-09-03 21:06:04,869-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local743141690_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 21:06:04,870-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local743141690_0001_m_000001_0
2018-09-03 21:06:04,871-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 2, commitMemory -> 84, usedMemory ->147
2018-09-03 21:06:04,873-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local743141690_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2018-09-03 21:06:04,873-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 23 bytes from map-output for attempt_local743141690_0001_m_000002_0
2018-09-03 21:06:04,873-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 3, commitMemory -> 147, usedMemory ->170
2018-09-03 21:06:04,875-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:06:04,876-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:06:04,876-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:06:04,887-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 21:06:04,888-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 140 bytes
2018-09-03 21:06:04,893-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 170 bytes to disk to satisfy reduce memory limit
2018-09-03 21:06:04,894-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 170 bytes from disk
2018-09-03 21:06:04,894-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:06:04,895-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:06:04,895-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 156 bytes
2018-09-03 21:06:04,895-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:06:04,923-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 21:06:04,931-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local743141690_0001_r_000001_0
2018-09-03 21:06:04,932-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:06:04,932-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:06:04,933-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:06:04,933-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:06:04,933-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@13264c24
2018-09-03 21:06:04,933-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:06:04,934-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:06:04,934-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local743141690_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:06:04,936-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local743141690_0001_m_000000_0 decomp: 62 len: 66 to MEMORY
2018-09-03 21:06:04,936-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local743141690_0001_m_000000_0
2018-09-03 21:06:04,936-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->62
2018-09-03 21:06:04,937-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local743141690_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 21:06:04,937-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local743141690_0001_m_000001_0
2018-09-03 21:06:04,938-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 2, commitMemory -> 62, usedMemory ->125
2018-09-03 21:06:04,939-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local743141690_0001_m_000002_0 decomp: 22 len: 26 to MEMORY
2018-09-03 21:06:04,940-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local743141690_0001_m_000002_0
2018-09-03 21:06:04,940-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 3, commitMemory -> 125, usedMemory ->147
2018-09-03 21:06:04,940-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:06:04,941-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:06:04,941-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:06:04,947-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 21:06:04,947-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 117 bytes
2018-09-03 21:06:04,952-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 147 bytes to disk to satisfy reduce memory limit
2018-09-03 21:06:04,953-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 147 bytes from disk
2018-09-03 21:06:04,953-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:06:04,953-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:06:04,954-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 133 bytes
2018-09-03 21:06:04,954-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:06:04,966-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 21:06:04,972-[TS] WARN Thread-22 org.apache.hadoop.mapred.LocalJobRunner - job_local743141690_0001
java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:559)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:157)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:158)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:302)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:628)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:390)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:347)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-09-03 21:06:05,830-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local743141690_0001 failed with state FAILED due to: NA
2018-09-03 21:06:05,840-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=4905
		FILE: Number of bytes written=1506372
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=361
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=33
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Map input records=15
		Map output records=15
		Map output bytes=275
		Map output materialized bytes=341
		Input split bytes=756
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=341
		Reduce input records=0
		Reduce output records=0
		Spilled Records=15
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1149763584
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2018-09-03 21:12:26,858-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 21:12:28,120-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 21:12:28,174-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 21:12:28,175-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 21:12:28,583-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 21:12:28,596-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 21:12:28,655-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
2018-09-03 21:12:28,724-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 21:12:28,784-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3
2018-09-03 21:12:28,920-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local211960115_0001
2018-09-03 21:12:28,922-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 21:12:29,040-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 21:12:29,041-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local211960115_0001
2018-09-03 21:12:29,041-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 21:12:29,049-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:12:29,049-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:12:29,050-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 21:12:29,094-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 21:12:29,095-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local211960115_0001_m_000000_0
2018-09-03 21:12:29,120-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:12:29,120-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:12:29,140-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:12:29,140-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:12:29,144-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t4.txt:0+72
2018-09-03 21:12:29,243-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:12:29,243-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:12:29,243-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:12:29,244-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:12:29,244-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:12:29,251-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:12:29,443-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:12:29,466-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:12:29,467-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:12:29,467-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 128; bufvoid = 104857600
2018-09-03 21:12:29,467-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 21:12:29,619-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:12:29,655-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local211960115_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 21:12:29,673-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:12:29,673-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local211960115_0001_m_000000_0' done.
2018-09-03 21:12:29,699-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local211960115_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=856
		FILE: Number of bytes written=501496
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=72
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=128
		Map output materialized bytes=154
		Input split bytes=251
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=276299776
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:12:29,700-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local211960115_0001_m_000000_0
2018-09-03 21:12:29,708-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local211960115_0001_m_000001_0
2018-09-03 21:12:29,715-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:12:29,716-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:12:29,716-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:12:29,716-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:12:29,724-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t3.txt:0+62
2018-09-03 21:12:29,985-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:12:29,985-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:12:29,985-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:12:29,985-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:12:29,985-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:12:29,986-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:12:30,018-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:12:30,019-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:12:30,019-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:12:30,019-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 110; bufvoid = 104857600
2018-09-03 21:12:30,019-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 21:12:30,042-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:12:30,050-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local211960115_0001 running in uber mode : false
2018-09-03 21:12:30,051-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 33% reduce 0%
2018-09-03 21:12:30,058-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local211960115_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 21:12:30,062-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:12:30,062-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local211960115_0001_m_000001_0' done.
2018-09-03 21:12:30,063-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local211960115_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=1635
		FILE: Number of bytes written=501686
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=134
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=110
		Map output materialized bytes=134
		Input split bytes=251
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=381681664
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:12:30,063-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local211960115_0001_m_000001_0
2018-09-03 21:12:30,063-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local211960115_0001_m_000002_0
2018-09-03 21:12:30,064-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:12:30,064-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:12:30,064-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:12:30,065-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:12:30,067-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/s1.txt:0+21
2018-09-03 21:12:30,202-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:12:30,203-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:12:30,203-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:12:30,203-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:12:30,203-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:12:30,203-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:12:30,213-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:12:30,214-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:12:30,214-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:12:30,214-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 37; bufvoid = 104857600
2018-09-03 21:12:30,214-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2018-09-03 21:12:30,226-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:12:30,235-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local211960115_0001_m_000002_0 is done. And is in the process of committing
2018-09-03 21:12:30,240-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:12:30,240-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local211960115_0001_m_000002_0' done.
2018-09-03 21:12:30,240-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local211960115_0001_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=2414
		FILE: Number of bytes written=501795
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=37
		Map output materialized bytes=53
		Input split bytes=254
		Combine input records=0
		Spilled Records=2
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=487063552
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:12:30,241-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local211960115_0001_m_000002_0
2018-09-03 21:12:30,241-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 21:12:30,245-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 21:12:30,245-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local211960115_0001_r_000000_0
2018-09-03 21:12:30,252-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:12:30,252-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:12:30,253-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:12:30,253-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:12:30,255-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6060ff33
2018-09-03 21:12:30,257-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:12:30,272-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:12:30,274-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local211960115_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:12:30,302-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local211960115_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 21:12:30,306-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local211960115_0001_m_000001_0
2018-09-03 21:12:30,308-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
2018-09-03 21:12:30,310-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local211960115_0001_m_000000_0 decomp: 84 len: 88 to MEMORY
2018-09-03 21:12:30,311-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 84 bytes from map-output for attempt_local211960115_0001_m_000000_0
2018-09-03 21:12:30,311-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 84, inMemoryMapOutputs.size() -> 2, commitMemory -> 63, usedMemory ->147
2018-09-03 21:12:30,313-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local211960115_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2018-09-03 21:12:30,313-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 23 bytes from map-output for attempt_local211960115_0001_m_000002_0
2018-09-03 21:12:30,313-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 3, commitMemory -> 147, usedMemory ->170
2018-09-03 21:12:30,314-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:12:30,314-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:12:30,315-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:12:30,324-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 21:12:30,325-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 140 bytes
2018-09-03 21:12:30,332-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 170 bytes to disk to satisfy reduce memory limit
2018-09-03 21:12:30,332-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 170 bytes from disk
2018-09-03 21:12:30,332-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:12:30,333-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:12:30,333-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 156 bytes
2018-09-03 21:12:30,333-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:12:30,358-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 21:12:30,367-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local211960115_0001_r_000001_0
2018-09-03 21:12:30,368-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:12:30,368-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:12:30,368-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:12:30,368-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:12:30,368-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@54bf5bf5
2018-09-03 21:12:30,368-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:12:30,369-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:12:30,370-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local211960115_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:12:30,372-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local211960115_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 21:12:30,372-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local211960115_0001_m_000001_0
2018-09-03 21:12:30,372-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
2018-09-03 21:12:30,374-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local211960115_0001_m_000000_0 decomp: 62 len: 66 to MEMORY
2018-09-03 21:12:30,374-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local211960115_0001_m_000000_0
2018-09-03 21:12:30,374-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 63, usedMemory ->125
2018-09-03 21:12:30,375-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local211960115_0001_m_000002_0 decomp: 22 len: 26 to MEMORY
2018-09-03 21:12:30,376-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local211960115_0001_m_000002_0
2018-09-03 21:12:30,376-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 3, commitMemory -> 125, usedMemory ->147
2018-09-03 21:12:30,376-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:12:30,377-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:12:30,377-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:12:30,384-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 21:12:30,384-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 117 bytes
2018-09-03 21:12:30,390-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 147 bytes to disk to satisfy reduce memory limit
2018-09-03 21:12:30,390-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 147 bytes from disk
2018-09-03 21:12:30,390-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:12:30,391-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:12:30,391-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 133 bytes
2018-09-03 21:12:30,392-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:12:30,411-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 21:12:30,421-[TS] WARN Thread-22 org.apache.hadoop.mapred.LocalJobRunner - job_local211960115_0001
java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:559)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:157)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:158)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:302)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:628)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:390)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:347)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-09-03 21:12:31,063-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-09-03 21:12:31,063-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local211960115_0001 failed with state FAILED due to: NA
2018-09-03 21:12:31,071-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=4905
		FILE: Number of bytes written=1504977
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=361
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=33
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Map input records=15
		Map output records=15
		Map output bytes=275
		Map output materialized bytes=341
		Input split bytes=756
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=341
		Reduce input records=0
		Reduce output records=0
		Spilled Records=15
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1145044992
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2018-09-03 21:19:17,471-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 21:19:19,216-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 21:19:19,334-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 21:19:19,335-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 21:19:19,780-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 21:19:19,796-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 21:19:19,876-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
2018-09-03 21:19:19,958-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 21:19:20,019-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3
2018-09-03 21:19:20,181-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1824690232_0001
2018-09-03 21:19:20,184-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 21:19:20,317-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 21:19:20,318-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1824690232_0001
2018-09-03 21:19:20,319-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 21:19:20,328-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:19:20,328-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:19:20,330-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 21:19:20,392-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 21:19:20,393-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1824690232_0001_m_000000_0
2018-09-03 21:19:20,443-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:19:20,443-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:19:20,454-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:19:20,455-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:19:20,458-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t4.txt:0+72
2018-09-03 21:19:20,525-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:19:20,525-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:19:20,525-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:19:20,525-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:19:20,525-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:19:20,529-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:19:20,667-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:19:20,670-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:19:20,670-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:19:20,670-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 128; bufvoid = 104857600
2018-09-03 21:19:20,670-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 21:19:20,700-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:19:20,713-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1824690232_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 21:19:20,716-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:19:20,716-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1824690232_0001_m_000000_0' done.
2018-09-03 21:19:20,727-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1824690232_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=856
		FILE: Number of bytes written=503912
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=72
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=128
		Map output materialized bytes=154
		Input split bytes=251
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=234356736
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:19:20,727-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1824690232_0001_m_000000_0
2018-09-03 21:19:20,727-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1824690232_0001_m_000001_0
2018-09-03 21:19:20,729-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:19:20,729-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:19:20,729-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:19:20,729-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:19:20,731-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t3.txt:0+62
2018-09-03 21:19:20,807-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:19:20,808-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:19:20,809-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:19:20,809-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:19:20,809-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:19:20,810-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:19:20,818-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:19:20,818-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:19:20,818-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:19:20,818-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 110; bufvoid = 104857600
2018-09-03 21:19:20,818-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 21:19:20,840-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:19:20,852-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1824690232_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 21:19:20,855-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:19:20,855-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1824690232_0001_m_000001_0' done.
2018-09-03 21:19:20,856-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1824690232_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=1635
		FILE: Number of bytes written=504102
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=134
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=110
		Map output materialized bytes=134
		Input split bytes=251
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=339738624
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:19:20,856-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1824690232_0001_m_000001_0
2018-09-03 21:19:20,857-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1824690232_0001_m_000002_0
2018-09-03 21:19:20,858-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:19:20,858-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:19:20,858-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:19:20,858-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:19:20,860-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/s1.txt:0+21
2018-09-03 21:19:20,923-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:19:20,923-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:19:20,923-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:19:20,923-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:19:20,923-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:19:20,924-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:19:20,933-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:19:20,934-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:19:20,934-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:19:20,934-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 37; bufvoid = 104857600
2018-09-03 21:19:20,934-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2018-09-03 21:19:20,948-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:19:20,965-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1824690232_0001_m_000002_0 is done. And is in the process of committing
2018-09-03 21:19:20,970-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:19:20,970-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1824690232_0001_m_000002_0' done.
2018-09-03 21:19:20,971-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1824690232_0001_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=2414
		FILE: Number of bytes written=504211
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=37
		Map output materialized bytes=53
		Input split bytes=254
		Combine input records=0
		Spilled Records=2
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=445120512
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:19:20,972-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1824690232_0001_m_000002_0
2018-09-03 21:19:20,972-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 21:19:20,977-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 21:19:20,979-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1824690232_0001_r_000000_0
2018-09-03 21:19:21,003-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:19:21,004-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:19:21,008-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:19:21,009-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:19:21,014-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1c12e5c3
2018-09-03 21:19:21,016-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:19:21,060-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:19:21,063-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1824690232_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:19:21,104-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1824690232_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2018-09-03 21:19:21,109-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 23 bytes from map-output for attempt_local1824690232_0001_m_000002_0
2018-09-03 21:19:21,110-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->23
2018-09-03 21:19:21,113-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1824690232_0001_m_000000_0 decomp: 84 len: 88 to MEMORY
2018-09-03 21:19:21,113-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 84 bytes from map-output for attempt_local1824690232_0001_m_000000_0
2018-09-03 21:19:21,113-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 84, inMemoryMapOutputs.size() -> 2, commitMemory -> 23, usedMemory ->107
2018-09-03 21:19:21,114-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1824690232_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 21:19:21,115-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local1824690232_0001_m_000001_0
2018-09-03 21:19:21,115-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 3, commitMemory -> 107, usedMemory ->170
2018-09-03 21:19:21,115-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:19:21,118-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:19:21,119-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:19:21,133-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 21:19:21,133-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 140 bytes
2018-09-03 21:19:21,139-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 170 bytes to disk to satisfy reduce memory limit
2018-09-03 21:19:21,139-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 170 bytes from disk
2018-09-03 21:19:21,140-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:19:21,140-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:19:21,141-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 156 bytes
2018-09-03 21:19:21,141-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:19:21,175-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 21:19:21,194-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1824690232_0001_r_000001_0
2018-09-03 21:19:21,197-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:19:21,197-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:19:21,198-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:19:21,198-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:19:21,198-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4056ffd8
2018-09-03 21:19:21,199-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:19:21,202-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:19:21,204-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1824690232_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:19:21,209-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1824690232_0001_m_000002_0 decomp: 22 len: 26 to MEMORY
2018-09-03 21:19:21,210-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local1824690232_0001_m_000002_0
2018-09-03 21:19:21,210-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2018-09-03 21:19:21,211-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1824690232_0001_m_000000_0 decomp: 62 len: 66 to MEMORY
2018-09-03 21:19:21,212-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local1824690232_0001_m_000000_0
2018-09-03 21:19:21,212-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->84
2018-09-03 21:19:21,213-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1824690232_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 21:19:21,215-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local1824690232_0001_m_000001_0
2018-09-03 21:19:21,215-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 3, commitMemory -> 84, usedMemory ->147
2018-09-03 21:19:21,217-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:19:21,218-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:19:21,219-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:19:21,227-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 21:19:21,227-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 117 bytes
2018-09-03 21:19:21,238-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 147 bytes to disk to satisfy reduce memory limit
2018-09-03 21:19:21,239-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 147 bytes from disk
2018-09-03 21:19:21,239-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:19:21,239-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:19:21,239-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 133 bytes
2018-09-03 21:19:21,239-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:19:21,244-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 21:19:21,253-[TS] WARN Thread-22 org.apache.hadoop.mapred.LocalJobRunner - job_local1824690232_0001
java.lang.Exception: java.lang.ClassCastException: union.app.MyUnionCombineKey cannot be cast to sort.app.MyCombineKey
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:559)
Caused by: java.lang.ClassCastException: union.app.MyUnionCombineKey cannot be cast to sort.app.MyCombineKey
	at union.app.MyUnionReducer.reduce(MyUnionReducer.java:10)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:628)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:390)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:347)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-09-03 21:19:21,325-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1824690232_0001 running in uber mode : false
2018-09-03 21:19:21,326-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-09-03 21:19:21,327-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1824690232_0001 failed with state FAILED due to: NA
2018-09-03 21:19:21,337-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=4905
		FILE: Number of bytes written=1512225
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=361
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=33
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Map input records=15
		Map output records=15
		Map output bytes=275
		Map output materialized bytes=341
		Input split bytes=756
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=341
		Reduce input records=0
		Reduce output records=0
		Spilled Records=15
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1019215872
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=0
2018-09-03 21:19:49,911-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 21:19:51,415-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 21:19:51,483-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 21:19:51,483-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 21:19:59,097-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 21:20:00,271-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 21:20:00,332-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 21:20:00,332-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 21:20:00,598-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 21:20:00,611-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 21:20:00,653-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
2018-09-03 21:20:00,686-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 21:20:00,739-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3
2018-09-03 21:20:00,877-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local459754385_0001
2018-09-03 21:20:00,879-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 21:20:01,029-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 21:20:01,030-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local459754385_0001
2018-09-03 21:20:01,031-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 21:20:01,037-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:20:01,037-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:20:01,039-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 21:20:01,074-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 21:20:01,074-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local459754385_0001_m_000000_0
2018-09-03 21:20:01,099-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:20:01,099-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:20:01,108-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:20:01,109-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:20:01,112-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t4.txt:0+72
2018-09-03 21:20:01,207-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:20:01,207-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:20:01,207-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:20:01,207-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:20:01,207-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:20:01,213-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:20:01,297-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:20:01,300-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:20:01,300-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:20:01,300-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 128; bufvoid = 104857600
2018-09-03 21:20:01,300-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 21:20:01,325-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:20:01,339-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local459754385_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 21:20:01,341-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:20:01,341-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local459754385_0001_m_000000_0' done.
2018-09-03 21:20:01,353-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local459754385_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=856
		FILE: Number of bytes written=501496
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=72
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=128
		Map output materialized bytes=154
		Input split bytes=251
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=278396928
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:20:01,353-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local459754385_0001_m_000000_0
2018-09-03 21:20:01,353-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local459754385_0001_m_000001_0
2018-09-03 21:20:01,354-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:20:01,354-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:20:01,355-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:20:01,355-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:20:01,356-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t3.txt:0+62
2018-09-03 21:20:01,433-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:20:01,433-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:20:01,433-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:20:01,433-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:20:01,433-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:20:01,434-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:20:01,446-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:20:01,446-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:20:01,446-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:20:01,446-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 110; bufvoid = 104857600
2018-09-03 21:20:01,446-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 21:20:01,459-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:20:01,465-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local459754385_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 21:20:01,468-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:20:01,468-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local459754385_0001_m_000001_0' done.
2018-09-03 21:20:01,468-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local459754385_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=1635
		FILE: Number of bytes written=501686
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=134
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=110
		Map output materialized bytes=134
		Input split bytes=251
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=383778816
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:20:01,468-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local459754385_0001_m_000001_0
2018-09-03 21:20:01,468-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local459754385_0001_m_000002_0
2018-09-03 21:20:01,469-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:20:01,470-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:20:01,470-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:20:01,470-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:20:01,472-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/s1.txt:0+21
2018-09-03 21:20:01,540-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:20:01,540-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:20:01,540-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:20:01,540-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:20:01,540-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:20:01,540-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:20:01,555-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:20:01,555-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:20:01,555-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:20:01,555-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 37; bufvoid = 104857600
2018-09-03 21:20:01,555-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2018-09-03 21:20:01,572-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:20:01,587-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local459754385_0001_m_000002_0 is done. And is in the process of committing
2018-09-03 21:20:01,588-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:20:01,589-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local459754385_0001_m_000002_0' done.
2018-09-03 21:20:01,589-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local459754385_0001_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=2414
		FILE: Number of bytes written=501795
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=37
		Map output materialized bytes=53
		Input split bytes=254
		Combine input records=0
		Spilled Records=2
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=489160704
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:20:01,589-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local459754385_0001_m_000002_0
2018-09-03 21:20:01,589-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 21:20:01,600-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 21:20:01,600-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local459754385_0001_r_000000_0
2018-09-03 21:20:01,607-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:20:01,607-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:20:01,607-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:20:01,607-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:20:01,614-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@15dd1ba7
2018-09-03 21:20:01,615-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:20:01,635-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:20:01,637-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local459754385_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:20:01,656-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local459754385_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2018-09-03 21:20:01,659-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 23 bytes from map-output for attempt_local459754385_0001_m_000002_0
2018-09-03 21:20:01,660-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->23
2018-09-03 21:20:01,663-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local459754385_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 21:20:01,664-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local459754385_0001_m_000001_0
2018-09-03 21:20:01,664-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 2, commitMemory -> 23, usedMemory ->86
2018-09-03 21:20:01,665-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local459754385_0001_m_000000_0 decomp: 84 len: 88 to MEMORY
2018-09-03 21:20:01,666-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 84 bytes from map-output for attempt_local459754385_0001_m_000000_0
2018-09-03 21:20:01,666-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 84, inMemoryMapOutputs.size() -> 3, commitMemory -> 86, usedMemory ->170
2018-09-03 21:20:01,666-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:20:01,667-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:20:01,667-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:20:01,676-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 21:20:01,677-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 140 bytes
2018-09-03 21:20:01,683-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 170 bytes to disk to satisfy reduce memory limit
2018-09-03 21:20:01,684-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 170 bytes from disk
2018-09-03 21:20:01,684-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:20:01,684-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:20:01,685-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 156 bytes
2018-09-03 21:20:01,685-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:20:01,709-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 21:20:02,038-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local459754385_0001 running in uber mode : false
2018-09-03 21:20:02,039-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-09-03 21:20:02,235-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local459754385_0001_r_000000_0 is done. And is in the process of committing
2018-09-03 21:20:02,247-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:20:02,247-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local459754385_0001_r_000000_0 is allowed to commit now
2018-09-03 21:20:02,277-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local459754385_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/data_1/out_5
2018-09-03 21:20:02,278-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 21:20:02,278-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local459754385_0001_r_000000_0' done.
2018-09-03 21:20:02,278-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local459754385_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=3093
		FILE: Number of bytes written=501965
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=219
		HDFS: Number of read operations=18
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=182
		Reduce input records=8
		Reduce output records=7
		Spilled Records=8
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=489160704
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=219
2018-09-03 21:20:02,279-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local459754385_0001_r_000000_0
2018-09-03 21:20:02,279-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local459754385_0001_r_000001_0
2018-09-03 21:20:02,280-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:20:02,280-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:20:02,280-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:20:02,280-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:20:02,280-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@499d431f
2018-09-03 21:20:02,280-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:20:02,281-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:20:02,286-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local459754385_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:20:02,294-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local459754385_0001_m_000002_0 decomp: 22 len: 26 to MEMORY
2018-09-03 21:20:02,295-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local459754385_0001_m_000002_0
2018-09-03 21:20:02,295-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2018-09-03 21:20:02,297-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local459754385_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 21:20:02,297-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local459754385_0001_m_000001_0
2018-09-03 21:20:02,297-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->85
2018-09-03 21:20:02,299-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local459754385_0001_m_000000_0 decomp: 62 len: 66 to MEMORY
2018-09-03 21:20:02,300-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local459754385_0001_m_000000_0
2018-09-03 21:20:02,300-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 3, commitMemory -> 85, usedMemory ->147
2018-09-03 21:20:02,301-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:20:02,304-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:20:02,306-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:20:02,328-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 21:20:02,328-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 117 bytes
2018-09-03 21:20:02,337-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 147 bytes to disk to satisfy reduce memory limit
2018-09-03 21:20:02,339-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 147 bytes from disk
2018-09-03 21:20:02,339-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:20:02,339-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:20:02,340-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 133 bytes
2018-09-03 21:20:02,340-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:20:02,381-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local459754385_0001_r_000001_0 is done. And is in the process of committing
2018-09-03 21:20:02,386-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:20:02,389-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local459754385_0001_r_000001_0 is allowed to commit now
2018-09-03 21:20:02,393-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local459754385_0001_r_000001_0' to hdfs://localhost:9000/user/lizhijun/data_1/out_5
2018-09-03 21:20:02,394-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 21:20:02,394-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local459754385_0001_r_000001_0' done.
2018-09-03 21:20:02,396-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local459754385_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=3567
		FILE: Number of bytes written=502112
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=402
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=159
		Reduce input records=7
		Reduce output records=6
		Spilled Records=7
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=489160704
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=183
2018-09-03 21:20:02,396-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local459754385_0001_r_000001_0
2018-09-03 21:20:02,396-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 21:20:03,042-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 21:20:03,043-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local459754385_0001 completed successfully
2018-09-03 21:20:03,052-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=11565
		FILE: Number of bytes written=2509054
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=671
		HDFS: Number of bytes written=621
		HDFS: Number of read operations=74
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=11
	Map-Reduce Framework
		Map input records=15
		Map output records=15
		Map output bytes=275
		Map output materialized bytes=341
		Input split bytes=756
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=341
		Reduce input records=15
		Reduce output records=13
		Spilled Records=30
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2129657856
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=402
2018-09-03 21:22:31,172-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 21:22:32,605-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 21:22:32,665-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 21:22:32,665-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 21:22:32,971-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 21:22:32,982-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 21:22:33,029-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
2018-09-03 21:22:33,071-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 21:22:33,120-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3
2018-09-03 21:22:33,251-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1583643188_0001
2018-09-03 21:22:33,252-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 21:22:33,389-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 21:22:33,389-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1583643188_0001
2018-09-03 21:22:33,390-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 21:22:33,395-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:22:33,395-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:22:33,397-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 21:22:33,431-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 21:22:33,432-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1583643188_0001_m_000000_0
2018-09-03 21:22:33,446-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:22:33,446-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:22:33,456-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:22:33,457-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:22:33,460-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t4.txt:0+72
2018-09-03 21:22:33,626-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:22:33,626-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:22:33,626-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:22:33,626-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:22:33,626-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:22:33,630-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:22:33,742-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:22:33,745-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:22:33,745-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:22:33,745-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 128; bufvoid = 104857600
2018-09-03 21:22:33,745-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 21:22:33,771-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:22:33,785-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1583643188_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 21:22:33,788-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:22:33,788-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1583643188_0001_m_000000_0' done.
2018-09-03 21:22:33,795-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1583643188_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=856
		FILE: Number of bytes written=503912
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=72
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=128
		Map output materialized bytes=154
		Input split bytes=251
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=278396928
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:22:33,795-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1583643188_0001_m_000000_0
2018-09-03 21:22:33,795-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1583643188_0001_m_000001_0
2018-09-03 21:22:33,796-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:22:33,796-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:22:33,797-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:22:33,797-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:22:33,798-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t3.txt:0+62
2018-09-03 21:22:33,896-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:22:33,896-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:22:33,896-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:22:33,897-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:22:33,897-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:22:33,897-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:22:33,904-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:22:33,904-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:22:33,904-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:22:33,904-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 110; bufvoid = 104857600
2018-09-03 21:22:33,904-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 21:22:33,917-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:22:33,922-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1583643188_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 21:22:33,924-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:22:33,924-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1583643188_0001_m_000001_0' done.
2018-09-03 21:22:33,925-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1583643188_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=1635
		FILE: Number of bytes written=504102
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=134
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=110
		Map output materialized bytes=134
		Input split bytes=251
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=383778816
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:22:33,925-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1583643188_0001_m_000001_0
2018-09-03 21:22:33,925-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1583643188_0001_m_000002_0
2018-09-03 21:22:33,926-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:22:33,926-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:22:33,926-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:22:33,927-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:22:33,929-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/s1.txt:0+21
2018-09-03 21:22:34,072-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:22:34,073-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:22:34,073-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:22:34,073-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:22:34,073-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:22:34,074-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:22:34,090-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:22:34,090-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:22:34,090-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:22:34,090-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 37; bufvoid = 104857600
2018-09-03 21:22:34,091-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2018-09-03 21:22:34,104-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:22:34,109-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1583643188_0001_m_000002_0 is done. And is in the process of committing
2018-09-03 21:22:34,112-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:22:34,112-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1583643188_0001_m_000002_0' done.
2018-09-03 21:22:34,112-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1583643188_0001_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=2414
		FILE: Number of bytes written=504211
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=37
		Map output materialized bytes=53
		Input split bytes=254
		Combine input records=0
		Spilled Records=2
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=489160704
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:22:34,113-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1583643188_0001_m_000002_0
2018-09-03 21:22:34,113-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 21:22:34,115-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 21:22:34,115-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1583643188_0001_r_000000_0
2018-09-03 21:22:34,120-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:22:34,121-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:22:34,121-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:22:34,121-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:22:34,123-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@684229bd
2018-09-03 21:22:34,124-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:22:34,137-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:22:34,139-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1583643188_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:22:34,159-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1583643188_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2018-09-03 21:22:34,162-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 23 bytes from map-output for attempt_local1583643188_0001_m_000002_0
2018-09-03 21:22:34,163-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->23
2018-09-03 21:22:34,166-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1583643188_0001_m_000000_0 decomp: 84 len: 88 to MEMORY
2018-09-03 21:22:34,167-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 84 bytes from map-output for attempt_local1583643188_0001_m_000000_0
2018-09-03 21:22:34,167-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 84, inMemoryMapOutputs.size() -> 2, commitMemory -> 23, usedMemory ->107
2018-09-03 21:22:34,169-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1583643188_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 21:22:34,169-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local1583643188_0001_m_000001_0
2018-09-03 21:22:34,170-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 3, commitMemory -> 107, usedMemory ->170
2018-09-03 21:22:34,170-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:22:34,171-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:22:34,172-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:22:34,182-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 21:22:34,182-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 140 bytes
2018-09-03 21:22:34,188-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 170 bytes to disk to satisfy reduce memory limit
2018-09-03 21:22:34,188-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 170 bytes from disk
2018-09-03 21:22:34,189-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:22:34,189-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:22:34,189-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 156 bytes
2018-09-03 21:22:34,190-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:22:34,215-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 21:22:34,274-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1583643188_0001_r_000000_0 is done. And is in the process of committing
2018-09-03 21:22:34,276-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:22:34,276-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1583643188_0001_r_000000_0 is allowed to commit now
2018-09-03 21:22:34,290-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1583643188_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/data_1/out_6
2018-09-03 21:22:34,291-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 21:22:34,291-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1583643188_0001_r_000000_0' done.
2018-09-03 21:22:34,291-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1583643188_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=3093
		FILE: Number of bytes written=504381
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=219
		HDFS: Number of read operations=18
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=182
		Reduce input records=8
		Reduce output records=7
		Spilled Records=8
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=489160704
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=219
2018-09-03 21:22:34,292-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1583643188_0001_r_000000_0
2018-09-03 21:22:34,292-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1583643188_0001_r_000001_0
2018-09-03 21:22:34,293-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:22:34,294-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:22:34,294-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:22:34,294-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:22:34,294-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@74b52bb2
2018-09-03 21:22:34,294-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:22:34,295-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:22:34,296-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1583643188_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:22:34,298-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1583643188_0001_m_000002_0 decomp: 22 len: 26 to MEMORY
2018-09-03 21:22:34,298-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local1583643188_0001_m_000002_0
2018-09-03 21:22:34,298-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2018-09-03 21:22:34,300-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1583643188_0001_m_000000_0 decomp: 62 len: 66 to MEMORY
2018-09-03 21:22:34,300-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local1583643188_0001_m_000000_0
2018-09-03 21:22:34,300-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->84
2018-09-03 21:22:34,302-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1583643188_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 21:22:34,302-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local1583643188_0001_m_000001_0
2018-09-03 21:22:34,302-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 3, commitMemory -> 84, usedMemory ->147
2018-09-03 21:22:34,303-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:22:34,304-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:22:34,304-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:22:34,312-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 21:22:34,312-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 117 bytes
2018-09-03 21:22:34,317-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 147 bytes to disk to satisfy reduce memory limit
2018-09-03 21:22:34,317-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 147 bytes from disk
2018-09-03 21:22:34,317-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:22:34,318-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:22:34,318-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 133 bytes
2018-09-03 21:22:34,318-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:22:34,339-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1583643188_0001_r_000001_0 is done. And is in the process of committing
2018-09-03 21:22:34,341-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:22:34,341-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1583643188_0001_r_000001_0 is allowed to commit now
2018-09-03 21:22:34,346-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1583643188_0001_r_000001_0' to hdfs://localhost:9000/user/lizhijun/data_1/out_6
2018-09-03 21:22:34,347-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 21:22:34,347-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1583643188_0001_r_000001_0' done.
2018-09-03 21:22:34,348-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1583643188_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=3567
		FILE: Number of bytes written=504528
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=402
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=159
		Reduce input records=7
		Reduce output records=6
		Spilled Records=7
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=489160704
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=183
2018-09-03 21:22:34,348-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1583643188_0001_r_000001_0
2018-09-03 21:22:34,348-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 21:22:34,397-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1583643188_0001 running in uber mode : false
2018-09-03 21:22:34,398-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 21:22:34,399-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1583643188_0001 completed successfully
2018-09-03 21:22:34,407-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=11565
		FILE: Number of bytes written=2521134
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=671
		HDFS: Number of bytes written=621
		HDFS: Number of read operations=74
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=11
	Map-Reduce Framework
		Map input records=15
		Map output records=15
		Map output bytes=275
		Map output materialized bytes=341
		Input split bytes=756
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=341
		Reduce input records=15
		Reduce output records=13
		Spilled Records=30
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2129657856
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=402
2018-09-03 21:22:47,225-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 21:22:48,348-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 21:22:48,400-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 21:22:48,400-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 21:22:48,679-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 21:22:48,693-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 21:22:48,743-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
2018-09-03 21:22:48,777-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 21:22:48,830-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3
2018-09-03 21:22:48,971-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1045984306_0001
2018-09-03 21:22:48,973-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 21:22:49,105-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 21:22:49,106-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1045984306_0001
2018-09-03 21:22:49,106-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 21:22:49,112-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:22:49,112-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:22:49,114-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 21:22:49,143-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 21:22:49,144-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1045984306_0001_m_000000_0
2018-09-03 21:22:49,159-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:22:49,159-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:22:49,166-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:22:49,166-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:22:49,170-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t4.txt:0+72
2018-09-03 21:22:49,248-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:22:49,249-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:22:49,249-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:22:49,249-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:22:49,249-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:22:49,252-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:22:49,332-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:22:49,333-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:22:49,334-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:22:49,334-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 128; bufvoid = 104857600
2018-09-03 21:22:49,334-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 21:22:49,350-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:22:49,361-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1045984306_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 21:22:49,363-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:22:49,364-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1045984306_0001_m_000000_0' done.
2018-09-03 21:22:49,370-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1045984306_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=856
		FILE: Number of bytes written=504379
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=72
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=128
		Map output materialized bytes=154
		Input split bytes=251
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=276824064
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:22:49,371-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1045984306_0001_m_000000_0
2018-09-03 21:22:49,371-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1045984306_0001_m_000001_0
2018-09-03 21:22:49,372-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:22:49,372-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:22:49,373-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:22:49,373-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:22:49,374-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t3.txt:0+62
2018-09-03 21:22:49,427-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:22:49,427-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:22:49,427-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:22:49,427-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:22:49,427-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:22:49,428-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:22:49,435-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:22:49,436-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:22:49,436-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:22:49,436-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 110; bufvoid = 104857600
2018-09-03 21:22:49,436-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 21:22:49,452-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:22:49,462-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1045984306_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 21:22:49,464-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:22:49,465-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1045984306_0001_m_000001_0' done.
2018-09-03 21:22:49,465-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1045984306_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=1635
		FILE: Number of bytes written=504569
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=134
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=110
		Map output materialized bytes=134
		Input split bytes=251
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=382205952
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:22:49,466-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1045984306_0001_m_000001_0
2018-09-03 21:22:49,467-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1045984306_0001_m_000002_0
2018-09-03 21:22:49,468-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:22:49,468-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:22:49,468-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:22:49,469-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:22:49,472-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/s1.txt:0+21
2018-09-03 21:22:49,580-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:22:49,583-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:22:49,583-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:22:49,584-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:22:49,584-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:22:49,587-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:22:49,594-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:22:49,595-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:22:49,595-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:22:49,595-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 37; bufvoid = 104857600
2018-09-03 21:22:49,595-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2018-09-03 21:22:49,609-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:22:49,614-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1045984306_0001_m_000002_0 is done. And is in the process of committing
2018-09-03 21:22:49,616-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:22:49,616-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1045984306_0001_m_000002_0' done.
2018-09-03 21:22:49,617-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1045984306_0001_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=2414
		FILE: Number of bytes written=504678
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=37
		Map output materialized bytes=53
		Input split bytes=254
		Combine input records=0
		Spilled Records=2
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=487587840
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:22:49,617-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1045984306_0001_m_000002_0
2018-09-03 21:22:49,617-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 21:22:49,619-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 21:22:49,620-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1045984306_0001_r_000000_0
2018-09-03 21:22:49,625-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:22:49,625-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:22:49,626-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:22:49,626-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:22:49,629-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@28fab988
2018-09-03 21:22:49,630-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:22:49,648-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:22:49,650-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1045984306_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:22:49,682-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1045984306_0001_m_000000_0 decomp: 84 len: 88 to MEMORY
2018-09-03 21:22:49,691-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 84 bytes from map-output for attempt_local1045984306_0001_m_000000_0
2018-09-03 21:22:49,700-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 84, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->84
2018-09-03 21:22:49,704-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1045984306_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2018-09-03 21:22:49,705-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 23 bytes from map-output for attempt_local1045984306_0001_m_000002_0
2018-09-03 21:22:49,705-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 2, commitMemory -> 84, usedMemory ->107
2018-09-03 21:22:49,708-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1045984306_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 21:22:49,709-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local1045984306_0001_m_000001_0
2018-09-03 21:22:49,709-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 3, commitMemory -> 107, usedMemory ->170
2018-09-03 21:22:49,710-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:22:49,710-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:22:49,711-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:22:49,722-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 21:22:49,723-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 140 bytes
2018-09-03 21:22:49,733-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 170 bytes to disk to satisfy reduce memory limit
2018-09-03 21:22:49,734-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 170 bytes from disk
2018-09-03 21:22:49,734-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:22:49,734-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:22:49,735-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 156 bytes
2018-09-03 21:22:49,735-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:22:49,782-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 21:22:49,843-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1045984306_0001_r_000000_0 is done. And is in the process of committing
2018-09-03 21:22:49,846-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:22:49,846-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1045984306_0001_r_000000_0 is allowed to commit now
2018-09-03 21:22:49,857-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1045984306_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/data_1/out_7
2018-09-03 21:22:49,858-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 21:22:49,858-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1045984306_0001_r_000000_0' done.
2018-09-03 21:22:49,859-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1045984306_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=3093
		FILE: Number of bytes written=504848
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=219
		HDFS: Number of read operations=18
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=182
		Reduce input records=8
		Reduce output records=7
		Spilled Records=8
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=487587840
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=219
2018-09-03 21:22:49,859-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1045984306_0001_r_000000_0
2018-09-03 21:22:49,859-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1045984306_0001_r_000001_0
2018-09-03 21:22:49,864-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:22:49,864-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:22:49,864-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:22:49,864-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:22:49,865-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4de15e62
2018-09-03 21:22:49,865-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:22:49,865-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:22:49,866-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1045984306_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:22:49,867-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1045984306_0001_m_000000_0 decomp: 62 len: 66 to MEMORY
2018-09-03 21:22:49,868-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local1045984306_0001_m_000000_0
2018-09-03 21:22:49,868-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->62
2018-09-03 21:22:49,869-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1045984306_0001_m_000002_0 decomp: 22 len: 26 to MEMORY
2018-09-03 21:22:49,869-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local1045984306_0001_m_000002_0
2018-09-03 21:22:49,869-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 62, usedMemory ->84
2018-09-03 21:22:49,871-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1045984306_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 21:22:49,872-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local1045984306_0001_m_000001_0
2018-09-03 21:22:49,872-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 3, commitMemory -> 84, usedMemory ->147
2018-09-03 21:22:49,872-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:22:49,873-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:22:49,873-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:22:49,879-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 21:22:49,879-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 117 bytes
2018-09-03 21:22:49,884-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 147 bytes to disk to satisfy reduce memory limit
2018-09-03 21:22:49,884-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 147 bytes from disk
2018-09-03 21:22:49,884-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:22:49,884-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:22:49,885-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 133 bytes
2018-09-03 21:22:49,885-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:22:49,909-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1045984306_0001_r_000001_0 is done. And is in the process of committing
2018-09-03 21:22:49,911-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:22:49,911-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1045984306_0001_r_000001_0 is allowed to commit now
2018-09-03 21:22:49,916-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1045984306_0001_r_000001_0' to hdfs://localhost:9000/user/lizhijun/data_1/out_7
2018-09-03 21:22:49,917-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 21:22:49,917-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1045984306_0001_r_000001_0' done.
2018-09-03 21:22:49,917-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1045984306_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=3567
		FILE: Number of bytes written=504995
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=402
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=159
		Reduce input records=7
		Reduce output records=6
		Spilled Records=7
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=487587840
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=183
2018-09-03 21:22:49,918-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1045984306_0001_r_000001_0
2018-09-03 21:22:49,918-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 21:22:50,110-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1045984306_0001 running in uber mode : false
2018-09-03 21:22:50,111-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 21:22:50,112-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1045984306_0001 completed successfully
2018-09-03 21:22:50,121-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=11565
		FILE: Number of bytes written=2523469
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=671
		HDFS: Number of bytes written=621
		HDFS: Number of read operations=74
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=11
	Map-Reduce Framework
		Map input records=15
		Map output records=15
		Map output bytes=275
		Map output materialized bytes=341
		Input split bytes=756
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=341
		Reduce input records=15
		Reduce output records=13
		Spilled Records=30
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2121793536
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=402
2018-09-03 21:25:11,155-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 21:25:12,479-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 21:25:12,537-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 21:25:12,538-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 21:25:12,909-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 21:25:12,925-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 21:25:12,975-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
2018-09-03 21:25:13,018-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 21:25:13,069-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3
2018-09-03 21:25:13,212-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1514577028_0001
2018-09-03 21:25:13,214-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 21:25:13,354-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 21:25:13,354-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 21:25:13,355-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1514577028_0001
2018-09-03 21:25:13,360-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:25:13,360-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:25:13,362-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 21:25:13,398-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 21:25:13,398-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1514577028_0001_m_000000_0
2018-09-03 21:25:13,419-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:25:13,419-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:25:13,431-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:25:13,432-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:25:13,435-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t4.txt:0+72
2018-09-03 21:25:13,521-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:25:13,522-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:25:13,522-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:25:13,522-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:25:13,522-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:25:13,526-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:25:13,632-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:25:13,636-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:25:13,636-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:25:13,636-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 128; bufvoid = 104857600
2018-09-03 21:25:13,636-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 21:25:13,660-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:25:13,673-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1514577028_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 21:25:13,675-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:25:13,675-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1514577028_0001_m_000000_0' done.
2018-09-03 21:25:13,683-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1514577028_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=856
		FILE: Number of bytes written=504379
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=72
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=128
		Map output materialized bytes=154
		Input split bytes=251
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=277348352
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:25:13,684-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1514577028_0001_m_000000_0
2018-09-03 21:25:13,684-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1514577028_0001_m_000001_0
2018-09-03 21:25:13,685-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:25:13,685-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:25:13,686-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:25:13,686-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:25:13,687-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t3.txt:0+62
2018-09-03 21:25:13,751-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:25:13,751-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:25:13,751-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:25:13,751-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:25:13,751-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:25:13,752-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:25:13,769-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:25:13,769-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:25:13,769-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:25:13,769-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 110; bufvoid = 104857600
2018-09-03 21:25:13,769-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 21:25:13,779-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:25:13,786-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1514577028_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 21:25:13,789-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:25:13,790-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1514577028_0001_m_000001_0' done.
2018-09-03 21:25:13,791-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1514577028_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=1635
		FILE: Number of bytes written=504569
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=134
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=110
		Map output materialized bytes=134
		Input split bytes=251
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=382730240
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:25:13,791-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1514577028_0001_m_000001_0
2018-09-03 21:25:13,791-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1514577028_0001_m_000002_0
2018-09-03 21:25:13,792-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:25:13,793-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:25:13,794-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:25:13,795-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:25:13,798-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/s1.txt:0+21
2018-09-03 21:25:13,886-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:25:13,887-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:25:13,887-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:25:13,887-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:25:13,887-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:25:13,888-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:25:13,897-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:25:13,897-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:25:13,897-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:25:13,898-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 37; bufvoid = 104857600
2018-09-03 21:25:13,898-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2018-09-03 21:25:13,918-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:25:13,924-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1514577028_0001_m_000002_0 is done. And is in the process of committing
2018-09-03 21:25:13,927-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:25:13,927-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1514577028_0001_m_000002_0' done.
2018-09-03 21:25:13,928-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1514577028_0001_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=2414
		FILE: Number of bytes written=504678
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=37
		Map output materialized bytes=53
		Input split bytes=254
		Combine input records=0
		Spilled Records=2
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=488112128
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:25:13,928-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1514577028_0001_m_000002_0
2018-09-03 21:25:13,928-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 21:25:13,931-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 21:25:13,931-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1514577028_0001_r_000000_0
2018-09-03 21:25:13,938-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:25:13,938-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:25:13,938-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:25:13,938-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:25:13,940-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@16f896d
2018-09-03 21:25:13,942-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:25:13,961-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:25:13,963-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1514577028_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:25:13,982-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1514577028_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2018-09-03 21:25:13,985-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 23 bytes from map-output for attempt_local1514577028_0001_m_000002_0
2018-09-03 21:25:13,986-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->23
2018-09-03 21:25:13,988-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1514577028_0001_m_000000_0 decomp: 84 len: 88 to MEMORY
2018-09-03 21:25:13,989-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 84 bytes from map-output for attempt_local1514577028_0001_m_000000_0
2018-09-03 21:25:13,989-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 84, inMemoryMapOutputs.size() -> 2, commitMemory -> 23, usedMemory ->107
2018-09-03 21:25:13,990-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1514577028_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 21:25:13,991-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local1514577028_0001_m_000001_0
2018-09-03 21:25:13,991-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 3, commitMemory -> 107, usedMemory ->170
2018-09-03 21:25:13,992-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:25:13,992-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:25:13,993-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:25:14,006-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 21:25:14,006-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 140 bytes
2018-09-03 21:25:14,012-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 170 bytes to disk to satisfy reduce memory limit
2018-09-03 21:25:14,013-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 170 bytes from disk
2018-09-03 21:25:14,013-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:25:14,013-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:25:14,014-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 156 bytes
2018-09-03 21:25:14,014-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:25:14,037-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 21:25:14,095-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1514577028_0001_r_000000_0 is done. And is in the process of committing
2018-09-03 21:25:14,098-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:25:14,098-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1514577028_0001_r_000000_0 is allowed to commit now
2018-09-03 21:25:14,112-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1514577028_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/data_1/out_8
2018-09-03 21:25:14,113-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 21:25:14,113-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1514577028_0001_r_000000_0' done.
2018-09-03 21:25:14,114-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1514577028_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=3093
		FILE: Number of bytes written=504848
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=146
		HDFS: Number of read operations=18
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=182
		Reduce input records=8
		Reduce output records=7
		Spilled Records=8
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=488112128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=146
2018-09-03 21:25:14,114-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1514577028_0001_r_000000_0
2018-09-03 21:25:14,120-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1514577028_0001_r_000001_0
2018-09-03 21:25:14,121-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:25:14,121-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:25:14,122-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:25:14,122-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:25:14,122-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5a5d6c4d
2018-09-03 21:25:14,122-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:25:14,123-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:25:14,124-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1514577028_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:25:14,126-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1514577028_0001_m_000002_0 decomp: 22 len: 26 to MEMORY
2018-09-03 21:25:14,127-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local1514577028_0001_m_000002_0
2018-09-03 21:25:14,127-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2018-09-03 21:25:14,129-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1514577028_0001_m_000000_0 decomp: 62 len: 66 to MEMORY
2018-09-03 21:25:14,129-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local1514577028_0001_m_000000_0
2018-09-03 21:25:14,129-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->84
2018-09-03 21:25:14,131-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1514577028_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 21:25:14,131-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local1514577028_0001_m_000001_0
2018-09-03 21:25:14,131-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 3, commitMemory -> 84, usedMemory ->147
2018-09-03 21:25:14,131-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:25:14,132-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:25:14,132-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:25:14,140-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 21:25:14,140-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 117 bytes
2018-09-03 21:25:14,150-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 147 bytes to disk to satisfy reduce memory limit
2018-09-03 21:25:14,151-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 147 bytes from disk
2018-09-03 21:25:14,151-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:25:14,151-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:25:14,151-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 133 bytes
2018-09-03 21:25:14,152-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:25:14,173-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1514577028_0001_r_000001_0 is done. And is in the process of committing
2018-09-03 21:25:14,174-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:25:14,175-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1514577028_0001_r_000001_0 is allowed to commit now
2018-09-03 21:25:14,181-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1514577028_0001_r_000001_0' to hdfs://localhost:9000/user/lizhijun/data_1/out_8
2018-09-03 21:25:14,181-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 21:25:14,182-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1514577028_0001_r_000001_0' done.
2018-09-03 21:25:14,182-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1514577028_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=3567
		FILE: Number of bytes written=504995
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=268
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=159
		Reduce input records=7
		Reduce output records=6
		Spilled Records=7
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=488112128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=122
2018-09-03 21:25:14,182-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1514577028_0001_r_000001_0
2018-09-03 21:25:14,182-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 21:25:14,371-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1514577028_0001 running in uber mode : false
2018-09-03 21:25:14,372-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 21:25:14,373-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1514577028_0001 completed successfully
2018-09-03 21:25:14,381-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=11565
		FILE: Number of bytes written=2523469
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=671
		HDFS: Number of bytes written=414
		HDFS: Number of read operations=74
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=11
	Map-Reduce Framework
		Map input records=15
		Map output records=15
		Map output bytes=275
		Map output materialized bytes=341
		Input split bytes=756
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=341
		Reduce input records=15
		Reduce output records=13
		Spilled Records=30
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2124414976
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=268
2018-09-03 21:27:35,436-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 21:27:37,075-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 21:27:37,152-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 21:27:37,153-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 21:27:37,461-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 21:27:37,475-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 21:27:37,536-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
2018-09-03 21:27:37,587-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 21:27:37,638-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3
2018-09-03 21:27:37,775-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local227813263_0001
2018-09-03 21:27:37,777-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 21:27:37,909-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 21:27:37,910-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local227813263_0001
2018-09-03 21:27:37,910-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 21:27:37,917-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:27:37,917-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:27:37,919-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 21:27:37,960-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 21:27:37,961-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local227813263_0001_m_000000_0
2018-09-03 21:27:37,978-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:27:37,978-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:27:37,989-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:27:37,990-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:27:37,994-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t4.txt:0+72
2018-09-03 21:27:38,081-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:27:38,081-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:27:38,081-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:27:38,082-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:27:38,082-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:27:38,084-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:27:38,193-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:27:38,196-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:27:38,196-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:27:38,196-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 128; bufvoid = 104857600
2018-09-03 21:27:38,196-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 21:27:38,213-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:27:38,230-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local227813263_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 21:27:38,233-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:27:38,233-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local227813263_0001_m_000000_0' done.
2018-09-03 21:27:38,239-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local227813263_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=856
		FILE: Number of bytes written=501961
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=72
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=128
		Map output materialized bytes=154
		Input split bytes=251
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=274202624
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:27:38,239-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local227813263_0001_m_000000_0
2018-09-03 21:27:38,240-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local227813263_0001_m_000001_0
2018-09-03 21:27:38,241-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:27:38,241-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:27:38,241-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:27:38,241-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:27:38,242-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t3.txt:0+62
2018-09-03 21:27:38,370-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:27:38,370-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:27:38,370-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:27:38,371-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:27:38,371-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:27:38,371-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:27:38,379-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:27:38,379-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:27:38,379-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:27:38,379-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 110; bufvoid = 104857600
2018-09-03 21:27:38,380-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 21:27:38,397-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:27:38,403-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local227813263_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 21:27:38,405-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:27:38,406-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local227813263_0001_m_000001_0' done.
2018-09-03 21:27:38,406-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local227813263_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=1635
		FILE: Number of bytes written=502151
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=134
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=110
		Map output materialized bytes=134
		Input split bytes=251
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=379584512
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:27:38,407-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local227813263_0001_m_000001_0
2018-09-03 21:27:38,407-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local227813263_0001_m_000002_0
2018-09-03 21:27:38,408-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:27:38,408-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:27:38,408-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:27:38,409-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:27:38,410-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/s1.txt:0+21
2018-09-03 21:27:38,544-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:27:38,544-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:27:38,544-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:27:38,544-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:27:38,544-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:27:38,545-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:27:38,572-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:27:38,572-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:27:38,573-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:27:38,573-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 37; bufvoid = 104857600
2018-09-03 21:27:38,573-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2018-09-03 21:27:38,585-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:27:38,592-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local227813263_0001_m_000002_0 is done. And is in the process of committing
2018-09-03 21:27:38,593-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:27:38,593-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local227813263_0001_m_000002_0' done.
2018-09-03 21:27:38,594-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local227813263_0001_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=2414
		FILE: Number of bytes written=502260
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=37
		Map output materialized bytes=53
		Input split bytes=254
		Combine input records=0
		Spilled Records=2
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=484966400
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:27:38,594-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local227813263_0001_m_000002_0
2018-09-03 21:27:38,594-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 21:27:38,598-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 21:27:38,598-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local227813263_0001_r_000000_0
2018-09-03 21:27:38,605-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:27:38,605-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:27:38,606-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:27:38,606-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:27:38,612-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2025e28a
2018-09-03 21:27:38,613-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:27:38,630-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:27:38,633-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local227813263_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:27:38,655-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local227813263_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2018-09-03 21:27:38,660-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 23 bytes from map-output for attempt_local227813263_0001_m_000002_0
2018-09-03 21:27:38,661-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->23
2018-09-03 21:27:38,663-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local227813263_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 21:27:38,664-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local227813263_0001_m_000001_0
2018-09-03 21:27:38,664-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 2, commitMemory -> 23, usedMemory ->86
2018-09-03 21:27:38,666-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local227813263_0001_m_000000_0 decomp: 84 len: 88 to MEMORY
2018-09-03 21:27:38,666-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 84 bytes from map-output for attempt_local227813263_0001_m_000000_0
2018-09-03 21:27:38,666-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 84, inMemoryMapOutputs.size() -> 3, commitMemory -> 86, usedMemory ->170
2018-09-03 21:27:38,666-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:27:38,667-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:27:38,667-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:27:38,676-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 21:27:38,677-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 140 bytes
2018-09-03 21:27:38,683-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 170 bytes to disk to satisfy reduce memory limit
2018-09-03 21:27:38,683-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 170 bytes from disk
2018-09-03 21:27:38,684-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:27:38,684-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:27:38,684-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 156 bytes
2018-09-03 21:27:38,685-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:27:38,710-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 21:27:38,917-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local227813263_0001 running in uber mode : false
2018-09-03 21:27:38,918-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-09-03 21:27:39,175-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local227813263_0001_r_000000_0 is done. And is in the process of committing
2018-09-03 21:27:39,177-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:27:39,177-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local227813263_0001_r_000000_0 is allowed to commit now
2018-09-03 21:27:39,193-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local227813263_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/data_1/out_9
2018-09-03 21:27:39,193-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 21:27:39,194-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local227813263_0001_r_000000_0' done.
2018-09-03 21:27:39,194-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local227813263_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=3093
		FILE: Number of bytes written=502430
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=150
		HDFS: Number of read operations=18
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=182
		Reduce input records=8
		Reduce output records=7
		Spilled Records=8
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=484966400
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=150
2018-09-03 21:27:39,195-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local227813263_0001_r_000000_0
2018-09-03 21:27:39,195-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local227813263_0001_r_000001_0
2018-09-03 21:27:39,196-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:27:39,196-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:27:39,196-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:27:39,196-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:27:39,196-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7e886c78
2018-09-03 21:27:39,196-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:27:39,197-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:27:39,198-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local227813263_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:27:39,200-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local227813263_0001_m_000002_0 decomp: 22 len: 26 to MEMORY
2018-09-03 21:27:39,200-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local227813263_0001_m_000002_0
2018-09-03 21:27:39,201-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2018-09-03 21:27:39,202-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local227813263_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 21:27:39,202-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local227813263_0001_m_000001_0
2018-09-03 21:27:39,202-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->85
2018-09-03 21:27:39,204-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local227813263_0001_m_000000_0 decomp: 62 len: 66 to MEMORY
2018-09-03 21:27:39,204-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local227813263_0001_m_000000_0
2018-09-03 21:27:39,204-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 3, commitMemory -> 85, usedMemory ->147
2018-09-03 21:27:39,205-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:27:39,205-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:27:39,205-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:27:39,211-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 21:27:39,211-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 117 bytes
2018-09-03 21:27:39,217-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 147 bytes to disk to satisfy reduce memory limit
2018-09-03 21:27:39,217-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 147 bytes from disk
2018-09-03 21:27:39,217-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:27:39,218-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:27:39,218-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 133 bytes
2018-09-03 21:27:39,218-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:27:39,237-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local227813263_0001_r_000001_0 is done. And is in the process of committing
2018-09-03 21:27:39,239-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:27:39,239-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local227813263_0001_r_000001_0 is allowed to commit now
2018-09-03 21:27:39,245-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local227813263_0001_r_000001_0' to hdfs://localhost:9000/user/lizhijun/data_1/out_9
2018-09-03 21:27:39,245-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 21:27:39,246-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local227813263_0001_r_000001_0' done.
2018-09-03 21:27:39,246-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local227813263_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=3567
		FILE: Number of bytes written=502577
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=271
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=159
		Reduce input records=7
		Reduce output records=6
		Spilled Records=7
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=484966400
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=121
2018-09-03 21:27:39,246-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local227813263_0001_r_000001_0
2018-09-03 21:27:39,246-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 21:27:39,923-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 21:27:39,924-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local227813263_0001 completed successfully
2018-09-03 21:27:39,936-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=11565
		FILE: Number of bytes written=2511379
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=671
		HDFS: Number of bytes written=421
		HDFS: Number of read operations=74
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=11
	Map-Reduce Framework
		Map input records=15
		Map output records=15
		Map output bytes=275
		Map output materialized bytes=341
		Input split bytes=756
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=341
		Reduce input records=15
		Reduce output records=13
		Spilled Records=30
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2108686336
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=271
2018-09-03 21:29:42,807-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 21:29:44,183-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 21:29:44,239-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 21:29:44,239-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 21:29:44,521-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 21:29:44,534-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 21:29:44,577-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1
2018-09-03 21:29:44,614-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 21:29:44,669-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3
2018-09-03 21:29:44,801-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local635416926_0001
2018-09-03 21:29:44,803-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 21:29:44,930-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 21:29:44,930-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local635416926_0001
2018-09-03 21:29:44,931-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 21:29:44,937-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:29:44,937-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:29:44,938-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 21:29:44,969-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 21:29:44,969-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local635416926_0001_m_000000_0
2018-09-03 21:29:44,984-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:29:44,984-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:29:44,994-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:29:44,994-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:29:44,997-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t4.txt:0+72
2018-09-03 21:29:45,073-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:29:45,074-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:29:45,074-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:29:45,074-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:29:45,074-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:29:45,077-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:29:45,186-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:29:45,188-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:29:45,188-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:29:45,188-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 128; bufvoid = 104857600
2018-09-03 21:29:45,189-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 21:29:45,205-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:29:45,216-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local635416926_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 21:29:45,219-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:29:45,219-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local635416926_0001_m_000000_0' done.
2018-09-03 21:29:45,225-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local635416926_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=856
		FILE: Number of bytes written=501498
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=72
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=128
		Map output materialized bytes=154
		Input split bytes=251
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=277348352
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:29:45,225-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local635416926_0001_m_000000_0
2018-09-03 21:29:45,225-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local635416926_0001_m_000001_0
2018-09-03 21:29:45,226-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:29:45,226-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:29:45,227-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:29:45,227-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:29:45,229-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/t3.txt:0+62
2018-09-03 21:29:45,285-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:29:45,285-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:29:45,285-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:29:45,285-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:29:45,285-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:29:45,285-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:29:45,295-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:29:45,295-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:29:45,295-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:29:45,295-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 110; bufvoid = 104857600
2018-09-03 21:29:45,295-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 21:29:45,324-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:29:45,333-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local635416926_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 21:29:45,335-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:29:45,335-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local635416926_0001_m_000001_0' done.
2018-09-03 21:29:45,336-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local635416926_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=1635
		FILE: Number of bytes written=501688
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=134
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=110
		Map output materialized bytes=134
		Input split bytes=251
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=382730240
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:29:45,336-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local635416926_0001_m_000001_0
2018-09-03 21:29:45,336-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local635416926_0001_m_000002_0
2018-09-03 21:29:45,337-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:29:45,337-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:29:45,338-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:29:45,338-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:29:45,340-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data_1/s1.txt:0+21
2018-09-03 21:29:45,400-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:29:45,400-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:29:45,400-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:29:45,400-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:29:45,400-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:29:45,401-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:29:45,407-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:29:45,408-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:29:45,408-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:29:45,408-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 37; bufvoid = 104857600
2018-09-03 21:29:45,408-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2018-09-03 21:29:45,419-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:29:45,425-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local635416926_0001_m_000002_0 is done. And is in the process of committing
2018-09-03 21:29:45,428-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:29:45,428-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local635416926_0001_m_000002_0' done.
2018-09-03 21:29:45,428-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local635416926_0001_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=2414
		FILE: Number of bytes written=501797
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=13
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=37
		Map output materialized bytes=53
		Input split bytes=254
		Combine input records=0
		Spilled Records=2
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=488112128
	File Input Format Counters 
		Bytes Read=0
2018-09-03 21:29:45,428-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local635416926_0001_m_000002_0
2018-09-03 21:29:45,429-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 21:29:45,431-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 21:29:45,432-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local635416926_0001_r_000000_0
2018-09-03 21:29:45,436-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:29:45,436-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:29:45,437-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:29:45,437-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:29:45,439-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@528f1fe1
2018-09-03 21:29:45,440-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:29:45,453-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:29:45,454-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local635416926_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:29:45,472-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local635416926_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 21:29:45,475-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local635416926_0001_m_000001_0
2018-09-03 21:29:45,476-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
2018-09-03 21:29:45,479-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local635416926_0001_m_000000_0 decomp: 84 len: 88 to MEMORY
2018-09-03 21:29:45,479-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 84 bytes from map-output for attempt_local635416926_0001_m_000000_0
2018-09-03 21:29:45,479-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 84, inMemoryMapOutputs.size() -> 2, commitMemory -> 63, usedMemory ->147
2018-09-03 21:29:45,481-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local635416926_0001_m_000002_0 decomp: 23 len: 27 to MEMORY
2018-09-03 21:29:45,481-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 23 bytes from map-output for attempt_local635416926_0001_m_000002_0
2018-09-03 21:29:45,481-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 23, inMemoryMapOutputs.size() -> 3, commitMemory -> 147, usedMemory ->170
2018-09-03 21:29:45,482-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:29:45,482-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:29:45,482-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:29:45,495-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 21:29:45,495-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 140 bytes
2018-09-03 21:29:45,501-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 170 bytes to disk to satisfy reduce memory limit
2018-09-03 21:29:45,501-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 170 bytes from disk
2018-09-03 21:29:45,502-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:29:45,502-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:29:45,503-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 156 bytes
2018-09-03 21:29:45,504-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:29:45,529-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 21:29:45,585-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local635416926_0001_r_000000_0 is done. And is in the process of committing
2018-09-03 21:29:45,590-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:29:45,590-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local635416926_0001_r_000000_0 is allowed to commit now
2018-09-03 21:29:45,606-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local635416926_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/data_1/out_10
2018-09-03 21:29:45,607-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 21:29:45,607-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local635416926_0001_r_000000_0' done.
2018-09-03 21:29:45,608-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local635416926_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=3093
		FILE: Number of bytes written=501967
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=150
		HDFS: Number of read operations=18
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=182
		Reduce input records=8
		Reduce output records=7
		Spilled Records=8
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=488112128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=150
2018-09-03 21:29:45,608-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local635416926_0001_r_000000_0
2018-09-03 21:29:45,608-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local635416926_0001_r_000001_0
2018-09-03 21:29:45,609-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:29:45,609-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:29:45,609-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:29:45,610-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:29:45,610-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@65664b66
2018-09-03 21:29:45,610-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:29:45,611-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:29:45,612-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local635416926_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:29:45,613-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local635416926_0001_m_000001_0 decomp: 63 len: 67 to MEMORY
2018-09-03 21:29:45,614-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 63 bytes from map-output for attempt_local635416926_0001_m_000001_0
2018-09-03 21:29:45,614-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 63, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->63
2018-09-03 21:29:45,617-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local635416926_0001_m_000000_0 decomp: 62 len: 66 to MEMORY
2018-09-03 21:29:45,617-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local635416926_0001_m_000000_0
2018-09-03 21:29:45,618-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 2, commitMemory -> 63, usedMemory ->125
2018-09-03 21:29:45,619-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local635416926_0001_m_000002_0 decomp: 22 len: 26 to MEMORY
2018-09-03 21:29:45,619-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local635416926_0001_m_000002_0
2018-09-03 21:29:45,620-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 3, commitMemory -> 125, usedMemory ->147
2018-09-03 21:29:45,620-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:29:45,620-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:29:45,621-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:29:45,628-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 3 sorted segments
2018-09-03 21:29:45,628-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 3 segments left of total size: 117 bytes
2018-09-03 21:29:45,634-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 3 segments, 147 bytes to disk to satisfy reduce memory limit
2018-09-03 21:29:45,634-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 147 bytes from disk
2018-09-03 21:29:45,634-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:29:45,634-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:29:45,635-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 133 bytes
2018-09-03 21:29:45,635-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:29:45,653-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local635416926_0001_r_000001_0 is done. And is in the process of committing
2018-09-03 21:29:45,655-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 3 / 3 copied.
2018-09-03 21:29:45,655-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local635416926_0001_r_000001_0 is allowed to commit now
2018-09-03 21:29:45,664-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local635416926_0001_r_000001_0' to hdfs://localhost:9000/user/lizhijun/data_1/out_10
2018-09-03 21:29:45,665-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 21:29:45,665-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local635416926_0001_r_000001_0' done.
2018-09-03 21:29:45,665-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local635416926_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=3567
		FILE: Number of bytes written=502114
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=155
		HDFS: Number of bytes written=271
		HDFS: Number of read operations=23
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=159
		Reduce input records=7
		Reduce output records=6
		Spilled Records=7
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=488112128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=121
2018-09-03 21:29:45,666-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local635416926_0001_r_000001_0
2018-09-03 21:29:45,666-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 21:29:45,938-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local635416926_0001 running in uber mode : false
2018-09-03 21:29:45,939-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 21:29:45,940-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local635416926_0001 completed successfully
2018-09-03 21:29:45,948-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=11565
		FILE: Number of bytes written=2509064
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=671
		HDFS: Number of bytes written=421
		HDFS: Number of read operations=74
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=11
	Map-Reduce Framework
		Map input records=15
		Map output records=15
		Map output bytes=275
		Map output materialized bytes=341
		Input split bytes=756
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=341
		Reduce input records=15
		Reduce output records=13
		Spilled Records=30
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2124414976
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=271
2018-09-03 21:38:29,736-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 21:38:31,049-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 21:38:31,104-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 21:38:31,104-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 21:38:31,406-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 21:38:31,417-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 21:38:31,512-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 3
2018-09-03 21:38:31,566-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:3
2018-09-03 21:38:31,701-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local797391120_0001
2018-09-03 21:38:31,703-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 21:38:31,828-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 21:38:31,828-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local797391120_0001
2018-09-03 21:38:31,829-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 21:38:31,834-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:38:31,835-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:38:31,835-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 21:38:31,875-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 21:38:31,875-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local797391120_0001_m_000000_0
2018-09-03 21:38:31,895-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:38:31,895-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:38:31,905-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:38:31,905-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:38:31,908-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t2.txt:0+58
2018-09-03 21:38:32,031-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:38:32,032-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:38:32,032-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:38:32,032-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:38:32,033-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:38:32,039-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:38:32,161-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=110}
2018-09-03 21:38:32,161-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=99}
2018-09-03 21:38:32,161-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1993, temp=89}
2018-09-03 21:38:32,161-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=10}
2018-09-03 21:38:32,162-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=67}
2018-09-03 21:38:32,162-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=10}
2018-09-03 21:38:32,162-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1993, temp=200}
2018-09-03 21:38:32,164-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:38:32,166-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:38:32,166-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:38:32,166-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-09-03 21:38:32,166-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 21:38:32,186-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:38:32,201-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local797391120_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 21:38:32,205-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:38:32,205-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local797391120_0001_m_000000_0' done.
2018-09-03 21:38:32,213-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local797391120_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=415
		FILE: Number of bytes written=499418
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=82
		Input split bytes=112
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=278396928
	File Input Format Counters 
		Bytes Read=58
2018-09-03 21:38:32,213-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local797391120_0001_m_000000_0
2018-09-03 21:38:32,213-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local797391120_0001_m_000001_0
2018-09-03 21:38:32,214-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:38:32,215-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:38:32,215-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:38:32,215-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:38:32,219-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t1.txt:0+50
2018-09-03 21:38:32,289-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:38:32,289-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:38:32,289-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:38:32,290-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:38:32,290-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:38:32,290-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:38:32,306-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=100}
2018-09-03 21:38:32,306-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=99}
2018-09-03 21:38:32,307-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=89}
2018-09-03 21:38:32,308-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=10}
2018-09-03 21:38:32,308-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=67}
2018-09-03 21:38:32,308-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=101}
2018-09-03 21:38:32,309-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:38:32,309-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:38:32,309-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:38:32,309-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-09-03 21:38:32,309-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 21:38:32,322-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:38:32,328-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local797391120_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 21:38:32,330-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:38:32,330-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local797391120_0001_m_000001_0' done.
2018-09-03 21:38:32,330-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local797391120_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=770
		FILE: Number of bytes written=499546
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=72
		Input split bytes=112
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=383778816
	File Input Format Counters 
		Bytes Read=50
2018-09-03 21:38:32,331-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local797391120_0001_m_000001_0
2018-09-03 21:38:32,331-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local797391120_0001_m_000002_0
2018-09-03 21:38:32,331-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:38:32,331-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:38:32,332-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:38:32,332-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:38:32,333-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/output:0+0
2018-09-03 21:38:32,438-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:38:32,438-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:38:32,438-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:38:32,438-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:38:32,438-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:38:32,441-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:38:32,580-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:38:32,598-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 21:38:32,605-[TS] WARN Thread-22 org.apache.hadoop.mapred.LocalJobRunner - job_local797391120_0001
java.lang.Exception: java.io.FileNotFoundException: Path is not a file: /user/lizhijun/data/output
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:90)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:76)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:153)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1927)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:738)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:426)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.FileNotFoundException: Path is not a file: /user/lizhijun/data/output
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:90)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:76)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:153)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1927)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:738)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:426)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:858)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:845)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:834)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:998)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:326)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:322)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:334)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:950)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:86)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:560)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:798)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): Path is not a file: /user/lizhijun/data/output
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:90)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:76)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:153)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1927)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:738)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:426)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1443)
	at org.apache.hadoop.ipc.Client.call(Client.java:1353)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy11.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:317)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy12.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:856)
	... 18 more
2018-09-03 21:38:32,832-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local797391120_0001 running in uber mode : false
2018-09-03 21:38:32,833-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-09-03 21:38:32,835-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local797391120_0001 failed with state FAILED due to: NA
2018-09-03 21:38:32,842-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 22
	File System Counters
		FILE: Number of bytes read=1185
		FILE: Number of bytes written=998964
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=166
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=154
		Input split bytes=224
		Combine input records=0
		Spilled Records=13
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=662175744
	File Input Format Counters 
		Bytes Read=108
2018-09-03 21:39:17,232-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 21:39:18,515-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 21:39:18,579-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 21:39:18,579-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 21:39:18,857-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 21:39:18,869-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 21:39:18,932-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 4
2018-09-03 21:39:18,987-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:4
2018-09-03 21:39:19,121-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local527227215_0001
2018-09-03 21:39:19,123-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 21:39:19,245-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 21:39:19,245-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local527227215_0001
2018-09-03 21:39:19,246-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 21:39:19,251-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:39:19,251-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:39:19,252-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 21:39:19,285-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 21:39:19,286-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local527227215_0001_m_000000_0
2018-09-03 21:39:19,305-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:39:19,305-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:39:19,313-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:39:19,313-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:39:19,317-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t2.txt:0+58
2018-09-03 21:39:19,394-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:39:19,395-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:39:19,395-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:39:19,395-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:39:19,395-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:39:19,399-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:39:19,479-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=110}
2018-09-03 21:39:19,480-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=99}
2018-09-03 21:39:19,480-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1993, temp=89}
2018-09-03 21:39:19,480-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=10}
2018-09-03 21:39:19,480-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=67}
2018-09-03 21:39:19,481-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=10}
2018-09-03 21:39:19,481-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1993, temp=200}
2018-09-03 21:39:19,483-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:39:19,485-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:39:19,485-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:39:19,485-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-09-03 21:39:19,485-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 21:39:19,503-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:39:19,514-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local527227215_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 21:39:19,517-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:39:19,517-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local527227215_0001_m_000000_0' done.
2018-09-03 21:39:19,523-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local527227215_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=534
		FILE: Number of bytes written=499537
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=82
		Input split bytes=112
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=276824064
	File Input Format Counters 
		Bytes Read=58
2018-09-03 21:39:19,523-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local527227215_0001_m_000000_0
2018-09-03 21:39:19,524-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local527227215_0001_m_000001_0
2018-09-03 21:39:19,525-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:39:19,525-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:39:19,526-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:39:19,526-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:39:19,527-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t1.txt:0+50
2018-09-03 21:39:19,583-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:39:19,583-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:39:19,583-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:39:19,583-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:39:19,583-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:39:19,584-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:39:19,593-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=100}
2018-09-03 21:39:19,593-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=99}
2018-09-03 21:39:19,593-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=89}
2018-09-03 21:39:19,593-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=10}
2018-09-03 21:39:19,593-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=67}
2018-09-03 21:39:19,594-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=101}
2018-09-03 21:39:19,594-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:39:19,594-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:39:19,594-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:39:19,594-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-09-03 21:39:19,594-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 21:39:19,606-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:39:19,612-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local527227215_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 21:39:19,614-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:39:19,614-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local527227215_0001_m_000001_0' done.
2018-09-03 21:39:19,615-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local527227215_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=1003
		FILE: Number of bytes written=499665
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=72
		Input split bytes=112
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=382205952
	File Input Format Counters 
		Bytes Read=50
2018-09-03 21:39:19,615-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local527227215_0001_m_000001_0
2018-09-03 21:39:19,615-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local527227215_0001_m_000002_0
2018-09-03 21:39:19,616-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:39:19,617-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:39:19,617-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:39:19,617-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:39:19,618-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/output:0+0
2018-09-03 21:39:19,681-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:39:19,681-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:39:19,681-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:39:19,681-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:39:19,681-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:39:19,682-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:39:19,694-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:39:19,714-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local527227215_0001_m_000003_0
2018-09-03 21:39:19,715-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:39:19,715-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:39:19,716-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:39:19,716-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:39:19,717-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/output_1:0+0
2018-09-03 21:39:19,778-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:39:19,778-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:39:19,778-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:39:19,778-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:39:19,778-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:39:19,779-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:39:19,780-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:39:19,799-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 21:39:19,804-[TS] WARN Thread-22 org.apache.hadoop.mapred.LocalJobRunner - job_local527227215_0001
java.lang.Exception: java.io.FileNotFoundException: Path is not a file: /user/lizhijun/data/output
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:90)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:76)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:153)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1927)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:738)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:426)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.FileNotFoundException: Path is not a file: /user/lizhijun/data/output
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:90)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:76)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:153)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1927)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:738)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:426)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:858)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:845)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:834)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:998)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:326)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:322)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:334)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:950)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:86)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:560)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:798)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): Path is not a file: /user/lizhijun/data/output
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:90)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:76)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:153)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1927)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:738)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:426)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1443)
	at org.apache.hadoop.ipc.Client.call(Client.java:1353)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy11.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:317)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy12.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:856)
	... 18 more
2018-09-03 21:39:20,252-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local527227215_0001 running in uber mode : false
2018-09-03 21:39:20,253-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-09-03 21:39:20,255-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local527227215_0001 failed with state FAILED due to: NA
2018-09-03 21:39:20,262-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 22
	File System Counters
		FILE: Number of bytes read=1537
		FILE: Number of bytes written=999202
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=166
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=154
		Input split bytes=224
		Combine input records=0
		Spilled Records=13
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=659030016
	File Input Format Counters 
		Bytes Read=108
2018-09-03 21:40:29,130-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 21:40:30,694-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 21:40:30,762-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 21:40:30,762-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 21:40:49,427-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 21:40:50,802-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 21:40:50,862-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 21:40:50,862-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 21:40:51,172-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 21:40:51,185-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 21:40:51,255-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 5
2018-09-03 21:40:51,307-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:5
2018-09-03 21:40:51,447-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1656467077_0001
2018-09-03 21:40:51,449-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 21:40:51,593-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 21:40:51,594-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1656467077_0001
2018-09-03 21:40:51,594-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 21:40:51,600-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:40:51,601-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:40:51,601-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 21:40:51,641-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1656467077_0001_m_000000_0
2018-09-03 21:40:51,643-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 21:40:51,662-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:40:51,662-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:40:51,674-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:40:51,675-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:40:51,679-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t2.txt:0+58
2018-09-03 21:40:51,829-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:40:51,830-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:40:51,830-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:40:51,830-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:40:51,830-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:40:51,835-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:40:51,945-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=110}
2018-09-03 21:40:51,945-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=99}
2018-09-03 21:40:51,945-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1993, temp=89}
2018-09-03 21:40:51,945-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=10}
2018-09-03 21:40:51,946-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=67}
2018-09-03 21:40:51,946-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=10}
2018-09-03 21:40:51,946-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1993, temp=200}
2018-09-03 21:40:51,948-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:40:51,951-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:40:51,951-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:40:51,951-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-09-03 21:40:51,951-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 21:40:51,975-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:40:51,989-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1656467077_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 21:40:51,992-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:40:51,992-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1656467077_0001_m_000000_0' done.
2018-09-03 21:40:51,999-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1656467077_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=657
		FILE: Number of bytes written=501609
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=82
		Input split bytes=112
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=278396928
	File Input Format Counters 
		Bytes Read=58
2018-09-03 21:40:51,999-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1656467077_0001_m_000000_0
2018-09-03 21:40:52,000-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1656467077_0001_m_000001_0
2018-09-03 21:40:52,001-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:40:52,001-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:40:52,002-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:40:52,002-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:40:52,006-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t1.txt:0+50
2018-09-03 21:40:52,137-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:40:52,140-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:40:52,140-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:40:52,140-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:40:52,140-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:40:52,144-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:40:52,152-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=100}
2018-09-03 21:40:52,152-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=99}
2018-09-03 21:40:52,152-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=89}
2018-09-03 21:40:52,153-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=10}
2018-09-03 21:40:52,153-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=67}
2018-09-03 21:40:52,153-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=101}
2018-09-03 21:40:52,154-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:40:52,154-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:40:52,154-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:40:52,155-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-09-03 21:40:52,155-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 21:40:52,171-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:40:52,177-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1656467077_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 21:40:52,180-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:40:52,180-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1656467077_0001_m_000001_0' done.
2018-09-03 21:40:52,181-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1656467077_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=1244
		FILE: Number of bytes written=501737
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=72
		Input split bytes=112
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=383778816
	File Input Format Counters 
		Bytes Read=50
2018-09-03 21:40:52,181-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1656467077_0001_m_000001_0
2018-09-03 21:40:52,181-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1656467077_0001_m_000002_0
2018-09-03 21:40:52,182-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:40:52,182-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:40:52,182-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:40:52,182-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:40:52,184-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/output:0+0
2018-09-03 21:40:52,295-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:40:52,296-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:40:52,296-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:40:52,296-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:40:52,296-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:40:52,298-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:40:52,326-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:40:52,343-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1656467077_0001_m_000003_0
2018-09-03 21:40:52,344-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:40:52,344-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:40:52,345-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:40:52,345-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:40:52,346-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/output_1:0+0
2018-09-03 21:40:52,487-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:40:52,487-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:40:52,490-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:40:52,494-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:40:52,494-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:40:52,494-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:40:52,505-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:40:52,524-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1656467077_0001_m_000004_0
2018-09-03 21:40:52,525-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:40:52,525-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:40:52,525-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:40:52,526-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:40:52,527-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/output_3:0+0
2018-09-03 21:40:52,603-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1656467077_0001 running in uber mode : false
2018-09-03 21:40:52,605-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-09-03 21:40:52,706-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:40:52,706-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:40:52,707-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:40:52,707-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:40:52,707-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:40:52,707-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:40:52,709-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:40:52,730-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 21:40:52,737-[TS] WARN Thread-22 org.apache.hadoop.mapred.LocalJobRunner - job_local1656467077_0001
java.lang.Exception: java.io.FileNotFoundException: Path is not a file: /user/lizhijun/data/output
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:90)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:76)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:153)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1927)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:738)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:426)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.io.FileNotFoundException: Path is not a file: /user/lizhijun/data/output
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:90)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:76)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:153)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1927)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:738)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:426)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:858)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:845)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:834)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:998)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:326)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:322)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:334)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:950)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:86)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:560)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:798)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): Path is not a file: /user/lizhijun/data/output
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:90)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:76)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:153)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1927)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:738)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:426)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1443)
	at org.apache.hadoop.ipc.Client.call(Client.java:1353)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy11.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:317)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy12.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:856)
	... 18 more
2018-09-03 21:40:53,613-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1656467077_0001 failed with state FAILED due to: NA
2018-09-03 21:40:53,623-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 22
	File System Counters
		FILE: Number of bytes read=1901
		FILE: Number of bytes written=1003346
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=166
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=154
		Input split bytes=224
		Combine input records=0
		Spilled Records=13
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=662175744
	File Input Format Counters 
		Bytes Read=108
2018-09-03 21:42:15,868-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-09-03 21:42:17,162-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-09-03 21:42:17,238-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-09-03 21:42:17,238-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-09-03 21:42:17,553-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-09-03 21:42:17,566-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-09-03 21:42:17,649-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-09-03 21:42:17,714-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-09-03 21:42:17,864-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local702930298_0001
2018-09-03 21:42:17,867-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-09-03 21:42:18,015-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-09-03 21:42:18,016-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local702930298_0001
2018-09-03 21:42:18,016-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-09-03 21:42:18,022-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:42:18,022-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:42:18,023-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-09-03 21:42:18,057-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-09-03 21:42:18,058-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local702930298_0001_m_000000_0
2018-09-03 21:42:18,079-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:42:18,079-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:42:18,090-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:42:18,090-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:42:18,095-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t2.txt:0+58
2018-09-03 21:42:18,177-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:42:18,177-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:42:18,177-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:42:18,177-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:42:18,177-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:42:18,180-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:42:18,266-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=110}
2018-09-03 21:42:18,266-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=99}
2018-09-03 21:42:18,267-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1993, temp=89}
2018-09-03 21:42:18,267-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=10}
2018-09-03 21:42:18,267-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=67}
2018-09-03 21:42:18,267-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=10}
2018-09-03 21:42:18,267-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1993, temp=200}
2018-09-03 21:42:18,269-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:42:18,271-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:42:18,271-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:42:18,271-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-09-03 21:42:18,271-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-09-03 21:42:18,289-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:42:18,304-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local702930298_0001_m_000000_0 is done. And is in the process of committing
2018-09-03 21:42:18,306-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:42:18,307-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local702930298_0001_m_000000_0' done.
2018-09-03 21:42:18,314-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local702930298_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=299
		FILE: Number of bytes written=498839
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=82
		Input split bytes=112
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=275775488
	File Input Format Counters 
		Bytes Read=58
2018-09-03 21:42:18,314-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local702930298_0001_m_000000_0
2018-09-03 21:42:18,314-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local702930298_0001_m_000001_0
2018-09-03 21:42:18,315-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:42:18,316-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:42:18,316-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:42:18,316-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:42:18,320-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data/t1.txt:0+50
2018-09-03 21:42:18,382-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-09-03 21:42:18,383-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-09-03 21:42:18,383-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-09-03 21:42:18,383-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-09-03 21:42:18,383-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-09-03 21:42:18,384-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-09-03 21:42:18,392-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=100}
2018-09-03 21:42:18,392-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=99}
2018-09-03 21:42:18,393-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=89}
2018-09-03 21:42:18,393-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=10}
2018-09-03 21:42:18,393-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1992, temp=67}
2018-09-03 21:42:18,393-[TS] INFO LocalJobRunner Map Task Executor #0 sort.app.MyPartitioner - MyPartitioner:MyCombineKey{year=1982, temp=101}
2018-09-03 21:42:18,394-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-09-03 21:42:18,394-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-09-03 21:42:18,394-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-09-03 21:42:18,394-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-09-03 21:42:18,394-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-09-03 21:42:18,407-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-09-03 21:42:18,414-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local702930298_0001_m_000001_0 is done. And is in the process of committing
2018-09-03 21:42:18,416-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-09-03 21:42:18,417-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local702930298_0001_m_000001_0' done.
2018-09-03 21:42:18,418-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local702930298_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=542
		FILE: Number of bytes written=498967
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=72
		Input split bytes=112
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=381157376
	File Input Format Counters 
		Bytes Read=50
2018-09-03 21:42:18,418-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local702930298_0001_m_000001_0
2018-09-03 21:42:18,418-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-09-03 21:42:18,423-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-09-03 21:42:18,423-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local702930298_0001_r_000000_0
2018-09-03 21:42:18,428-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:42:18,428-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:42:18,428-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:42:18,428-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:42:18,431-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@209fd814
2018-09-03 21:42:18,432-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:42:18,446-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:42:18,449-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local702930298_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:42:18,468-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local702930298_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2018-09-03 21:42:18,470-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local702930298_0001_m_000001_0
2018-09-03 21:42:18,471-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->62
2018-09-03 21:42:18,473-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local702930298_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2018-09-03 21:42:18,474-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 52 bytes from map-output for attempt_local702930298_0001_m_000000_0
2018-09-03 21:42:18,474-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 52, inMemoryMapOutputs.size() -> 2, commitMemory -> 62, usedMemory ->114
2018-09-03 21:42:18,474-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:42:18,475-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 21:42:18,475-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:42:18,487-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 21:42:18,488-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 94 bytes
2018-09-03 21:42:18,493-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 114 bytes to disk to satisfy reduce memory limit
2018-09-03 21:42:18,493-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 116 bytes from disk
2018-09-03 21:42:18,494-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:42:18,494-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:42:18,494-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 102 bytes
2018-09-03 21:42:18,495-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 21:42:18,525-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-09-03 21:42:19,002-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local702930298_0001_r_000000_0 is done. And is in the process of committing
2018-09-03 21:42:19,003-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 21:42:19,004-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local702930298_0001_r_000000_0 is allowed to commit now
2018-09-03 21:42:19,023-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local702930298_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/data/output_5
2018-09-03 21:42:19,024-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 21:42:19,024-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local702930298_0001 running in uber mode : false
2018-09-03 21:42:19,024-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local702930298_0001_r_000000_0' done.
2018-09-03 21:42:19,025-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local702930298_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=924
		FILE: Number of bytes written=499083
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=67
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=8
		Reduce shuffle bytes=122
		Reduce input records=11
		Reduce output records=8
		Spilled Records=11
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=381157376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=67
2018-09-03 21:42:19,025-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local702930298_0001_r_000000_0
2018-09-03 21:42:19,025-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-09-03 21:42:19,025-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local702930298_0001_r_000001_0
2018-09-03 21:42:19,026-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-09-03 21:42:19,026-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-09-03 21:42:19,027-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-09-03 21:42:19,027-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-09-03 21:42:19,027-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7910e216
2018-09-03 21:42:19,027-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-09-03 21:42:19,028-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-09-03 21:42:19,029-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local702930298_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-09-03 21:42:19,031-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local702930298_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2018-09-03 21:42:19,032-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local702930298_0001_m_000001_0
2018-09-03 21:42:19,032-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2018-09-03 21:42:19,033-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local702930298_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2018-09-03 21:42:19,034-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local702930298_0001_m_000000_0
2018-09-03 21:42:19,034-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->24
2018-09-03 21:42:19,034-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-09-03 21:42:19,035-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 21:42:19,035-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-09-03 21:42:19,041-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-09-03 21:42:19,041-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-09-03 21:42:19,046-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 24 bytes to disk to satisfy reduce memory limit
2018-09-03 21:42:19,047-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 26 bytes from disk
2018-09-03 21:42:19,047-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-09-03 21:42:19,047-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-09-03 21:42:19,047-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-09-03 21:42:19,047-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 21:42:19,484-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local702930298_0001_r_000001_0 is done. And is in the process of committing
2018-09-03 21:42:19,486-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-09-03 21:42:19,486-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local702930298_0001_r_000001_0 is allowed to commit now
2018-09-03 21:42:19,496-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local702930298_0001_r_000001_0' to hdfs://localhost:9000/user/lizhijun/data/output_5
2018-09-03 21:42:19,498-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-09-03 21:42:19,498-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local702930298_0001_r_000001_0' done.
2018-09-03 21:42:19,499-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local702930298_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1094
		FILE: Number of bytes written=499109
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=32
		Reduce input records=2
		Reduce output records=2
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=381157376
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=17
2018-09-03 21:42:19,499-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local702930298_0001_r_000001_0
2018-09-03 21:42:19,499-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-09-03 21:42:20,032-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local702930298_0001 completed successfully
2018-09-03 21:42:20,041-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=2859
		FILE: Number of bytes written=1995998
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=382
		HDFS: Number of bytes written=151
		HDFS: Number of read operations=41
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=10
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=154
		Input split bytes=224
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=154
		Reduce input records=13
		Reduce output records=10
		Spilled Records=26
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1419247616
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=84
