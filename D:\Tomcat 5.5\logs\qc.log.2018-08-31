2018-08-31 00:01:19,755-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-08-31 00:01:21,090-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-08-31 00:01:21,307-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-08-31 00:01:21,308-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-08-31 00:01:21,618-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-31 00:01:21,633-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-31 00:01:21,716-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-08-31 00:01:21,771-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-08-31 00:01:21,899-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1838643906_0001
2018-08-31 00:01:21,901-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-08-31 00:01:22,016-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-08-31 00:01:22,023-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:01:22,023-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:01:22,024-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-31 00:01:22,025-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-08-31 00:01:22,026-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1838643906_0001
2018-08-31 00:01:22,061-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-08-31 00:01:22,061-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1838643906_0001_m_000000_0
2018-08-31 00:01:22,083-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:01:22,083-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:01:22,095-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:01:22,096-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:01:22,099-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data1/t2.txt:0+58
2018-08-31 00:01:22,242-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-31 00:01:22,243-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-08-31 00:01:22,243-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-08-31 00:01:22,243-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-08-31 00:01:22,243-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-08-31 00:01:22,248-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-31 00:01:22,412-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-08-31 00:01:22,415-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-08-31 00:01:22,415-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-08-31 00:01:22,415-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-08-31 00:01:22,415-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-08-31 00:01:22,433-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-08-31 00:01:22,445-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1838643906_0001_m_000000_0 is done. And is in the process of committing
2018-08-31 00:01:22,448-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-08-31 00:01:22,448-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1838643906_0001_m_000000_0' done.
2018-08-31 00:01:22,455-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1838643906_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=301
		FILE: Number of bytes written=498811
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=76
		Input split bytes=113
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=301989888
	File Input Format Counters 
		Bytes Read=58
2018-08-31 00:01:22,455-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1838643906_0001_m_000000_0
2018-08-31 00:01:22,455-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1838643906_0001_m_000001_0
2018-08-31 00:01:22,456-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:01:22,456-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:01:22,457-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:01:22,457-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:01:22,458-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data1/t1.txt:0+50
2018-08-31 00:01:22,548-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-31 00:01:22,548-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-08-31 00:01:22,548-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-08-31 00:01:22,548-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-08-31 00:01:22,548-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-08-31 00:01:22,549-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-31 00:01:22,566-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-08-31 00:01:22,566-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-08-31 00:01:22,566-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-08-31 00:01:22,567-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-08-31 00:01:22,567-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-08-31 00:01:22,584-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-08-31 00:01:22,591-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1838643906_0001_m_000001_0 is done. And is in the process of committing
2018-08-31 00:01:22,593-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-08-31 00:01:22,593-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1838643906_0001_m_000001_0' done.
2018-08-31 00:01:22,594-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1838643906_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=546
		FILE: Number of bytes written=498909
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=66
		Input split bytes=113
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=407371776
	File Input Format Counters 
		Bytes Read=50
2018-08-31 00:01:22,594-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1838643906_0001_m_000001_0
2018-08-31 00:01:22,594-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-08-31 00:01:22,597-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-08-31 00:01:22,597-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1838643906_0001_r_000000_0
2018-08-31 00:01:22,609-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:01:22,609-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:01:22,609-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:01:22,609-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:01:22,614-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5751d801
2018-08-31 00:01:22,615-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-08-31 00:01:22,631-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-31 00:01:22,633-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1838643906_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-31 00:01:22,666-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1838643906_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2018-08-31 00:01:22,669-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local1838643906_0001_m_000001_0
2018-08-31 00:01:22,670-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->62
2018-08-31 00:01:22,673-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1838643906_0001_m_000000_0 decomp: 72 len: 76 to MEMORY
2018-08-31 00:01:22,675-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 72 bytes from map-output for attempt_local1838643906_0001_m_000000_0
2018-08-31 00:01:22,675-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 72, inMemoryMapOutputs.size() -> 2, commitMemory -> 62, usedMemory ->134
2018-08-31 00:01:22,676-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-08-31 00:01:22,677-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:01:22,677-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-08-31 00:01:22,688-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-08-31 00:01:22,688-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 114 bytes
2018-08-31 00:01:22,698-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 134 bytes to disk to satisfy reduce memory limit
2018-08-31 00:01:22,699-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 136 bytes from disk
2018-08-31 00:01:22,699-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-08-31 00:01:22,700-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-08-31 00:01:22,700-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 122 bytes
2018-08-31 00:01:22,700-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:01:22,748-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-08-31 00:01:23,040-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1838643906_0001 running in uber mode : false
2018-08-31 00:01:23,042-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-08-31 00:01:23,410-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1838643906_0001_r_000000_0 is done. And is in the process of committing
2018-08-31 00:01:23,413-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:01:23,413-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1838643906_0001_r_000000_0 is allowed to commit now
2018-08-31 00:01:23,447-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1838643906_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/output_11
2018-08-31 00:01:23,448-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-08-31 00:01:23,448-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1838643906_0001_r_000000_0' done.
2018-08-31 00:01:23,449-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1838643906_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=888
		FILE: Number of bytes written=499045
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=142
		Reduce input records=13
		Reduce output records=10
		Spilled Records=13
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=407371776
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=84
2018-08-31 00:01:23,449-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1838643906_0001_r_000000_0
2018-08-31 00:01:23,449-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-08-31 00:01:24,044-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-08-31 00:01:24,045-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1838643906_0001 completed successfully
2018-08-31 00:01:24,053-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=1735
		FILE: Number of bytes written=1496765
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=274
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=142
		Input split bytes=226
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=142
		Reduce input records=13
		Reduce output records=10
		Spilled Records=26
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=1116733440
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=84
2018-08-31 00:02:30,577-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-08-31 00:02:31,670-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-08-31 00:02:31,734-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-08-31 00:02:31,734-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-08-31 00:02:32,013-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-31 00:02:32,026-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-31 00:02:32,090-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-08-31 00:02:32,144-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-08-31 00:02:32,279-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1400508502_0001
2018-08-31 00:02:32,281-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-08-31 00:02:32,403-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-08-31 00:02:32,403-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1400508502_0001
2018-08-31 00:02:32,404-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-08-31 00:02:32,408-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:02:32,408-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:02:32,409-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-31 00:02:32,442-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1400508502_0001_m_000000_0
2018-08-31 00:02:32,444-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-08-31 00:02:32,466-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:02:32,466-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:02:32,476-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:02:32,476-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:02:32,479-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data1/t2.txt:0+58
2018-08-31 00:02:32,561-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-31 00:02:32,562-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-08-31 00:02:32,562-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-08-31 00:02:32,562-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-08-31 00:02:32,562-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-08-31 00:02:32,567-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-31 00:02:32,631-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-08-31 00:02:32,633-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-08-31 00:02:32,633-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-08-31 00:02:32,633-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-08-31 00:02:32,633-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-08-31 00:02:32,649-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-08-31 00:02:32,660-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1400508502_0001_m_000000_0 is done. And is in the process of committing
2018-08-31 00:02:32,662-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-08-31 00:02:32,662-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1400508502_0001_m_000000_0' done.
2018-08-31 00:02:32,670-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1400508502_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=301
		FILE: Number of bytes written=498867
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=88
		Input split bytes=113
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=277348352
	File Input Format Counters 
		Bytes Read=58
2018-08-31 00:02:32,670-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1400508502_0001_m_000000_0
2018-08-31 00:02:32,671-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1400508502_0001_m_000001_0
2018-08-31 00:02:32,672-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:02:32,672-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:02:32,673-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:02:32,673-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:02:32,674-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data1/t1.txt:0+50
2018-08-31 00:02:32,736-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-31 00:02:32,736-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-08-31 00:02:32,736-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-08-31 00:02:32,736-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-08-31 00:02:32,736-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-08-31 00:02:32,737-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-31 00:02:32,747-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-08-31 00:02:32,747-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-08-31 00:02:32,748-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-08-31 00:02:32,748-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-08-31 00:02:32,748-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-08-31 00:02:32,764-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-08-31 00:02:32,772-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1400508502_0001_m_000001_0 is done. And is in the process of committing
2018-08-31 00:02:32,777-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-08-31 00:02:32,778-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1400508502_0001_m_000001_0' done.
2018-08-31 00:02:32,779-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1400508502_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=546
		FILE: Number of bytes written=499025
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=78
		Input split bytes=113
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=382730240
	File Input Format Counters 
		Bytes Read=50
2018-08-31 00:02:32,779-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1400508502_0001_m_000001_0
2018-08-31 00:02:32,779-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-08-31 00:02:32,783-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-08-31 00:02:32,783-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1400508502_0001_r_000000_0
2018-08-31 00:02:32,791-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:02:32,791-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:02:32,792-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:02:32,792-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:02:32,797-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2f63d976
2018-08-31 00:02:32,799-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-08-31 00:02:32,814-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-31 00:02:32,815-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1400508502_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-31 00:02:32,831-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1400508502_0001_m_000001_0 decomp: 42 len: 46 to MEMORY
2018-08-31 00:02:32,833-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 42 bytes from map-output for attempt_local1400508502_0001_m_000001_0
2018-08-31 00:02:32,834-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 42, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->42
2018-08-31 00:02:32,836-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1400508502_0001_m_000000_0 decomp: 32 len: 36 to MEMORY
2018-08-31 00:02:32,836-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 32 bytes from map-output for attempt_local1400508502_0001_m_000000_0
2018-08-31 00:02:32,836-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 32, inMemoryMapOutputs.size() -> 2, commitMemory -> 42, usedMemory ->74
2018-08-31 00:02:32,836-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-08-31 00:02:32,837-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:02:32,837-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-08-31 00:02:32,845-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-08-31 00:02:32,846-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 54 bytes
2018-08-31 00:02:32,850-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 74 bytes to disk to satisfy reduce memory limit
2018-08-31 00:02:32,851-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 76 bytes from disk
2018-08-31 00:02:32,851-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-08-31 00:02:32,851-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-08-31 00:02:32,852-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 62 bytes
2018-08-31 00:02:32,853-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:02:32,876-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-08-31 00:02:32,923-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1400508502_0001_r_000000_0 is done. And is in the process of committing
2018-08-31 00:02:32,925-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:02:32,925-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1400508502_0001_r_000000_0 is allowed to commit now
2018-08-31 00:02:32,936-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1400508502_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/output_12
2018-08-31 00:02:32,937-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-08-31 00:02:32,937-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1400508502_0001_r_000000_0' done.
2018-08-31 00:02:32,938-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1400508502_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=948
		FILE: Number of bytes written=499101
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=42
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=82
		Reduce input records=7
		Reduce output records=5
		Spilled Records=7
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=382730240
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=42
2018-08-31 00:02:32,938-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1400508502_0001_r_000000_0
2018-08-31 00:02:32,938-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1400508502_0001_r_000001_0
2018-08-31 00:02:32,939-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:02:32,939-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:02:32,939-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:02:32,939-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:02:32,939-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6b78b156
2018-08-31 00:02:32,940-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-08-31 00:02:32,941-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-31 00:02:32,941-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1400508502_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-31 00:02:32,943-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1400508502_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2018-08-31 00:02:32,944-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local1400508502_0001_m_000001_0
2018-08-31 00:02:32,944-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2018-08-31 00:02:32,945-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1400508502_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2018-08-31 00:02:32,946-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local1400508502_0001_m_000000_0
2018-08-31 00:02:32,946-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->24
2018-08-31 00:02:32,946-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-08-31 00:02:32,947-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:02:32,948-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-08-31 00:02:32,956-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-08-31 00:02:32,957-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-08-31 00:02:32,964-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 24 bytes to disk to satisfy reduce memory limit
2018-08-31 00:02:32,965-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 26 bytes from disk
2018-08-31 00:02:32,965-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-08-31 00:02:32,965-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-08-31 00:02:32,966-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-08-31 00:02:32,966-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:02:33,007-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1400508502_0001_r_000001_0 is done. And is in the process of committing
2018-08-31 00:02:33,012-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:02:33,014-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1400508502_0001_r_000001_0 is allowed to commit now
2018-08-31 00:02:33,027-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1400508502_0001_r_000001_0' to hdfs://localhost:9000/user/lizhijun/output_12
2018-08-31 00:02:33,028-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-08-31 00:02:33,028-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1400508502_0001_r_000001_0' done.
2018-08-31 00:02:33,030-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1400508502_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1218
		FILE: Number of bytes written=499127
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=59
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=32
		Reduce input records=2
		Reduce output records=2
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=382730240
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=17
2018-08-31 00:02:33,031-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1400508502_0001_r_000001_0
2018-08-31 00:02:33,031-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1400508502_0001_r_000002_0
2018-08-31 00:02:33,033-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:02:33,033-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:02:33,034-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:02:33,034-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:02:33,034-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@71662511
2018-08-31 00:02:33,034-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-08-31 00:02:33,035-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-31 00:02:33,036-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1400508502_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-31 00:02:33,038-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local1400508502_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2018-08-31 00:02:33,038-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local1400508502_0001_m_000001_0
2018-08-31 00:02:33,038-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2018-08-31 00:02:33,042-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local1400508502_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2018-08-31 00:02:33,042-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local1400508502_0001_m_000000_0
2018-08-31 00:02:33,042-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->44
2018-08-31 00:02:33,043-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-08-31 00:02:33,044-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:02:33,044-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-08-31 00:02:33,051-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-08-31 00:02:33,052-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 24 bytes
2018-08-31 00:02:33,060-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 44 bytes to disk to satisfy reduce memory limit
2018-08-31 00:02:33,061-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 46 bytes from disk
2018-08-31 00:02:33,061-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-08-31 00:02:33,061-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-08-31 00:02:33,061-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 32 bytes
2018-08-31 00:02:33,062-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:02:33,412-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1400508502_0001 running in uber mode : false
2018-08-31 00:02:33,414-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 67%
2018-08-31 00:02:33,508-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1400508502_0001_r_000002_0 is done. And is in the process of committing
2018-08-31 00:02:33,512-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:02:33,512-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1400508502_0001_r_000002_0 is allowed to commit now
2018-08-31 00:02:33,522-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1400508502_0001_r_000002_0' to hdfs://localhost:9000/user/lizhijun/output_12
2018-08-31 00:02:33,523-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-08-31 00:02:33,523-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1400508502_0001_r_000002_0' done.
2018-08-31 00:02:33,524-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1400508502_0001_r_000002_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1476
		FILE: Number of bytes written=499173
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=22
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=7
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=52
		Reduce input records=4
		Reduce output records=3
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=382730240
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=25
2018-08-31 00:02:33,524-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1400508502_0001_r_000002_0
2018-08-31 00:02:33,524-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-08-31 00:02:34,416-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-08-31 00:02:34,417-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1400508502_0001 completed successfully
2018-08-31 00:02:34,428-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=4489
		FILE: Number of bytes written=2495293
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=490
		HDFS: Number of bytes written=185
		HDFS: Number of read operations=63
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=17
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=166
		Input split bytes=226
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=166
		Reduce input records=13
		Reduce output records=10
		Spilled Records=26
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1808269312
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=84
2018-08-31 00:09:40,889-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-08-31 00:09:42,419-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-08-31 00:09:42,675-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-08-31 00:09:42,675-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-08-31 00:09:42,987-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-31 00:09:43,000-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-31 00:09:43,082-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-08-31 00:09:43,142-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-08-31 00:09:43,272-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1511793526_0001
2018-08-31 00:09:43,273-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-08-31 00:09:43,389-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-08-31 00:09:43,390-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1511793526_0001
2018-08-31 00:09:43,390-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-08-31 00:09:43,396-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:09:43,396-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:09:43,397-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-31 00:09:43,443-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-08-31 00:09:43,443-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1511793526_0001_m_000000_0
2018-08-31 00:09:43,464-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:09:43,464-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:09:43,478-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:09:43,478-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:09:43,481-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data1/t2.txt:0+58
2018-08-31 00:09:43,599-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-31 00:09:43,599-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-08-31 00:09:43,599-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-08-31 00:09:43,599-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-08-31 00:09:43,599-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-08-31 00:09:43,603-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-31 00:09:43,736-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-08-31 00:09:43,741-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-08-31 00:09:43,741-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-08-31 00:09:43,742-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-08-31 00:09:43,742-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-08-31 00:09:43,770-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-08-31 00:09:43,789-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1511793526_0001_m_000000_0 is done. And is in the process of committing
2018-08-31 00:09:43,793-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-08-31 00:09:43,793-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1511793526_0001_m_000000_0' done.
2018-08-31 00:09:43,801-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1511793526_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=301
		FILE: Number of bytes written=498867
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=88
		Input split bytes=113
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=303038464
	File Input Format Counters 
		Bytes Read=58
2018-08-31 00:09:43,802-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1511793526_0001_m_000000_0
2018-08-31 00:09:43,802-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1511793526_0001_m_000001_0
2018-08-31 00:09:43,803-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:09:43,803-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:09:43,804-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:09:43,804-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:09:43,805-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data1/t1.txt:0+50
2018-08-31 00:09:43,954-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-31 00:09:43,955-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-08-31 00:09:43,955-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-08-31 00:09:43,955-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-08-31 00:09:43,955-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-08-31 00:09:43,956-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-31 00:09:43,992-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-08-31 00:09:43,993-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-08-31 00:09:43,993-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-08-31 00:09:43,993-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-08-31 00:09:43,994-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-08-31 00:09:44,011-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-08-31 00:09:44,022-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1511793526_0001_m_000001_0 is done. And is in the process of committing
2018-08-31 00:09:44,024-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-08-31 00:09:44,024-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1511793526_0001_m_000001_0' done.
2018-08-31 00:09:44,025-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1511793526_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=546
		FILE: Number of bytes written=499025
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=78
		Input split bytes=113
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=408420352
	File Input Format Counters 
		Bytes Read=50
2018-08-31 00:09:44,025-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1511793526_0001_m_000001_0
2018-08-31 00:09:44,026-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-08-31 00:09:44,029-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-08-31 00:09:44,029-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1511793526_0001_r_000000_0
2018-08-31 00:09:44,040-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:09:44,040-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:09:44,042-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:09:44,042-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:09:44,053-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@26a881b5
2018-08-31 00:09:44,055-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-08-31 00:09:44,073-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-31 00:09:44,093-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1511793526_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-31 00:09:44,114-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1511793526_0001_m_000001_0 decomp: 42 len: 46 to MEMORY
2018-08-31 00:09:44,117-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 42 bytes from map-output for attempt_local1511793526_0001_m_000001_0
2018-08-31 00:09:44,119-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 42, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->42
2018-08-31 00:09:44,121-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1511793526_0001_m_000000_0 decomp: 32 len: 36 to MEMORY
2018-08-31 00:09:44,122-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 32 bytes from map-output for attempt_local1511793526_0001_m_000000_0
2018-08-31 00:09:44,122-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 32, inMemoryMapOutputs.size() -> 2, commitMemory -> 42, usedMemory ->74
2018-08-31 00:09:44,122-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-08-31 00:09:44,123-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:09:44,123-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-08-31 00:09:44,134-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-08-31 00:09:44,134-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 54 bytes
2018-08-31 00:09:44,139-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 74 bytes to disk to satisfy reduce memory limit
2018-08-31 00:09:44,139-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 76 bytes from disk
2018-08-31 00:09:44,140-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-08-31 00:09:44,140-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-08-31 00:09:44,140-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 62 bytes
2018-08-31 00:09:44,141-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:09:44,187-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-08-31 00:09:44,395-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1511793526_0001 running in uber mode : false
2018-08-31 00:09:44,396-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-08-31 00:09:44,689-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1511793526_0001_r_000000_0 is done. And is in the process of committing
2018-08-31 00:09:44,691-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:09:44,691-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1511793526_0001_r_000000_0 is allowed to commit now
2018-08-31 00:09:44,702-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1511793526_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/output_13
2018-08-31 00:09:44,703-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-08-31 00:09:44,703-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1511793526_0001_r_000000_0' done.
2018-08-31 00:09:44,704-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1511793526_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=948
		FILE: Number of bytes written=499101
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=42
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=82
		Reduce input records=7
		Reduce output records=5
		Spilled Records=7
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=408420352
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=42
2018-08-31 00:09:44,704-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1511793526_0001_r_000000_0
2018-08-31 00:09:44,704-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1511793526_0001_r_000001_0
2018-08-31 00:09:44,705-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:09:44,705-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:09:44,705-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:09:44,706-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:09:44,706-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6fab33bc
2018-08-31 00:09:44,706-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-08-31 00:09:44,707-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-31 00:09:44,707-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1511793526_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-31 00:09:44,710-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1511793526_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2018-08-31 00:09:44,710-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local1511793526_0001_m_000001_0
2018-08-31 00:09:44,710-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2018-08-31 00:09:44,712-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1511793526_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2018-08-31 00:09:44,713-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local1511793526_0001_m_000000_0
2018-08-31 00:09:44,713-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->24
2018-08-31 00:09:44,713-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-08-31 00:09:44,714-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:09:44,714-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-08-31 00:09:44,722-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-08-31 00:09:44,722-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-08-31 00:09:44,730-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 24 bytes to disk to satisfy reduce memory limit
2018-08-31 00:09:44,730-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 26 bytes from disk
2018-08-31 00:09:44,731-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-08-31 00:09:44,731-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-08-31 00:09:44,731-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-08-31 00:09:44,731-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:09:45,152-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1511793526_0001_r_000001_0 is done. And is in the process of committing
2018-08-31 00:09:45,154-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:09:45,154-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1511793526_0001_r_000001_0 is allowed to commit now
2018-08-31 00:09:45,159-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1511793526_0001_r_000001_0' to hdfs://localhost:9000/user/lizhijun/output_13
2018-08-31 00:09:45,160-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-08-31 00:09:45,160-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1511793526_0001_r_000001_0' done.
2018-08-31 00:09:45,160-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1511793526_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1218
		FILE: Number of bytes written=499127
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=59
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=32
		Reduce input records=2
		Reduce output records=2
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=408420352
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=17
2018-08-31 00:09:45,161-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1511793526_0001_r_000001_0
2018-08-31 00:09:45,161-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1511793526_0001_r_000002_0
2018-08-31 00:09:45,162-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:09:45,162-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:09:45,162-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:09:45,163-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:09:45,163-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@25c48bc9
2018-08-31 00:09:45,163-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-08-31 00:09:45,164-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-31 00:09:45,164-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1511793526_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-31 00:09:45,166-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local1511793526_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2018-08-31 00:09:45,167-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local1511793526_0001_m_000001_0
2018-08-31 00:09:45,167-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2018-08-31 00:09:45,169-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local1511793526_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2018-08-31 00:09:45,169-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local1511793526_0001_m_000000_0
2018-08-31 00:09:45,170-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->44
2018-08-31 00:09:45,170-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-08-31 00:09:45,170-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:09:45,171-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-08-31 00:09:45,178-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-08-31 00:09:45,178-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 24 bytes
2018-08-31 00:09:45,184-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 44 bytes to disk to satisfy reduce memory limit
2018-08-31 00:09:45,185-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 46 bytes from disk
2018-08-31 00:09:45,185-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-08-31 00:09:45,185-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-08-31 00:09:45,185-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 32 bytes
2018-08-31 00:09:45,186-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:09:45,401-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 67%
2018-08-31 00:09:45,620-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1511793526_0001_r_000002_0 is done. And is in the process of committing
2018-08-31 00:09:45,624-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:09:45,624-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1511793526_0001_r_000002_0 is allowed to commit now
2018-08-31 00:09:45,638-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1511793526_0001_r_000002_0' to hdfs://localhost:9000/user/lizhijun/output_13
2018-08-31 00:09:45,640-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-08-31 00:09:45,640-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1511793526_0001_r_000002_0' done.
2018-08-31 00:09:45,640-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1511793526_0001_r_000002_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1476
		FILE: Number of bytes written=499173
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=22
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=7
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=52
		Reduce input records=4
		Reduce output records=3
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=408420352
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=25
2018-08-31 00:09:45,641-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1511793526_0001_r_000002_0
2018-08-31 00:09:45,641-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-08-31 00:09:46,406-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-08-31 00:09:46,407-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1511793526_0001 completed successfully
2018-08-31 00:09:46,417-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=4489
		FILE: Number of bytes written=2495293
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=490
		HDFS: Number of bytes written=185
		HDFS: Number of read operations=63
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=17
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=166
		Input split bytes=226
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=166
		Reduce input records=13
		Reduce output records=10
		Spilled Records=26
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=1936719872
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=84
2018-08-31 00:10:19,330-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-08-31 00:10:20,443-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-08-31 00:10:20,498-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-08-31 00:10:20,498-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-08-31 00:10:20,771-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-31 00:10:20,783-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-31 00:10:20,846-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-08-31 00:10:20,899-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-08-31 00:10:21,018-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1815984348_0001
2018-08-31 00:10:21,020-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-08-31 00:10:21,120-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-08-31 00:10:21,120-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-08-31 00:10:21,120-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1815984348_0001
2018-08-31 00:10:21,126-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:10:21,126-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:10:21,127-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-31 00:10:21,161-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-08-31 00:10:21,162-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1815984348_0001_m_000000_0
2018-08-31 00:10:21,187-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:10:21,187-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:10:21,197-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:10:21,198-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:10:21,201-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data1/t2.txt:0+58
2018-08-31 00:10:21,276-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-31 00:10:21,276-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-08-31 00:10:21,276-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-08-31 00:10:21,276-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-08-31 00:10:21,276-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-08-31 00:10:21,280-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-31 00:10:21,346-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-08-31 00:10:21,349-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-08-31 00:10:21,349-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-08-31 00:10:21,349-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-08-31 00:10:21,349-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-08-31 00:10:21,366-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-08-31 00:10:21,379-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1815984348_0001_m_000000_0 is done. And is in the process of committing
2018-08-31 00:10:21,382-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-08-31 00:10:21,382-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1815984348_0001_m_000000_0' done.
2018-08-31 00:10:21,389-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1815984348_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=301
		FILE: Number of bytes written=499332
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=88
		Input split bytes=113
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=301989888
	File Input Format Counters 
		Bytes Read=58
2018-08-31 00:10:21,389-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1815984348_0001_m_000000_0
2018-08-31 00:10:21,390-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1815984348_0001_m_000001_0
2018-08-31 00:10:21,390-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:10:21,391-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:10:21,391-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:10:21,391-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:10:21,393-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data1/t1.txt:0+50
2018-08-31 00:10:21,447-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-31 00:10:21,447-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-08-31 00:10:21,447-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-08-31 00:10:21,447-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-08-31 00:10:21,447-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-08-31 00:10:21,447-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-31 00:10:21,452-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-08-31 00:10:21,452-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-08-31 00:10:21,452-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-08-31 00:10:21,452-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-08-31 00:10:21,452-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-08-31 00:10:21,464-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-08-31 00:10:21,471-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1815984348_0001_m_000001_0 is done. And is in the process of committing
2018-08-31 00:10:21,473-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-08-31 00:10:21,473-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1815984348_0001_m_000001_0' done.
2018-08-31 00:10:21,474-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1815984348_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=546
		FILE: Number of bytes written=499490
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=78
		Input split bytes=113
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=407371776
	File Input Format Counters 
		Bytes Read=50
2018-08-31 00:10:21,474-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1815984348_0001_m_000001_0
2018-08-31 00:10:21,474-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-08-31 00:10:21,478-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-08-31 00:10:21,478-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1815984348_0001_r_000000_0
2018-08-31 00:10:21,484-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:10:21,484-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:10:21,485-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:10:21,485-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:10:21,488-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@26a881b5
2018-08-31 00:10:21,490-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-08-31 00:10:21,503-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-31 00:10:21,519-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1815984348_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-31 00:10:21,544-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1815984348_0001_m_000001_0 decomp: 42 len: 46 to MEMORY
2018-08-31 00:10:21,546-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 42 bytes from map-output for attempt_local1815984348_0001_m_000001_0
2018-08-31 00:10:21,547-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 42, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->42
2018-08-31 00:10:21,549-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1815984348_0001_m_000000_0 decomp: 32 len: 36 to MEMORY
2018-08-31 00:10:21,549-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 32 bytes from map-output for attempt_local1815984348_0001_m_000000_0
2018-08-31 00:10:21,549-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 32, inMemoryMapOutputs.size() -> 2, commitMemory -> 42, usedMemory ->74
2018-08-31 00:10:21,550-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-08-31 00:10:21,552-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:10:21,553-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-08-31 00:10:21,597-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-08-31 00:10:21,598-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 54 bytes
2018-08-31 00:10:21,606-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 74 bytes to disk to satisfy reduce memory limit
2018-08-31 00:10:21,607-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 76 bytes from disk
2018-08-31 00:10:21,607-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-08-31 00:10:21,608-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-08-31 00:10:21,608-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 62 bytes
2018-08-31 00:10:21,609-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:10:21,633-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-08-31 00:10:21,647-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1815984348_0001_r_000001_0
2018-08-31 00:10:21,648-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:10:21,648-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:10:21,648-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:10:21,648-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:10:21,648-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2aa728a2
2018-08-31 00:10:21,649-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-08-31 00:10:21,649-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-31 00:10:21,650-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1815984348_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-31 00:10:21,652-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1815984348_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2018-08-31 00:10:21,652-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local1815984348_0001_m_000001_0
2018-08-31 00:10:21,652-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2018-08-31 00:10:21,653-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1815984348_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2018-08-31 00:10:21,654-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local1815984348_0001_m_000000_0
2018-08-31 00:10:21,654-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->24
2018-08-31 00:10:21,654-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-08-31 00:10:21,655-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:10:21,655-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-08-31 00:10:21,661-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-08-31 00:10:21,661-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-08-31 00:10:21,667-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 24 bytes to disk to satisfy reduce memory limit
2018-08-31 00:10:21,667-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 26 bytes from disk
2018-08-31 00:10:21,668-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-08-31 00:10:21,668-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-08-31 00:10:21,668-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-08-31 00:10:21,668-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:10:21,673-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1815984348_0001_r_000002_0
2018-08-31 00:10:21,675-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:10:21,675-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:10:21,675-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:10:21,675-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:10:21,675-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@c5b01b8
2018-08-31 00:10:21,676-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-08-31 00:10:21,677-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-31 00:10:21,677-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1815984348_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-31 00:10:21,678-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local1815984348_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2018-08-31 00:10:21,679-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local1815984348_0001_m_000001_0
2018-08-31 00:10:21,679-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2018-08-31 00:10:21,681-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local1815984348_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2018-08-31 00:10:21,681-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local1815984348_0001_m_000000_0
2018-08-31 00:10:21,681-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->44
2018-08-31 00:10:21,682-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-08-31 00:10:21,682-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:10:21,682-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-08-31 00:10:21,694-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-08-31 00:10:21,694-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 24 bytes
2018-08-31 00:10:21,703-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 44 bytes to disk to satisfy reduce memory limit
2018-08-31 00:10:21,703-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 46 bytes from disk
2018-08-31 00:10:21,703-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-08-31 00:10:21,703-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-08-31 00:10:21,703-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 32 bytes
2018-08-31 00:10:21,704-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:10:21,728-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-08-31 00:10:21,744-[TS] WARN Thread-22 org.apache.hadoop.mapred.LocalJobRunner - job_local1815984348_0001
java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:559)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:157)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:158)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:302)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:628)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:390)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:347)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-08-31 00:10:22,129-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1815984348_0001 running in uber mode : false
2018-08-31 00:10:22,130-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-08-31 00:10:22,132-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1815984348_0001 failed with state FAILED due to: NA
2018-08-31 00:10:22,140-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=847
		FILE: Number of bytes written=998822
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=166
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=166
		Input split bytes=226
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=166
		Reduce input records=0
		Reduce output records=0
		Spilled Records=13
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=709361664
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=0
2018-08-31 00:13:06,674-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-08-31 00:13:08,114-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-08-31 00:13:08,335-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-08-31 00:13:08,337-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-08-31 00:13:08,670-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-31 00:13:08,684-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-31 00:13:08,770-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-08-31 00:13:08,832-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-08-31 00:13:08,966-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local809364250_0001
2018-08-31 00:13:08,968-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-08-31 00:13:09,101-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-08-31 00:13:09,102-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-08-31 00:13:09,102-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local809364250_0001
2018-08-31 00:13:09,108-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:13:09,108-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:13:09,109-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-31 00:13:09,142-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-08-31 00:13:09,143-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local809364250_0001_m_000000_0
2018-08-31 00:13:09,157-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:13:09,157-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:13:09,168-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:13:09,168-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:13:09,171-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data1/t2.txt:0+58
2018-08-31 00:13:09,324-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-31 00:13:09,324-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-08-31 00:13:09,324-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-08-31 00:13:09,325-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-08-31 00:13:09,325-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-08-31 00:13:09,328-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-31 00:13:09,419-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-08-31 00:13:09,422-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-08-31 00:13:09,422-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-08-31 00:13:09,422-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-08-31 00:13:09,422-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-08-31 00:13:09,458-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-08-31 00:13:09,481-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local809364250_0001_m_000000_0 is done. And is in the process of committing
2018-08-31 00:13:09,484-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-08-31 00:13:09,484-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local809364250_0001_m_000000_0' done.
2018-08-31 00:13:09,495-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local809364250_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=301
		FILE: Number of bytes written=496922
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=88
		Input split bytes=113
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=276299776
	File Input Format Counters 
		Bytes Read=58
2018-08-31 00:13:09,495-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local809364250_0001_m_000000_0
2018-08-31 00:13:09,496-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local809364250_0001_m_000001_0
2018-08-31 00:13:09,497-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:13:09,497-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:13:09,498-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:13:09,498-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:13:09,499-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data1/t1.txt:0+50
2018-08-31 00:13:09,593-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-31 00:13:09,593-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-08-31 00:13:09,593-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-08-31 00:13:09,593-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-08-31 00:13:09,593-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-08-31 00:13:09,594-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-31 00:13:09,613-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-08-31 00:13:09,613-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-08-31 00:13:09,613-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-08-31 00:13:09,613-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-08-31 00:13:09,613-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-08-31 00:13:09,634-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-08-31 00:13:09,640-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local809364250_0001_m_000001_0 is done. And is in the process of committing
2018-08-31 00:13:09,643-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-08-31 00:13:09,644-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local809364250_0001_m_000001_0' done.
2018-08-31 00:13:09,645-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local809364250_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=546
		FILE: Number of bytes written=497080
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=78
		Input split bytes=113
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=381681664
	File Input Format Counters 
		Bytes Read=50
2018-08-31 00:13:09,645-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local809364250_0001_m_000001_0
2018-08-31 00:13:09,645-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-08-31 00:13:09,648-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-08-31 00:13:09,648-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local809364250_0001_r_000000_0
2018-08-31 00:13:09,653-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:13:09,653-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:13:09,654-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:13:09,654-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:13:09,657-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@209fd814
2018-08-31 00:13:09,661-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-08-31 00:13:09,679-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-31 00:13:09,681-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local809364250_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-31 00:13:09,709-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local809364250_0001_m_000001_0 decomp: 42 len: 46 to MEMORY
2018-08-31 00:13:09,713-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 42 bytes from map-output for attempt_local809364250_0001_m_000001_0
2018-08-31 00:13:09,714-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 42, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->42
2018-08-31 00:13:09,717-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local809364250_0001_m_000000_0 decomp: 32 len: 36 to MEMORY
2018-08-31 00:13:09,717-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 32 bytes from map-output for attempt_local809364250_0001_m_000000_0
2018-08-31 00:13:09,717-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 32, inMemoryMapOutputs.size() -> 2, commitMemory -> 42, usedMemory ->74
2018-08-31 00:13:09,718-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-08-31 00:13:09,719-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:13:09,720-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-08-31 00:13:09,740-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-08-31 00:13:09,741-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 54 bytes
2018-08-31 00:13:09,747-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 74 bytes to disk to satisfy reduce memory limit
2018-08-31 00:13:09,748-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 76 bytes from disk
2018-08-31 00:13:09,749-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-08-31 00:13:09,749-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-08-31 00:13:09,749-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 62 bytes
2018-08-31 00:13:09,749-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:13:09,780-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-08-31 00:13:09,787-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local809364250_0001_r_000001_0
2018-08-31 00:13:09,788-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:13:09,788-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:13:09,788-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:13:09,788-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:13:09,789-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5b5afa06
2018-08-31 00:13:09,789-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-08-31 00:13:09,789-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-31 00:13:09,790-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local809364250_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-31 00:13:09,792-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local809364250_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2018-08-31 00:13:09,792-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local809364250_0001_m_000001_0
2018-08-31 00:13:09,792-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2018-08-31 00:13:09,794-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local809364250_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2018-08-31 00:13:09,794-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local809364250_0001_m_000000_0
2018-08-31 00:13:09,794-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->24
2018-08-31 00:13:09,795-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-08-31 00:13:09,795-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:13:09,796-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-08-31 00:13:09,801-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-08-31 00:13:09,801-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-08-31 00:13:09,807-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 24 bytes to disk to satisfy reduce memory limit
2018-08-31 00:13:09,807-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 26 bytes from disk
2018-08-31 00:13:09,807-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-08-31 00:13:09,807-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-08-31 00:13:09,808-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-08-31 00:13:09,808-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:13:09,814-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local809364250_0001_r_000002_0
2018-08-31 00:13:09,815-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:13:09,815-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:13:09,815-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:13:09,815-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:13:09,815-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@78cd87a2
2018-08-31 00:13:09,816-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-08-31 00:13:09,817-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-31 00:13:09,818-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local809364250_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-31 00:13:09,819-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local809364250_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2018-08-31 00:13:09,820-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local809364250_0001_m_000001_0
2018-08-31 00:13:09,820-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2018-08-31 00:13:09,822-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local809364250_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2018-08-31 00:13:09,822-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local809364250_0001_m_000000_0
2018-08-31 00:13:09,822-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->44
2018-08-31 00:13:09,823-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-08-31 00:13:09,823-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:13:09,824-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-08-31 00:13:09,830-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-08-31 00:13:09,830-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 24 bytes
2018-08-31 00:13:09,836-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 44 bytes to disk to satisfy reduce memory limit
2018-08-31 00:13:09,837-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 46 bytes from disk
2018-08-31 00:13:09,837-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-08-31 00:13:09,837-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-08-31 00:13:09,837-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 32 bytes
2018-08-31 00:13:09,838-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:13:09,847-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-08-31 00:13:09,856-[TS] WARN Thread-22 org.apache.hadoop.mapred.LocalJobRunner - job_local809364250_0001
java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:559)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:157)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:158)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:302)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:628)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:390)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:347)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2018-08-31 00:13:10,110-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local809364250_0001 running in uber mode : false
2018-08-31 00:13:10,112-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-08-31 00:13:10,113-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local809364250_0001 failed with state FAILED due to: NA
2018-08-31 00:13:10,124-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=847
		FILE: Number of bytes written=994002
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=166
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=166
		Input split bytes=226
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=166
		Reduce input records=0
		Reduce output records=0
		Spilled Records=13
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=657981440
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=0
2018-08-31 00:27:28,210-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-08-31 00:27:30,128-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032
2018-08-31 00:27:31,779-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:27:32,793-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:27:33,798-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:27:34,808-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:27:35,817-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:27:36,830-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:27:37,839-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:27:38,846-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:27:39,852-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:27:40,860-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:27:41,885-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:27:42,890-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:27:43,894-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:27:44,898-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:27:45,908-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:27:46,916-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:27:47,923-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:14,107-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-08-31 00:40:15,655-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032
2018-08-31 00:40:17,046-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:18,052-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:19,056-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:20,087-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:21,090-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:22,096-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:23,105-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:24,108-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:25,112-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:26,117-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:27,129-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:28,135-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:29,141-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:30,145-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:31,151-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:32,155-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:33,159-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:34,163-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:35,167-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:36,172-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:40:36,174-[TS] INFO main org.apache.hadoop.io.retry.RetryInvocationHandler - java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 1 failover attempts. Trying to failover after sleeping for 41032ms.
2018-08-31 00:41:18,215-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:19,221-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:20,225-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:21,232-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:22,234-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:23,241-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:24,246-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:25,247-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:26,248-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:27,253-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:27,256-[TS] INFO main org.apache.hadoop.io.retry.RetryInvocationHandler - java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 2 failover attempts. Trying to failover after sleeping for 17116ms.
2018-08-31 00:41:45,381-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:46,387-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:47,390-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:48,396-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:49,401-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:50,446-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:51,449-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:52,451-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:53,452-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:54,458-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:41:54,461-[TS] INFO main org.apache.hadoop.io.retry.RetryInvocationHandler - java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 3 failover attempts. Trying to failover after sleeping for 35154ms.
2018-08-31 00:42:30,620-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:42:31,625-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:42:32,630-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:42:33,631-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:42:34,633-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:42:35,637-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:42:36,639-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:42:37,642-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:42:38,648-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:42:39,649-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:42:39,651-[TS] INFO main org.apache.hadoop.io.retry.RetryInvocationHandler - java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 4 failover attempts. Trying to failover after sleeping for 23953ms.
2018-08-31 00:43:04,612-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:05,616-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:06,622-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:07,623-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:08,624-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:09,631-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:10,632-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:11,637-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:12,641-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:13,647-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:13,649-[TS] INFO main org.apache.hadoop.io.retry.RetryInvocationHandler - java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 5 failover attempts. Trying to failover after sleeping for 18804ms.
2018-08-31 00:43:33,467-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:34,471-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:35,474-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:36,481-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:37,484-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:38,493-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:39,502-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:40,506-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:41,511-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:42,514-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:43:42,516-[TS] INFO main org.apache.hadoop.io.retry.RetryInvocationHandler - java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 6 failover attempts. Trying to failover after sleeping for 26301ms.
2018-08-31 00:44:09,828-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:44:10,834-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:44:11,838-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:44:12,842-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:44:13,847-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:44:14,851-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:44:15,853-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:44:16,856-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:44:17,858-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:44:18,864-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:44:18,866-[TS] INFO main org.apache.hadoop.io.retry.RetryInvocationHandler - java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 7 failover attempts. Trying to failover after sleeping for 40157ms.
2018-08-31 00:45:00,035-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:01,044-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:02,048-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:03,053-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:04,055-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:05,058-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:06,060-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:07,062-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:08,065-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:09,066-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:09,069-[TS] INFO main org.apache.hadoop.io.retry.RetryInvocationHandler - java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 8 failover attempts. Trying to failover after sleeping for 16960ms.
2018-08-31 00:45:27,039-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:28,044-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:29,049-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:30,054-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:31,059-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:32,066-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:33,072-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:34,083-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:35,089-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:36,091-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:45:36,094-[TS] INFO main org.apache.hadoop.io.retry.RetryInvocationHandler - java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 9 failover attempts. Trying to failover after sleeping for 32307ms.
2018-08-31 00:45:57,827-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-08-31 00:45:59,252-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032
2018-08-31 00:46:00,721-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:46:01,726-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:46:02,732-[TS] INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-08-31 00:47:17,671-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-08-31 00:47:19,307-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-08-31 00:47:21,546-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-31 00:47:21,561-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-31 00:47:21,734-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-08-31 00:47:21,810-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-08-31 00:47:21,856-[TS] INFO main org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-08-31 00:47:21,974-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1534947266193_0001
2018-08-31 00:47:21,976-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-08-31 00:47:22,154-[TS] INFO main org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.
2018-08-31 00:47:22,198-[TS] INFO main org.apache.hadoop.conf.Configuration - resource-types.xml not found
2018-08-31 00:47:22,199-[TS] INFO main org.apache.hadoop.yarn.util.resource.ResourceUtils - Unable to find 'resource-types.xml'.
2018-08-31 00:47:26,661-[TS] INFO main org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1534947266193_0001
2018-08-31 00:47:26,784-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://10.215.107.53:8088/proxy/application_1534947266193_0001/
2018-08-31 00:47:26,786-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_1534947266193_0001
2018-08-31 00:50:34,352-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-08-31 00:50:35,787-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-08-31 00:50:36,381-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-31 00:50:36,395-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-31 00:50:36,521-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-08-31 00:50:36,591-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-08-31 00:50:36,644-[TS] INFO main org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-08-31 00:50:36,736-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1534947266193_0002
2018-08-31 00:50:36,737-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-08-31 00:50:36,883-[TS] INFO main org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.
2018-08-31 00:50:36,943-[TS] INFO main org.apache.hadoop.conf.Configuration - resource-types.xml not found
2018-08-31 00:50:36,943-[TS] INFO main org.apache.hadoop.yarn.util.resource.ResourceUtils - Unable to find 'resource-types.xml'.
2018-08-31 00:50:37,049-[TS] INFO main org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1534947266193_0002
2018-08-31 00:50:37,095-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://10.215.107.53:8088/proxy/application_1534947266193_0002/
2018-08-31 00:50:37,096-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_1534947266193_0002
2018-08-31 00:51:35,390-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1534947266193_0002 running in uber mode : false
2018-08-31 00:51:35,394-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
2018-08-31 00:51:35,414-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_1534947266193_0002 failed with state KILLED due to: Application application_1534947266193_0002 was killed by user dr.who
2018-08-31 00:51:35,459-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 0
2018-08-31 00:52:30,828-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-08-31 00:52:32,166-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-08-31 00:52:32,224-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-08-31 00:52:32,224-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-08-31 00:52:32,588-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-31 00:52:32,615-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-31 00:52:32,693-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-08-31 00:52:32,746-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-08-31 00:52:32,882-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1656259260_0001
2018-08-31 00:52:32,884-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-08-31 00:52:33,039-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-08-31 00:52:33,042-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1656259260_0001
2018-08-31 00:52:33,046-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-08-31 00:52:33,052-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:52:33,052-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:52:33,053-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-31 00:52:33,186-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-08-31 00:52:33,187-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1656259260_0001_m_000000_0
2018-08-31 00:52:33,203-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:52:33,203-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:52:33,213-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:52:33,213-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:52:33,215-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data1/t2.txt:0+58
2018-08-31 00:52:33,300-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-31 00:52:33,300-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-08-31 00:52:33,300-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-08-31 00:52:33,301-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-08-31 00:52:33,301-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-08-31 00:52:33,306-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-31 00:52:33,554-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-08-31 00:52:33,560-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-08-31 00:52:33,560-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-08-31 00:52:33,560-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-08-31 00:52:33,560-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-08-31 00:52:33,596-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-08-31 00:52:33,627-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1656259260_0001_m_000000_0 is done. And is in the process of committing
2018-08-31 00:52:33,633-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-08-31 00:52:33,633-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1656259260_0001_m_000000_0' done.
2018-08-31 00:52:33,656-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1656259260_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=301
		FILE: Number of bytes written=498867
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=88
		Input split bytes=113
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=277872640
	File Input Format Counters 
		Bytes Read=58
2018-08-31 00:52:33,656-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1656259260_0001_m_000000_0
2018-08-31 00:52:33,657-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1656259260_0001_m_000001_0
2018-08-31 00:52:33,659-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:52:33,659-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:52:33,660-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:52:33,660-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:52:33,663-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data1/t1.txt:0+50
2018-08-31 00:52:33,861-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-31 00:52:33,861-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-08-31 00:52:33,862-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-08-31 00:52:33,862-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-08-31 00:52:33,862-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-08-31 00:52:33,863-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-31 00:52:33,885-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-08-31 00:52:33,886-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-08-31 00:52:33,886-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-08-31 00:52:33,886-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-08-31 00:52:33,887-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-08-31 00:52:33,912-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-08-31 00:52:33,924-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1656259260_0001_m_000001_0 is done. And is in the process of committing
2018-08-31 00:52:33,930-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-08-31 00:52:33,930-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1656259260_0001_m_000001_0' done.
2018-08-31 00:52:33,932-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1656259260_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=546
		FILE: Number of bytes written=499025
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=78
		Input split bytes=113
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=383254528
	File Input Format Counters 
		Bytes Read=50
2018-08-31 00:52:33,932-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1656259260_0001_m_000001_0
2018-08-31 00:52:33,933-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-08-31 00:52:33,940-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-08-31 00:52:33,941-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1656259260_0001_r_000000_0
2018-08-31 00:52:33,953-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:52:33,954-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:52:33,955-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:52:33,955-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:52:33,961-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3ef467c2
2018-08-31 00:52:33,964-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-08-31 00:52:34,003-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-31 00:52:34,007-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1656259260_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-31 00:52:34,047-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1656259260_0001_m_000000_0 decomp: 32 len: 36 to MEMORY
2018-08-31 00:52:34,053-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1656259260_0001 running in uber mode : false
2018-08-31 00:52:34,053-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 32 bytes from map-output for attempt_local1656259260_0001_m_000000_0
2018-08-31 00:52:34,054-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-08-31 00:52:34,055-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 32, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->32
2018-08-31 00:52:34,059-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1656259260_0001_m_000001_0 decomp: 42 len: 46 to MEMORY
2018-08-31 00:52:34,061-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 42 bytes from map-output for attempt_local1656259260_0001_m_000001_0
2018-08-31 00:52:34,061-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 42, inMemoryMapOutputs.size() -> 2, commitMemory -> 32, usedMemory ->74
2018-08-31 00:52:34,062-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-08-31 00:52:34,063-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:52:34,064-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-08-31 00:52:34,090-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-08-31 00:52:34,091-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 54 bytes
2018-08-31 00:52:34,112-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 74 bytes to disk to satisfy reduce memory limit
2018-08-31 00:52:34,114-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 76 bytes from disk
2018-08-31 00:52:34,115-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-08-31 00:52:34,115-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-08-31 00:52:34,129-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 62 bytes
2018-08-31 00:52:34,131-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:52:34,210-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-08-31 00:52:34,372-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1656259260_0001_r_000000_0 is done. And is in the process of committing
2018-08-31 00:52:34,376-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:52:34,376-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1656259260_0001_r_000000_0 is allowed to commit now
2018-08-31 00:52:34,405-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1656259260_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/output_18
2018-08-31 00:52:34,407-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-08-31 00:52:34,407-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1656259260_0001_r_000000_0' done.
2018-08-31 00:52:34,408-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1656259260_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=948
		FILE: Number of bytes written=499101
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=42
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=82
		Reduce input records=7
		Reduce output records=5
		Spilled Records=7
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=383254528
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=42
2018-08-31 00:52:34,409-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1656259260_0001_r_000000_0
2018-08-31 00:52:34,417-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1656259260_0001_r_000001_0
2018-08-31 00:52:34,420-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:52:34,420-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:52:34,421-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:52:34,421-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:52:34,422-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7ec76b48
2018-08-31 00:52:34,422-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-08-31 00:52:34,425-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-31 00:52:34,426-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1656259260_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-31 00:52:34,430-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1656259260_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2018-08-31 00:52:34,431-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local1656259260_0001_m_000000_0
2018-08-31 00:52:34,432-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2018-08-31 00:52:34,435-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1656259260_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2018-08-31 00:52:34,437-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local1656259260_0001_m_000001_0
2018-08-31 00:52:34,437-[TS] INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->24
2018-08-31 00:52:34,438-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-08-31 00:52:34,439-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:52:34,440-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-08-31 00:52:34,457-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-08-31 00:52:34,458-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-08-31 00:52:34,469-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 24 bytes to disk to satisfy reduce memory limit
2018-08-31 00:52:34,470-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 26 bytes from disk
2018-08-31 00:52:34,471-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-08-31 00:52:34,472-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-08-31 00:52:34,474-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12 bytes
2018-08-31 00:52:34,477-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:52:34,536-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1656259260_0001_r_000001_0 is done. And is in the process of committing
2018-08-31 00:52:34,540-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:52:34,541-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1656259260_0001_r_000001_0 is allowed to commit now
2018-08-31 00:52:34,572-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1656259260_0001_r_000001_0' to hdfs://localhost:9000/user/lizhijun/output_18
2018-08-31 00:52:34,573-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-08-31 00:52:34,574-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1656259260_0001_r_000001_0' done.
2018-08-31 00:52:34,575-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1656259260_0001_r_000001_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1218
		FILE: Number of bytes written=499127
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=59
		HDFS: Number of read operations=17
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=32
		Reduce input records=2
		Reduce output records=2
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=383254528
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=17
2018-08-31 00:52:34,575-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1656259260_0001_r_000001_0
2018-08-31 00:52:34,575-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1656259260_0001_r_000002_0
2018-08-31 00:52:34,577-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 00:52:34,577-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 00:52:34,578-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 00:52:34,578-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 00:52:34,579-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1835f753
2018-08-31 00:52:34,579-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-08-31 00:52:34,581-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-31 00:52:34,586-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1656259260_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-31 00:52:34,591-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local1656259260_0001_m_000000_0 decomp: 22 len: 26 to MEMORY
2018-08-31 00:52:34,592-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local1656259260_0001_m_000000_0
2018-08-31 00:52:34,593-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->22
2018-08-31 00:52:34,597-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local1656259260_0001_m_000001_0 decomp: 22 len: 26 to MEMORY
2018-08-31 00:52:34,599-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 22 bytes from map-output for attempt_local1656259260_0001_m_000001_0
2018-08-31 00:52:34,600-[TS] INFO localfetcher#3 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 22, inMemoryMapOutputs.size() -> 2, commitMemory -> 22, usedMemory ->44
2018-08-31 00:52:34,603-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-08-31 00:52:34,605-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:52:34,619-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-08-31 00:52:34,663-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-08-31 00:52:34,664-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 24 bytes
2018-08-31 00:52:34,686-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 44 bytes to disk to satisfy reduce memory limit
2018-08-31 00:52:34,687-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 46 bytes from disk
2018-08-31 00:52:34,687-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-08-31 00:52:34,687-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-08-31 00:52:34,689-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 32 bytes
2018-08-31 00:52:34,691-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:52:34,749-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1656259260_0001_r_000002_0 is done. And is in the process of committing
2018-08-31 00:52:34,753-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 00:52:34,754-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1656259260_0001_r_000002_0 is allowed to commit now
2018-08-31 00:52:34,769-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1656259260_0001_r_000002_0' to hdfs://localhost:9000/user/lizhijun/output_18
2018-08-31 00:52:34,771-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-08-31 00:52:34,771-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1656259260_0001_r_000002_0' done.
2018-08-31 00:52:34,772-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1656259260_0001_r_000002_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=1476
		FILE: Number of bytes written=499173
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=22
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=7
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=52
		Reduce input records=4
		Reduce output records=3
		Spilled Records=4
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=383254528
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=25
2018-08-31 00:52:34,773-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1656259260_0001_r_000002_0
2018-08-31 00:52:34,773-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-08-31 00:52:35,060-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-08-31 00:52:35,061-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1656259260_0001 completed successfully
2018-08-31 00:52:35,081-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=4489
		FILE: Number of bytes written=2495293
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=490
		HDFS: Number of bytes written=185
		HDFS: Number of read operations=63
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=17
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=166
		Input split bytes=226
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=166
		Reduce input records=13
		Reduce output records=10
		Spilled Records=26
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1810890752
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=84
2018-08-31 10:58:00,391-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-08-31 10:58:02,255-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-08-31 10:58:02,428-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-08-31 10:58:02,428-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-08-31 10:58:21,274-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-08-31 10:58:22,767-[TS] WARN main org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2018-08-31 10:58:22,831-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2018-08-31 10:58:22,832-[TS] INFO main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system started
2018-08-31 10:58:23,324-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-31 10:58:23,345-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-31 10:58:23,541-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-08-31 10:58:23,669-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-08-31 10:58:23,882-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1385839350_0001
2018-08-31 10:58:23,885-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-08-31 10:58:24,072-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
2018-08-31 10:58:24,073-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1385839350_0001
2018-08-31 10:58:24,074-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
2018-08-31 10:58:24,081-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 10:58:24,081-[TS] INFO Thread-22 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 10:58:24,081-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2018-08-31 10:58:24,191-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
2018-08-31 10:58:24,192-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1385839350_0001_m_000000_0
2018-08-31 10:58:24,221-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 10:58:24,221-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 10:58:24,232-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 10:58:24,232-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 10:58:24,235-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data1/t2.txt:0+58
2018-08-31 10:58:24,345-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-31 10:58:24,345-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-08-31 10:58:24,345-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-08-31 10:58:24,345-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-08-31 10:58:24,345-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-08-31 10:58:24,349-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-31 10:58:24,584-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-08-31 10:58:24,588-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-08-31 10:58:24,588-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-08-31 10:58:24,588-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 56; bufvoid = 104857600
2018-08-31 10:58:24,588-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
2018-08-31 10:58:24,611-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-08-31 10:58:24,633-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1385839350_0001_m_000000_0 is done. And is in the process of committing
2018-08-31 10:58:24,637-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-08-31 10:58:24,637-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1385839350_0001_m_000000_0' done.
2018-08-31 10:58:24,646-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1385839350_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=301
		FILE: Number of bytes written=498813
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=58
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=56
		Map output materialized bytes=76
		Input split bytes=113
		Combine input records=0
		Spilled Records=7
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=278921216
	File Input Format Counters 
		Bytes Read=58
2018-08-31 10:58:24,647-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1385839350_0001_m_000000_0
2018-08-31 10:58:24,648-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1385839350_0001_m_000001_0
2018-08-31 10:58:24,649-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 10:58:24,649-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 10:58:24,649-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 10:58:24,649-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 10:58:24,651-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: hdfs://localhost:9000/user/lizhijun/data1/t1.txt:0+50
2018-08-31 10:58:24,784-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
2018-08-31 10:58:24,785-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
2018-08-31 10:58:24,785-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
2018-08-31 10:58:24,785-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
2018-08-31 10:58:24,785-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
2018-08-31 10:58:24,791-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2018-08-31 10:58:24,813-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
2018-08-31 10:58:24,813-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
2018-08-31 10:58:24,813-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
2018-08-31 10:58:24,813-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 48; bufvoid = 104857600
2018-08-31 10:58:24,813-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214376(104857504); length = 21/6553600
2018-08-31 10:58:24,859-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
2018-08-31 10:58:24,871-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1385839350_0001_m_000001_0 is done. And is in the process of committing
2018-08-31 10:58:24,878-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
2018-08-31 10:58:24,878-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1385839350_0001_m_000001_0' done.
2018-08-31 10:58:24,879-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1385839350_0001_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=546
		FILE: Number of bytes written=498911
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=1
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=48
		Map output materialized bytes=66
		Input split bytes=113
		Combine input records=0
		Spilled Records=6
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=384303104
	File Input Format Counters 
		Bytes Read=50
2018-08-31 10:58:24,879-[TS] INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1385839350_0001_m_000001_0
2018-08-31 10:58:24,880-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
2018-08-31 10:58:24,884-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
2018-08-31 10:58:24,885-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1385839350_0001_r_000000_0
2018-08-31 10:58:24,898-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 2
2018-08-31 10:58:24,899-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2018-08-31 10:58:24,903-[TS] INFO pool-7-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
2018-08-31 10:58:24,903-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : null
2018-08-31 10:58:24,908-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3c472bc8
2018-08-31 10:58:24,911-[TS] WARN pool-7-thread-1 org.apache.hadoop.metrics2.impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2018-08-31 10:58:24,961-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1336252800, maxSingleShuffleLimit=334063200, mergeThreshold=881926912, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2018-08-31 10:58:24,965-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1385839350_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2018-08-31 10:58:25,011-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1385839350_0001_m_000001_0 decomp: 62 len: 66 to MEMORY
2018-08-31 10:58:25,021-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 62 bytes from map-output for attempt_local1385839350_0001_m_000001_0
2018-08-31 10:58:25,022-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->62
2018-08-31 10:58:25,024-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1385839350_0001_m_000000_0 decomp: 72 len: 76 to MEMORY
2018-08-31 10:58:25,025-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 72 bytes from map-output for attempt_local1385839350_0001_m_000000_0
2018-08-31 10:58:25,026-[TS] INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 72, inMemoryMapOutputs.size() -> 2, commitMemory -> 62, usedMemory ->134
2018-08-31 10:58:25,027-[TS] INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
2018-08-31 10:58:25,031-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 10:58:25,032-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
2018-08-31 10:58:25,054-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 2 sorted segments
2018-08-31 10:58:25,054-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 2 segments left of total size: 114 bytes
2018-08-31 10:58:25,065-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 2 segments, 134 bytes to disk to satisfy reduce memory limit
2018-08-31 10:58:25,066-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 136 bytes from disk
2018-08-31 10:58:25,066-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
2018-08-31 10:58:25,066-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
2018-08-31 10:58:25,067-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 122 bytes
2018-08-31 10:58:25,067-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 10:58:25,081-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1385839350_0001 running in uber mode : false
2018-08-31 10:58:25,082-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
2018-08-31 10:58:25,155-[TS] INFO pool-7-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2018-08-31 10:58:25,322-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1385839350_0001_r_000000_0 is done. And is in the process of committing
2018-08-31 10:58:25,327-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 2 / 2 copied.
2018-08-31 10:58:25,328-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1385839350_0001_r_000000_0 is allowed to commit now
2018-08-31 10:58:25,350-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1385839350_0001_r_000000_0' to hdfs://localhost:9000/user/lizhijun/output_19
2018-08-31 10:58:25,351-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
2018-08-31 10:58:25,352-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1385839350_0001_r_000000_0' done.
2018-08-31 10:58:25,355-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.Task - Final Counters for attempt_local1385839350_0001_r_000000_0: Counters: 29
	File System Counters
		FILE: Number of bytes read=888
		FILE: Number of bytes written=499047
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=108
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
	Map-Reduce Framework
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=142
		Reduce input records=13
		Reduce output records=10
		Spilled Records=13
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=384303104
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Output Format Counters 
		Bytes Written=84
2018-08-31 10:58:25,356-[TS] INFO pool-7-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1385839350_0001_r_000000_0
2018-08-31 10:58:25,357-[TS] INFO Thread-22 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
2018-08-31 10:58:26,086-[TS] INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
2018-08-31 10:58:26,086-[TS] INFO main org.apache.hadoop.mapreduce.Job - Job job_local1385839350_0001 completed successfully
2018-08-31 10:58:26,094-[TS] INFO main org.apache.hadoop.mapreduce.Job - Counters: 35
	File System Counters
		FILE: Number of bytes read=1735
		FILE: Number of bytes written=1496771
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=274
		HDFS: Number of bytes written=84
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=5
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=104
		Map output materialized bytes=142
		Input split bytes=226
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=142
		Reduce input records=13
		Reduce output records=10
		Spilled Records=26
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1047527424
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=84
2018-08-31 10:59:07,756-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-08-31 10:59:09,328-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-08-31 10:59:10,029-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-31 10:59:10,046-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-31 10:59:10,174-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-08-31 10:59:10,236-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-08-31 10:59:10,294-[TS] INFO main org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-08-31 10:59:10,382-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1534947266193_0003
2018-08-31 10:59:10,384-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-08-31 10:59:10,563-[TS] INFO main org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.
2018-08-31 10:59:10,615-[TS] INFO main org.apache.hadoop.conf.Configuration - resource-types.xml not found
2018-08-31 10:59:10,615-[TS] INFO main org.apache.hadoop.yarn.util.resource.ResourceUtils - Unable to find 'resource-types.xml'.
2018-08-31 10:59:10,988-[TS] INFO main org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1534947266193_0003
2018-08-31 10:59:11,047-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://10.215.107.53:8088/proxy/application_1534947266193_0003/
2018-08-31 10:59:11,047-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_1534947266193_0003
2018-08-31 11:54:48,018-[TS] WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-08-31 11:54:49,591-[TS] INFO main org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at localhost/127.0.0.1:8032
2018-08-31 11:54:50,303-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2018-08-31 11:54:50,483-[TS] WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2018-08-31 11:54:50,643-[TS] INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 2
2018-08-31 11:54:50,733-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2
2018-08-31 11:54:50,787-[TS] INFO main org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-08-31 11:54:50,898-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1534947266193_0004
2018-08-31 11:54:50,899-[TS] INFO main org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []
2018-08-31 11:54:51,057-[TS] INFO main org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.
2018-08-31 11:54:51,102-[TS] INFO main org.apache.hadoop.conf.Configuration - resource-types.xml not found
2018-08-31 11:54:51,103-[TS] INFO main org.apache.hadoop.yarn.util.resource.ResourceUtils - Unable to find 'resource-types.xml'.
2018-08-31 11:54:51,257-[TS] INFO main org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1534947266193_0004
2018-08-31 11:54:51,314-[TS] INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://10.215.107.53:8088/proxy/application_1534947266193_0004/
2018-08-31 11:54:51,315-[TS] INFO main org.apache.hadoop.mapreduce.Job - Running job: job_1534947266193_0004
